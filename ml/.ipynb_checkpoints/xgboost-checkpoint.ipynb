{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prep columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neilkloot/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/neilkloot/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>quoteDate</th>\n",
       "      <th>lastTradePriceOnly</th>\n",
       "      <th>adjustedPrice</th>\n",
       "      <th>volume</th>\n",
       "      <th>daysHigh</th>\n",
       "      <th>daysLow</th>\n",
       "      <th>previousClose</th>\n",
       "      <th>change</th>\n",
       "      <th>changeInPercent</th>\n",
       "      <th>52WeekHigh</th>\n",
       "      <th>52WeekLow</th>\n",
       "      <th>changeFrom52WeekHigh</th>\n",
       "      <th>changeFrom52WeekLow</th>\n",
       "      <th>percebtChangeFrom52WeekHigh</th>\n",
       "      <th>percentChangeFrom52WeekLow</th>\n",
       "      <th>Price200DayAverage</th>\n",
       "      <th>Price52WeekPercChange</th>\n",
       "      <th>1WeekVolatility</th>\n",
       "      <th>2WeekVolatility</th>\n",
       "      <th>4WeekVolatility</th>\n",
       "      <th>8WeekVolatility</th>\n",
       "      <th>12WeekVolatility</th>\n",
       "      <th>26WeekVolatility</th>\n",
       "      <th>52WeekVolatility</th>\n",
       "      <th>4WeekBollingerBandLower</th>\n",
       "      <th>4WeekBollingerBandUpper</th>\n",
       "      <th>4WeekBollingerPrediction</th>\n",
       "      <th>4WeekBollingerType</th>\n",
       "      <th>12WeekBollingerBandLower</th>\n",
       "      <th>12WeekBollingerBandUpper</th>\n",
       "      <th>12WeekBollingerPrediction</th>\n",
       "      <th>12WeekBollingerType</th>\n",
       "      <th>allordpreviousclose</th>\n",
       "      <th>allordchange</th>\n",
       "      <th>allorddayshigh</th>\n",
       "      <th>allorddayslow</th>\n",
       "      <th>allordpercebtChangeFrom52WeekHigh</th>\n",
       "      <th>allordpercentChangeFrom52WeekLow</th>\n",
       "      <th>asxpreviousclose</th>\n",
       "      <th>asxchange</th>\n",
       "      <th>asxdayshigh</th>\n",
       "      <th>asxdayslow</th>\n",
       "      <th>asxpercebtChangeFrom52WeekHigh</th>\n",
       "      <th>asxpercentChangeFrom52WeekLow</th>\n",
       "      <th>exDividendDate</th>\n",
       "      <th>exDividendPayout</th>\n",
       "      <th>640106_A3597525W</th>\n",
       "      <th>AINTCOV</th>\n",
       "      <th>AverageVolume</th>\n",
       "      <th>Beta</th>\n",
       "      <th>BookValuePerShareYear</th>\n",
       "      <th>CashPerShareYear</th>\n",
       "      <th>DPSRecentYear</th>\n",
       "      <th>EBITDMargin</th>\n",
       "      <th>EPS</th>\n",
       "      <th>EPSGrowthRate10Years</th>\n",
       "      <th>EPSGrowthRate5Years</th>\n",
       "      <th>FIRMMCRT</th>\n",
       "      <th>FXRUSD</th>\n",
       "      <th>Float</th>\n",
       "      <th>GRCPAIAD</th>\n",
       "      <th>GRCPAISAD</th>\n",
       "      <th>GRCPBCAD</th>\n",
       "      <th>GRCPBCSAD</th>\n",
       "      <th>GRCPBMAD</th>\n",
       "      <th>GRCPNRAD</th>\n",
       "      <th>GRCPRCAD</th>\n",
       "      <th>H01_GGDPCVGDP</th>\n",
       "      <th>H01_GGDPCVGDPFY</th>\n",
       "      <th>H05_GLFSEPTPOP</th>\n",
       "      <th>IAD</th>\n",
       "      <th>LTDebtToEquityQuarter</th>\n",
       "      <th>LTDebtToEquityYear</th>\n",
       "      <th>MarketCap</th>\n",
       "      <th>NetIncomeGrowthRate5Years</th>\n",
       "      <th>NetProfitMarginPercent</th>\n",
       "      <th>OperatingMargin</th>\n",
       "      <th>PE</th>\n",
       "      <th>PriceToBook</th>\n",
       "      <th>QuoteLast</th>\n",
       "      <th>ReturnOnAssets5Years</th>\n",
       "      <th>ReturnOnAssetsTTM</th>\n",
       "      <th>ReturnOnAssetsYear</th>\n",
       "      <th>ReturnOnEquity5Years</th>\n",
       "      <th>ReturnOnEquityTTM</th>\n",
       "      <th>ReturnOnEquityYear</th>\n",
       "      <th>RevenueGrowthRate10Years</th>\n",
       "      <th>RevenueGrowthRate5Years</th>\n",
       "      <th>TotalDebtToAssetsQuarter</th>\n",
       "      <th>TotalDebtToAssetsYear</th>\n",
       "      <th>TotalDebtToEquityQuarter</th>\n",
       "      <th>TotalDebtToEquityYear</th>\n",
       "      <th>bookValue</th>\n",
       "      <th>earningsPerShare</th>\n",
       "      <th>ebitda</th>\n",
       "      <th>epsEstimateCurrentYear</th>\n",
       "      <th>marketCapitalization</th>\n",
       "      <th>peRatio</th>\n",
       "      <th>pegRatio</th>\n",
       "      <th>pricePerBook</th>\n",
       "      <th>pricePerEpsEstimateCurrentYear</th>\n",
       "      <th>pricePerEpsEstimateNextYear</th>\n",
       "      <th>pricePerSales</th>\n",
       "      <th>Future1WeekDividend</th>\n",
       "      <th>Future1WeekPrice</th>\n",
       "      <th>Future1WeekReturn</th>\n",
       "      <th>Future1WeekRiskAdjustedReturn</th>\n",
       "      <th>Future2WeekDividend</th>\n",
       "      <th>Future2WeekPrice</th>\n",
       "      <th>Future2WeekReturn</th>\n",
       "      <th>Future2WeekRiskAdjustedReturn</th>\n",
       "      <th>Future4WeekDividend</th>\n",
       "      <th>Future4WeekPrice</th>\n",
       "      <th>Future4WeekReturn</th>\n",
       "      <th>Future4WeekRiskAdjustedReturn</th>\n",
       "      <th>Future8WeekDividend</th>\n",
       "      <th>Future8WeekPrice</th>\n",
       "      <th>Future8WeekReturn</th>\n",
       "      <th>Future8WeekRiskAdjustedReturn</th>\n",
       "      <th>Future12WeekDividend</th>\n",
       "      <th>Future12WeekPrice</th>\n",
       "      <th>Future12WeekReturn</th>\n",
       "      <th>Future12WeekRiskAdjustedReturn</th>\n",
       "      <th>Future26WeekDividend</th>\n",
       "      <th>Future26WeekPrice</th>\n",
       "      <th>Future26WeekReturn</th>\n",
       "      <th>Future26WeekRiskAdjustedReturn</th>\n",
       "      <th>Future52WeekDividend</th>\n",
       "      <th>Future52WeekPrice</th>\n",
       "      <th>Future52WeekReturn</th>\n",
       "      <th>Future52WeekRiskAdjustedReturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCA</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1876700</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.765</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.267974</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>5221.000000</td>\n",
       "      <td>41.299805</td>\n",
       "      <td>5324.399902</td>\n",
       "      <td>5221.000000</td>\n",
       "      <td>-0.082183</td>\n",
       "      <td>0.083960</td>\n",
       "      <td>5142.399902</td>\n",
       "      <td>39.100097</td>\n",
       "      <td>5247.600098</td>\n",
       "      <td>5142.399902</td>\n",
       "      <td>-0.098884</td>\n",
       "      <td>0.079135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.2</td>\n",
       "      <td>3828.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>63500000.0</td>\n",
       "      <td>87.307409</td>\n",
       "      <td>89.957900</td>\n",
       "      <td>87.425456</td>\n",
       "      <td>92.706255</td>\n",
       "      <td>87.037799</td>\n",
       "      <td>85.756318</td>\n",
       "      <td>96.070719</td>\n",
       "      <td>412937.0</td>\n",
       "      <td>1.227102</td>\n",
       "      <td>61.092677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4147.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-1.785714</td>\n",
       "      <td>-7.688946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.65</td>\n",
       "      <td>16.071429</td>\n",
       "      <td>2.693578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.64</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>2.260607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.61</td>\n",
       "      <td>8.928571</td>\n",
       "      <td>1.801456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-3.571429</td>\n",
       "      <td>-19.327464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCA</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.590</td>\n",
       "      <td>985000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.145631</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>5310.399902</td>\n",
       "      <td>89.399902</td>\n",
       "      <td>5356.500000</td>\n",
       "      <td>5310.399902</td>\n",
       "      <td>-0.066467</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>5233.399902</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>5278.899902</td>\n",
       "      <td>5233.399902</td>\n",
       "      <td>-0.082938</td>\n",
       "      <td>0.098231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.2</td>\n",
       "      <td>3828.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.7460</td>\n",
       "      <td>63500000.0</td>\n",
       "      <td>87.307409</td>\n",
       "      <td>89.957900</td>\n",
       "      <td>87.425456</td>\n",
       "      <td>92.706255</td>\n",
       "      <td>87.037799</td>\n",
       "      <td>85.756318</td>\n",
       "      <td>96.070719</td>\n",
       "      <td>412937.0</td>\n",
       "      <td>1.227102</td>\n",
       "      <td>61.092677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4147.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-8.474576</td>\n",
       "      <td>-33.621753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>10.169492</td>\n",
       "      <td>1.644524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>13.559322</td>\n",
       "      <td>2.167481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.694915</td>\n",
       "      <td>0.343165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-11.864407</td>\n",
       "      <td>-65.487513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-5.084746</td>\n",
       "      <td>-25.146688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCA</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.590</td>\n",
       "      <td>389500</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.551716</td>\n",
       "      <td>0.608284</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>0.551716</td>\n",
       "      <td>0.608284</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>5327.100098</td>\n",
       "      <td>16.700196</td>\n",
       "      <td>5365.200195</td>\n",
       "      <td>5303.100098</td>\n",
       "      <td>-0.063532</td>\n",
       "      <td>0.105988</td>\n",
       "      <td>5246.600098</td>\n",
       "      <td>13.200196</td>\n",
       "      <td>5281.799805</td>\n",
       "      <td>5218.500000</td>\n",
       "      <td>-0.080625</td>\n",
       "      <td>0.101001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.2</td>\n",
       "      <td>3828.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>63500000.0</td>\n",
       "      <td>90.544594</td>\n",
       "      <td>91.341998</td>\n",
       "      <td>90.991309</td>\n",
       "      <td>92.573106</td>\n",
       "      <td>89.675330</td>\n",
       "      <td>88.864985</td>\n",
       "      <td>100.033999</td>\n",
       "      <td>417044.0</td>\n",
       "      <td>1.124840</td>\n",
       "      <td>61.122687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4147.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.864407</td>\n",
       "      <td>1.980153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>23.728814</td>\n",
       "      <td>3.265570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>15.254237</td>\n",
       "      <td>2.464773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-3.389831</td>\n",
       "      <td>-16.909912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-5.084746</td>\n",
       "      <td>-28.202774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-5.084746</td>\n",
       "      <td>-25.164750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCA</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>288500</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.590</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.194915</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.194915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.459576</td>\n",
       "      <td>0.647924</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>0.459576</td>\n",
       "      <td>0.647924</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>5365.200195</td>\n",
       "      <td>38.100097</td>\n",
       "      <td>5365.899902</td>\n",
       "      <td>5306.899902</td>\n",
       "      <td>-0.056834</td>\n",
       "      <td>0.113898</td>\n",
       "      <td>5281.799805</td>\n",
       "      <td>35.199707</td>\n",
       "      <td>5282.299805</td>\n",
       "      <td>5221.100098</td>\n",
       "      <td>-0.074456</td>\n",
       "      <td>0.108388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.2</td>\n",
       "      <td>3828.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.7517</td>\n",
       "      <td>63500000.0</td>\n",
       "      <td>90.544594</td>\n",
       "      <td>91.341998</td>\n",
       "      <td>90.991309</td>\n",
       "      <td>92.573106</td>\n",
       "      <td>89.675330</td>\n",
       "      <td>88.864985</td>\n",
       "      <td>100.033999</td>\n",
       "      <td>417044.0</td>\n",
       "      <td>1.124840</td>\n",
       "      <td>61.122687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4147.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>38.947368</td>\n",
       "      <td>7.392109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>47.368421</td>\n",
       "      <td>7.965580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>43.157895</td>\n",
       "      <td>8.978208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>26.315789</td>\n",
       "      <td>6.024019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>22.105263</td>\n",
       "      <td>4.174630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>26.315789</td>\n",
       "      <td>5.414882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCA</td>\n",
       "      <td>2016-07-06</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.575</td>\n",
       "      <td>578900</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.105769</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.025424</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.472070</td>\n",
       "      <td>0.643930</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>0.472070</td>\n",
       "      <td>0.643930</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>5312.799805</td>\n",
       "      <td>-52.400390</td>\n",
       "      <td>5312.799805</td>\n",
       "      <td>5237.799805</td>\n",
       "      <td>-0.066046</td>\n",
       "      <td>0.103019</td>\n",
       "      <td>5228.000000</td>\n",
       "      <td>-53.799805</td>\n",
       "      <td>5228.000000</td>\n",
       "      <td>5148.700195</td>\n",
       "      <td>-0.083884</td>\n",
       "      <td>0.097098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.2</td>\n",
       "      <td>3828.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>63500000.0</td>\n",
       "      <td>90.544594</td>\n",
       "      <td>91.341998</td>\n",
       "      <td>90.991309</td>\n",
       "      <td>92.573106</td>\n",
       "      <td>89.675330</td>\n",
       "      <td>88.864985</td>\n",
       "      <td>100.033999</td>\n",
       "      <td>417044.0</td>\n",
       "      <td>1.124840</td>\n",
       "      <td>61.122687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4147.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>14.782609</td>\n",
       "      <td>2.619778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.487370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>0.940744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>1.010167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-6.086957</td>\n",
       "      <td>-32.554628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>7.826087</td>\n",
       "      <td>1.607076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol   quoteDate  lastTradePriceOnly  adjustedPrice   volume  daysHigh  \\\n",
       "0    CCA  2016-06-30               0.560          0.560  1876700     0.770   \n",
       "1    CCA  2016-07-01               0.590          0.590   985000     0.625   \n",
       "2    CCA  2016-07-04               0.590          0.590   389500     0.595   \n",
       "3    CCA  2016-07-05               0.475          0.475   288500     0.590   \n",
       "4    CCA  2016-07-06               0.575          0.575   578900     0.580   \n",
       "\n",
       "   daysLow  previousClose  change  changeInPercent  52WeekHigh  52WeekLow  \\\n",
       "0    0.535          0.765  -0.205        -0.267974        0.56      0.560   \n",
       "1    0.500          0.515   0.075         0.145631        0.59      0.560   \n",
       "2    0.555          0.565   0.025         0.044248        0.59      0.560   \n",
       "3    0.475          0.590  -0.115        -0.194915        0.59      0.475   \n",
       "4    0.520          0.520   0.055         0.105769        0.59      0.475   \n",
       "\n",
       "   changeFrom52WeekHigh  changeFrom52WeekLow  percebtChangeFrom52WeekHigh  \\\n",
       "0                   NaN                  NaN                          NaN   \n",
       "1                 0.000                 0.03                     0.000000   \n",
       "2                 0.000                 0.03                     0.000000   \n",
       "3                -0.115                 0.00                    -0.194915   \n",
       "4                -0.015                 0.10                    -0.025424   \n",
       "\n",
       "   percentChangeFrom52WeekLow  Price200DayAverage  Price52WeekPercChange  \\\n",
       "0                         NaN                 NaN                    NaN   \n",
       "1                    0.053571                 NaN                    NaN   \n",
       "2                    0.053571                 NaN                    NaN   \n",
       "3                    0.000000                 NaN                    NaN   \n",
       "4                    0.210526                 NaN                    NaN   \n",
       "\n",
       "   1WeekVolatility  2WeekVolatility  4WeekVolatility  8WeekVolatility  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1         0.015000         0.015000         0.015000         0.015000   \n",
       "2         0.014142         0.014142         0.014142         0.014142   \n",
       "3         0.047087         0.047087         0.047087         0.047087   \n",
       "4         0.042965         0.042965         0.042965         0.042965   \n",
       "\n",
       "   12WeekVolatility  26WeekVolatility  52WeekVolatility  \\\n",
       "0               NaN               NaN               NaN   \n",
       "1          0.015000          0.015000          0.015000   \n",
       "2          0.014142          0.014142          0.014142   \n",
       "3          0.047087          0.047087          0.047087   \n",
       "4          0.042965          0.042965          0.042965   \n",
       "\n",
       "   4WeekBollingerBandLower  4WeekBollingerBandUpper 4WeekBollingerPrediction  \\\n",
       "0                 0.560000                 0.560000                   Steady   \n",
       "1                 0.545000                 0.605000                   Steady   \n",
       "2                 0.551716                 0.608284                   Steady   \n",
       "3                 0.459576                 0.647924                   Steady   \n",
       "4                 0.472070                 0.643930                   Steady   \n",
       "\n",
       "  4WeekBollingerType  12WeekBollingerBandLower  12WeekBollingerBandUpper  \\\n",
       "0             Within                  0.560000                  0.560000   \n",
       "1             Within                  0.545000                  0.605000   \n",
       "2             Within                  0.551716                  0.608284   \n",
       "3             Within                  0.459576                  0.647924   \n",
       "4             Within                  0.472070                  0.643930   \n",
       "\n",
       "  12WeekBollingerPrediction 12WeekBollingerType  allordpreviousclose  \\\n",
       "0                    Steady              Within          5221.000000   \n",
       "1                    Steady              Within          5310.399902   \n",
       "2                    Steady              Within          5327.100098   \n",
       "3                    Steady              Within          5365.200195   \n",
       "4                    Steady              Within          5312.799805   \n",
       "\n",
       "   allordchange  allorddayshigh  allorddayslow  \\\n",
       "0     41.299805     5324.399902    5221.000000   \n",
       "1     89.399902     5356.500000    5310.399902   \n",
       "2     16.700196     5365.200195    5303.100098   \n",
       "3     38.100097     5365.899902    5306.899902   \n",
       "4    -52.400390     5312.799805    5237.799805   \n",
       "\n",
       "   allordpercebtChangeFrom52WeekHigh  allordpercentChangeFrom52WeekLow  \\\n",
       "0                          -0.082183                          0.083960   \n",
       "1                          -0.066467                          0.102520   \n",
       "2                          -0.063532                          0.105988   \n",
       "3                          -0.056834                          0.113898   \n",
       "4                          -0.066046                          0.103019   \n",
       "\n",
       "   asxpreviousclose  asxchange  asxdayshigh   asxdayslow  \\\n",
       "0       5142.399902  39.100097  5247.600098  5142.399902   \n",
       "1       5233.399902  91.000000  5278.899902  5233.399902   \n",
       "2       5246.600098  13.200196  5281.799805  5218.500000   \n",
       "3       5281.799805  35.199707  5282.299805  5221.100098   \n",
       "4       5228.000000 -53.799805  5228.000000  5148.700195   \n",
       "\n",
       "   asxpercebtChangeFrom52WeekHigh  asxpercentChangeFrom52WeekLow  \\\n",
       "0                       -0.098884                       0.079135   \n",
       "1                       -0.082938                       0.098231   \n",
       "2                       -0.080625                       0.101001   \n",
       "3                       -0.074456                       0.108388   \n",
       "4                       -0.083884                       0.097098   \n",
       "\n",
       "  exDividendDate  exDividendPayout  640106_A3597525W  AINTCOV  AverageVolume  \\\n",
       "0            NaN               NaN             108.2   3828.0            NaN   \n",
       "1            NaN               NaN             108.2   3828.0            NaN   \n",
       "2            NaN               NaN             108.2   3828.0            NaN   \n",
       "3            NaN               NaN             108.2   3828.0            NaN   \n",
       "4            NaN               NaN             108.2   3828.0            NaN   \n",
       "\n",
       "   Beta  BookValuePerShareYear  CashPerShareYear  DPSRecentYear  EBITDMargin  \\\n",
       "0   NaN                   0.24            -0.213            NaN          NaN   \n",
       "1   NaN                   0.24            -0.213            0.0          NaN   \n",
       "2   NaN                   0.24            -0.213            0.0          NaN   \n",
       "3   NaN                   0.24            -0.213            0.0          NaN   \n",
       "4   NaN                   0.24            -0.213            0.0          NaN   \n",
       "\n",
       "    EPS  EPSGrowthRate10Years  EPSGrowthRate5Years  FIRMMCRT  FXRUSD  \\\n",
       "0 -30.8                   NaN                  NaN      1.77  0.7426   \n",
       "1 -30.8                   NaN                  NaN      1.77  0.7460   \n",
       "2 -30.8                   NaN                  NaN      1.77  0.7506   \n",
       "3 -30.8                   NaN                  NaN      1.77  0.7517   \n",
       "4 -30.8                   NaN                  NaN      1.77  0.7436   \n",
       "\n",
       "        Float   GRCPAIAD  GRCPAISAD   GRCPBCAD  GRCPBCSAD   GRCPBMAD  \\\n",
       "0  63500000.0  87.307409  89.957900  87.425456  92.706255  87.037799   \n",
       "1  63500000.0  87.307409  89.957900  87.425456  92.706255  87.037799   \n",
       "2  63500000.0  90.544594  91.341998  90.991309  92.573106  89.675330   \n",
       "3  63500000.0  90.544594  91.341998  90.991309  92.573106  89.675330   \n",
       "4  63500000.0  90.544594  91.341998  90.991309  92.573106  89.675330   \n",
       "\n",
       "    GRCPNRAD    GRCPRCAD  H01_GGDPCVGDP  H01_GGDPCVGDPFY  H05_GLFSEPTPOP  IAD  \\\n",
       "0  85.756318   96.070719       412937.0         1.227102       61.092677  NaN   \n",
       "1  85.756318   96.070719       412937.0         1.227102       61.092677  NaN   \n",
       "2  88.864985  100.033999       417044.0         1.124840       61.122687  NaN   \n",
       "3  88.864985  100.033999       417044.0         1.124840       61.122687  NaN   \n",
       "4  88.864985  100.033999       417044.0         1.124840       61.122687  NaN   \n",
       "\n",
       "   LTDebtToEquityQuarter  LTDebtToEquityYear   MarketCap  \\\n",
       "0                    NaN                 NaN  36000000.0   \n",
       "1                    NaN                 NaN  36000000.0   \n",
       "2                    NaN                 NaN  36000000.0   \n",
       "3                    NaN                 NaN  36000000.0   \n",
       "4                    NaN                 NaN  36000000.0   \n",
       "\n",
       "   NetIncomeGrowthRate5Years  NetProfitMarginPercent  OperatingMargin   PE  \\\n",
       "0                        NaN                     NaN          -4147.2  NaN   \n",
       "1                        NaN                     NaN          -4147.2  0.0   \n",
       "2                        NaN                     NaN          -4147.2  0.0   \n",
       "3                        NaN                     NaN          -4147.2  0.0   \n",
       "4                        NaN                     NaN          -4147.2  0.0   \n",
       "\n",
       "   PriceToBook  QuoteLast  ReturnOnAssets5Years  ReturnOnAssetsTTM  \\\n",
       "0          NaN        NaN                   NaN                NaN   \n",
       "1          NaN        NaN                   NaN                NaN   \n",
       "2          NaN        NaN                   NaN                NaN   \n",
       "3          NaN        NaN                   NaN                NaN   \n",
       "4          NaN        NaN                   NaN                NaN   \n",
       "\n",
       "   ReturnOnAssetsYear  ReturnOnEquity5Years  ReturnOnEquityTTM  \\\n",
       "0                 NaN                   NaN                NaN   \n",
       "1                 NaN                   NaN                NaN   \n",
       "2                 NaN                   NaN                NaN   \n",
       "3                 NaN                   NaN                NaN   \n",
       "4                 NaN                   NaN                NaN   \n",
       "\n",
       "   ReturnOnEquityYear  RevenueGrowthRate10Years  RevenueGrowthRate5Years  \\\n",
       "0               -67.4                       NaN                      NaN   \n",
       "1               -67.4                       NaN                      NaN   \n",
       "2               -67.4                       NaN                      NaN   \n",
       "3               -67.4                       NaN                      NaN   \n",
       "4               -67.4                       NaN                      NaN   \n",
       "\n",
       "   TotalDebtToAssetsQuarter  TotalDebtToAssetsYear  TotalDebtToEquityQuarter  \\\n",
       "0                       NaN                    NaN                       NaN   \n",
       "1                       NaN                    NaN                       NaN   \n",
       "2                       NaN                    NaN                       NaN   \n",
       "3                       NaN                    NaN                       NaN   \n",
       "4                       NaN                    NaN                       NaN   \n",
       "\n",
       "   TotalDebtToEquityYear  bookValue  earningsPerShare  ebitda  \\\n",
       "0                    NaN        NaN               NaN     NaN   \n",
       "1                    0.0        NaN               NaN     NaN   \n",
       "2                    0.0        NaN               NaN     NaN   \n",
       "3                    0.0        NaN               NaN     NaN   \n",
       "4                    0.0        NaN               NaN     NaN   \n",
       "\n",
       "   epsEstimateCurrentYear  marketCapitalization  peRatio  pegRatio  \\\n",
       "0                     NaN                   NaN      NaN       NaN   \n",
       "1                     NaN                   NaN      NaN       NaN   \n",
       "2                     NaN                   NaN      NaN       NaN   \n",
       "3                     NaN                   NaN      NaN       NaN   \n",
       "4                     NaN                   NaN      NaN       NaN   \n",
       "\n",
       "   pricePerBook  pricePerEpsEstimateCurrentYear  pricePerEpsEstimateNextYear  \\\n",
       "0           NaN                             NaN                          NaN   \n",
       "1           NaN                             NaN                          NaN   \n",
       "2           NaN                             NaN                          NaN   \n",
       "3           NaN                             NaN                          NaN   \n",
       "4           NaN                             NaN                          NaN   \n",
       "\n",
       "   pricePerSales  Future1WeekDividend  Future1WeekPrice  Future1WeekReturn  \\\n",
       "0            NaN                  NaN              0.55          -1.785714   \n",
       "1            NaN                  0.0              0.54          -8.474576   \n",
       "2            NaN                  0.0              0.66          11.864407   \n",
       "3            NaN                  0.0              0.66          38.947368   \n",
       "4            NaN                  0.0              0.66          14.782609   \n",
       "\n",
       "   Future1WeekRiskAdjustedReturn  Future2WeekDividend  Future2WeekPrice  \\\n",
       "0                      -7.688946                  NaN              0.65   \n",
       "1                     -33.621753                  0.0              0.65   \n",
       "2                       1.980153                  0.0              0.73   \n",
       "3                       7.392109                  0.0              0.70   \n",
       "4                       2.619778                  0.0              0.69   \n",
       "\n",
       "   Future2WeekReturn  Future2WeekRiskAdjustedReturn  Future4WeekDividend  \\\n",
       "0          16.071429                       2.693578                  NaN   \n",
       "1          10.169492                       1.644524                  0.0   \n",
       "2          23.728814                       3.265570                  0.0   \n",
       "3          47.368421                       7.965580                  0.0   \n",
       "4          20.000000                       3.487370                  0.0   \n",
       "\n",
       "   Future4WeekPrice  Future4WeekReturn  Future4WeekRiskAdjustedReturn  \\\n",
       "0              0.64          14.285714                       2.260607   \n",
       "1              0.67          13.559322                       2.167481   \n",
       "2              0.68          15.254237                       2.464773   \n",
       "3              0.68          43.157895                       8.978208   \n",
       "4              0.60           4.347826                       0.940744   \n",
       "\n",
       "   Future8WeekDividend  Future8WeekPrice  Future8WeekReturn  \\\n",
       "0                  NaN              0.61           8.928571   \n",
       "1                  0.0              0.60           1.694915   \n",
       "2                  0.0              0.57          -3.389831   \n",
       "3                  0.0              0.60          26.315789   \n",
       "4                  0.0              0.60           4.347826   \n",
       "\n",
       "   Future8WeekRiskAdjustedReturn  Future12WeekDividend  Future12WeekPrice  \\\n",
       "0                       1.801456                   NaN               0.54   \n",
       "1                       0.343165                   0.0               0.52   \n",
       "2                     -16.909912                   0.0               0.56   \n",
       "3                       6.024019                   0.0               0.58   \n",
       "4                       1.010167                   0.0               0.54   \n",
       "\n",
       "   Future12WeekReturn  Future12WeekRiskAdjustedReturn  Future26WeekDividend  \\\n",
       "0           -3.571429                      -19.327464                   NaN   \n",
       "1          -11.864407                      -65.487513                   0.0   \n",
       "2           -5.084746                      -28.202774                   0.0   \n",
       "3           22.105263                        4.174630                   0.0   \n",
       "4           -6.086957                      -32.554628                   0.0   \n",
       "\n",
       "   Future26WeekPrice  Future26WeekReturn  Future26WeekRiskAdjustedReturn  \\\n",
       "0               0.56                 NaN                             NaN   \n",
       "1               0.56           -5.084746                      -25.146688   \n",
       "2               0.56           -5.084746                      -25.164750   \n",
       "3               0.60           26.315789                        5.414882   \n",
       "4               0.62            7.826087                        1.607076   \n",
       "\n",
       "   Future52WeekDividend  Future52WeekPrice  Future52WeekReturn  \\\n",
       "0                   NaN                NaN                 NaN   \n",
       "1                   NaN                NaN                 NaN   \n",
       "2                   NaN                NaN                 NaN   \n",
       "3                   NaN                NaN                 NaN   \n",
       "4                   NaN                NaN                 NaN   \n",
       "\n",
       "   Future52WeekRiskAdjustedReturn  \n",
       "0                             NaN  \n",
       "1                             NaN  \n",
       "2                             NaN  \n",
       "3                             NaN  \n",
       "4                             NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import stats\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "\n",
    "# Define columns\n",
    "data_columns = ['symbol', 'quoteDate', 'adjustedPrice', 'volume', 'previousClose', 'change', 'changeInPercent', \n",
    "                '52WeekHigh', '52WeekLow', 'changeFrom52WeekHigh', 'changeFrom52WeekLow', \n",
    "                'percebtChangeFrom52WeekHigh', 'percentChangeFrom52WeekLow', 'Price200DayAverage', \n",
    "                'Price52WeekPercChange', '1WeekVolatility', '2WeekVolatility', '4WeekVolatility', '8WeekVolatility', \n",
    "                '12WeekVolatility', '26WeekVolatility','52WeekVolatility','4WeekBollingerPrediction', '4WeekBollingerType',\n",
    "                '12WeekBollingerPrediction', '12WeekBollingerType', 'allordpreviousclose', 'allordchange', \n",
    "                'allorddayshigh', 'allorddayslow', 'allordpercebtChangeFrom52WeekHigh', \n",
    "                'allordpercentChangeFrom52WeekLow', 'asxpreviousclose', 'asxchange', 'asxdayshigh', \n",
    "                'asxdayslow', 'asxpercebtChangeFrom52WeekHigh', 'asxpercentChangeFrom52WeekLow', 'exDividendDate', \n",
    "                'exDividendPayout', '640106_A3597525W', 'AINTCOV', 'AverageVolume', 'BookValuePerShareYear', \n",
    "                'CashPerShareYear', 'DPSRecentYear', 'EBITDMargin', 'EPS', 'EPSGrowthRate10Years', \n",
    "                'EPSGrowthRate5Years', 'FIRMMCRT', 'FXRUSD', 'Float', 'GRCPAIAD', 'GRCPAISAD', 'GRCPBCAD', \n",
    "                'GRCPBCSAD', 'GRCPBMAD', 'GRCPNRAD', 'GRCPRCAD', 'H01_GGDPCVGDP', 'H01_GGDPCVGDPFY', 'H05_GLFSEPTPOP', \n",
    "                'IAD', 'LTDebtToEquityQuarter', 'LTDebtToEquityYear', 'MarketCap',\n",
    "                'NetIncomeGrowthRate5Years', 'NetProfitMarginPercent', 'OperatingMargin', 'PE',\n",
    "                'PriceToBook', 'ReturnOnAssets5Years', 'ReturnOnAssetsTTM', 'ReturnOnAssetsYear', \n",
    "                'ReturnOnEquity5Years', 'ReturnOnEquityTTM', 'ReturnOnEquityYear', 'RevenueGrowthRate10Years', \n",
    "                'RevenueGrowthRate5Years', 'TotalDebtToAssetsQuarter', 'TotalDebtToAssetsYear', \n",
    "                'TotalDebtToEquityQuarter', 'TotalDebtToEquityYear', 'bookValue', 'earningsPerShare', \n",
    "                'ebitda', 'epsEstimateCurrentYear', 'marketCapitalization', 'peRatio', 'pegRatio', 'pricePerBook', \n",
    "                'pricePerEpsEstimateCurrentYear', 'pricePerEpsEstimateNextYear', 'pricePerSales']\n",
    "\n",
    "selected_columns = ['symbol', 'adjustedPrice', 'volume', 'previousClose', 'change', \n",
    "                    '52WeekHigh', '52WeekLow', 'changeFrom52WeekHigh', 'changeFrom52WeekLow', \n",
    "                    'percebtChangeFrom52WeekHigh', 'percentChangeFrom52WeekLow', 'Price200DayAverage', \n",
    "                    'Price52WeekPercChange', '1WeekVolatility', '2WeekVolatility', '4WeekVolatility', '8WeekVolatility', \n",
    "                    '12WeekVolatility', '26WeekVolatility','52WeekVolatility','4WeekBollingerPrediction', '4WeekBollingerType',\n",
    "                    '12WeekBollingerPrediction', '12WeekBollingerType', 'allordchange', \n",
    "                    'allorddayshigh', 'allorddayslow', 'allordpercebtChangeFrom52WeekHigh', \n",
    "                    'allordpercentChangeFrom52WeekLow', 'asxchange', 'asxdayshigh', \n",
    "                    'asxdayslow', 'asxpercebtChangeFrom52WeekHigh', 'asxpercentChangeFrom52WeekLow', 'AverageVolume', \n",
    "                    'EBITDMargin', 'EPSGrowthRate10Years', 'EPSGrowthRate5Years', 'FIRMMCRT', 'FXRUSD', 'Float', \n",
    "                    'GRCPAIAD', 'GRCPBCAD', 'GRCPBMAD', 'GRCPNRAD', 'GRCPRCAD', 'H01_GGDPCVGDPFY', 'H05_GLFSEPTPOP', \n",
    "                    'IAD', 'LTDebtToEquityQuarter', 'LTDebtToEquityYear', 'MarketCap',\n",
    "                    'NetIncomeGrowthRate5Years', 'NetProfitMarginPercent', \n",
    "                    'PriceToBook', 'ReturnOnAssets5Years', 'ReturnOnAssetsTTM', 'ReturnOnAssetsYear', \n",
    "                    'ReturnOnEquity5Years', 'ReturnOnEquityTTM', 'RevenueGrowthRate10Years', \n",
    "                    'RevenueGrowthRate5Years', 'TotalDebtToAssetsQuarter', 'TotalDebtToAssetsYear', \n",
    "                    'TotalDebtToEquityQuarter', 'bookValue', 'earningsPerShare', \n",
    "                    'ebitda', 'epsEstimateCurrentYear', 'marketCapitalization', 'peRatio', 'pegRatio', 'pricePerBook', \n",
    "                    'pricePerEpsEstimateCurrentYear', 'pricePerEpsEstimateNextYear', 'pricePerSales']\n",
    "\n",
    "\n",
    "returns = {\n",
    "    '1': 'Future1WeekReturn',\n",
    "    '2': 'Future2WeekReturn',\n",
    "    '4': 'Future4WeekReturn',\n",
    "    '8': 'Future8WeekReturn',\n",
    "    '12': 'Future12WeekReturn',\n",
    "    '26': 'Future26WeekReturn',\n",
    "    '52': 'Future52WeekReturn',\n",
    "    '1ra': 'Future1WeekRiskAdjustedReturn',\n",
    "    '2ra': 'Future2WeekRiskAdjustedReturn',\n",
    "    '4ra': 'Future4WeekRiskAdjustedReturn',\n",
    "    '8ra': 'Future8WeekRiskAdjustedReturn',\n",
    "    '12ra': 'Future12WeekRiskAdjustedReturn',\n",
    "    '26ra': 'Future26WeekRiskAdjustedReturn',\n",
    "    '52ra': 'Future52WeekRiskAdjustedReturn'\n",
    "}\n",
    "\n",
    "# Load data\n",
    "raw_data = pd.read_csv('data/companyQuotes-20170417-001.csv')\n",
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clip values less than -99 (represents losing all money, can't go below -100)\n",
    "for key in returns:\n",
    "    return_column = returns[key]\n",
    "    raw_data[return_column] = raw_data[return_column].clip(-99, 999, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot values for each potential target\n",
    "for key in returns:\n",
    "    print('-----')\n",
    "    return_column = returns[key]\n",
    "    print(return_column)\n",
    "    raw_data.hist(column=return_column,bins=[-50, -45, -40, -35, -30, -25, -20, -15, -10, -5, 0, \n",
    "                                            5, 10, 15, 20, 25, 30, 35, 40, 45, 50])\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "    print('Instances: ', raw_data[return_column].count())\n",
    "    print('Mean: ', raw_data[return_column].mean())\n",
    "    print('Min: ', raw_data[return_column].min())\n",
    "    print('25th percentile: ', raw_data[return_column].quantile(0.25))\n",
    "    print('Median: ', raw_data[return_column].median())\n",
    "    print('75th percentile: ', raw_data[return_column].quantile(0.75))\n",
    "    print('Max: ', raw_data[return_column].max())\n",
    "    print('Std deviation: ', raw_data[return_column].std())\n",
    "    print('Variance: ', raw_data[return_column].var())\n",
    "    print('Skew: ', raw_data[return_column].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check outliers\n",
    "outliers = raw_data.loc[(raw_data[target_column] > 100) | (raw_data[target_column] < -50)]\n",
    "print(len(outliers))\n",
    "\n",
    "exclude_symbols = outliers['symbol'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove rows in the excluded symbols list\n",
    "filtered_data = raw_data[~raw_data['symbol'].isin(exclude_symbols)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply filter for specific symbolx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run filter for a few companies\n",
    "include_symbols = ['BHP', 'CBA', 'AOU', 'AYS', 'ATT', 'A01', 'BUD', 'AAP', 'AIV', 'AIB', '4DS']\n",
    "reduced_data = raw_data[raw_data['symbol'].isin(include_symbols)]\n",
    "print(len(reduced_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_data = reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Re-plot values for each potential target\n",
    "for key in returns:\n",
    "    print('-----')\n",
    "    return_column = returns[key]\n",
    "    print(return_column)\n",
    "    filtered_data.hist(column=return_column,bins=[-50, -45, -40, -35, -30, -25, -20, -15, -10, -5, 0,\n",
    "                                                  5, 10, 15, 20, 25, 30, 35, 40, 45, 50])\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "    print('Instances: ', filtered_data[return_column].count())\n",
    "    print('Mean: ', filtered_data[return_column].mean())\n",
    "    print('Min: ', filtered_data[return_column].min())\n",
    "    print('25th percentile: ', filtered_data[return_column].quantile(0.25))\n",
    "    print('Median: ', filtered_data[return_column].median())\n",
    "    print('75th percentile: ', filtered_data[return_column].quantile(0.75))\n",
    "    print('Max: ', filtered_data[return_column].max())\n",
    "    print('Std deviation: ', filtered_data[return_column].std())\n",
    "    print('Variance: ', filtered_data[return_column].var())\n",
    "    print('Skew: ', filtered_data[return_column].skew())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_data = raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up learning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set target column\n",
    "target_column = returns['8']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove rows missing the target column\n",
    "filtered_data = filtered_data.dropna(subset=[target_column], how='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-26acf5b12e8b>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-26acf5b12e8b>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    if target_val = 0:\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def convert_log(target_val):\n",
    "    if target_val == 0:\n",
    "        return 0\n",
    "    elif target_val < 0:\n",
    "        return (math.log(math.fabs(target_val)) * -1)\n",
    "    else:\n",
    "        return math.log(target_val)\n",
    "    \n",
    "filtered_data[target_column] = filtered_data[target_column].apply(lambda x: convert_log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create y_data\n",
    "y_data = filtered_data[target_column].values\n",
    "\n",
    "\n",
    "# Filter down data to the X columns being used\n",
    "filtered_data = filtered_data[data_columns]\n",
    "\n",
    "\n",
    "print(filtered_data.dtypes)\n",
    "\n",
    "print('Min:',min(y_data),', Max:', max(y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert non-numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def is_date(string):\n",
    "    try: \n",
    "        parse(string)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def convert_date_to_ordinal(date_val):\n",
    "    if(pd.isnull(date_val)):\n",
    "        return -99999\n",
    "    \n",
    "    elif(type(date_val) is str):\n",
    "        if(is_date(date_val)):\n",
    "            return parse(date_val).toordinal()\n",
    "        else:\n",
    "            return -99999\n",
    "\n",
    "    elif(type(date_val) is int or type(date_val) is float):\n",
    "        return date_val\n",
    "    \n",
    "\n",
    "# Fix date values - convert to ordinals\n",
    "filtered_data['quoteDate'] = filtered_data['quoteDate'].apply(lambda x: convert_date_to_ordinal(x))\n",
    "\n",
    "# print(filtered_data['exDividendDate'].apply(lambda x: convert_date_to_ordinal(x)))\n",
    "filtered_data['exDividendDate'] = filtered_data['exDividendDate'].apply(lambda x: convert_date_to_ordinal(x))\n",
    "\n",
    "print(filtered_data.head(5))\n",
    "\n",
    "# Convert categorical variables to boolean fields\n",
    "#  4WeekBollingerPrediction              \n",
    "#  4WeekBollingerType                    \n",
    "#  12WeekBollingerPrediction             \n",
    "#  12WeekBollingerType                   \n",
    "\n",
    "filtered_data = pd.get_dummies(data=filtered_data, columns=['symbol', '4WeekBollingerPrediction', '4WeekBollingerType', \n",
    "                                                            '12WeekBollingerPrediction', '12WeekBollingerType'])\n",
    "\n",
    "\n",
    "# Fill nan values with placeholder and check for null values\n",
    "filtered_data = filtered_data.fillna(-99999)\n",
    "print(pd.isnull(filtered_data).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(filtered_data.dtypes)\n",
    "\n",
    "# Copy over X_data columns\n",
    "X_data = filtered_data.values\n",
    "\n",
    "\n",
    "# Check how many fields in X_data\n",
    "print(X_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run xgboost with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "\n",
    "# Split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.7, test_size=0.3)\n",
    "\n",
    "print('Training for', target_column)\n",
    "\n",
    "# Fit model with training set\n",
    "start = time.time()\n",
    "model = xgb.XGBRegressor(base_score=0.35, colsample_bylevel=0.8, colsample_bytree=0.8, \n",
    "                         gamma=0, learning_rate=0.075, max_delta_step=0, max_depth=200, \n",
    "                         min_child_weight=0, missing=None, n_estimators=20000, nthread=-1, \n",
    "                         reg_alpha=0.4, reg_lambda=0.3, scale_pos_weight=0, subsample=0.8)\n",
    "eval_set = [(X_test, y_test)]\n",
    "model.fit(X_train, y_train, early_stopping_rounds=50, eval_metric=\"mae\", eval_set=eval_set, verbose=True)\n",
    "# Output model settings\n",
    "fit_time = time.time()\n",
    "print(model)\n",
    "print('Fit elapsed time: %d' % (fit_time - start))\n",
    "\n",
    "\n",
    "# make predictions for test data\n",
    "predictions = model.predict(X_test)\n",
    "predition_time = time.time()\n",
    "print('Prediction elapsed time: %d' % (predition_time - fit_time))\n",
    "\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print('Mean absolute error:', mae)\n",
    "\n",
    "# Evaluate distribution of errors - get error amount for each prediction\n",
    "y_errors = np.absolute(np.subtract(y_test, predictions))\n",
    "\n",
    "# Plot the distribution of errors\n",
    "pyplot.figure(figsize=(20, 16))\n",
    "plot_title = 'XGBoost ' + target_column + ' prediction errors'\n",
    "pyplot.plot(y_test, y_errors)\n",
    "pyplot.ylabel('Error')\n",
    "pyplot.xlabel('Actual return')\n",
    "pyplot.title(plot_title)\n",
    "pyplot.show(plot_title)\n",
    "\n",
    "# XGBRegressor(base_score=0.35, colsample_bylevel=0.8, colsample_bytree=0.8,\n",
    "#        gamma=0, learning_rate=0.075, max_delta_step=0, max_depth=70,\n",
    "#        min_child_weight=0, missing=None, n_estimators=20000, nthread=-1,\n",
    "#        objective='reg:linear', reg_alpha=0.4, reg_lambda=0.3,\n",
    "#        scale_pos_weight=0, seed=0, silent=True, subsample=0.8)\n",
    "# Fit elapsed time: 46\n",
    "# Prediction elapsed time: 0\n",
    "# Mean absolute error: 2.37654838506"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVGridSearch with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "\n",
    "# Split into train and test data\n",
    "print('Splitting data')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.75, test_size=0.25)\n",
    "\n",
    "kfold = KFold(n_splits=4, shuffle=True)\n",
    "\n",
    "print('Training for', target_column)\n",
    "\n",
    "# Fit model with training set\n",
    "start = time.time()\n",
    "model = xgb.XGBRegressor(nthread=-1, n_estimators=10000, learning_rate=0.05, max_depth=50, min_child_weight=0,\n",
    "                        gamma=1.5)\n",
    "eval_set = [(X_test, y_test)]\n",
    "over_fifty = [i/100.0 for i in range(0, 101, 5)]\n",
    "under_fifty = [i/100.0 for i in range(0, 36, 5)]\n",
    "\n",
    "paramGrid = {\n",
    "            #\"max_depth\": [i for i in range(25, 151, 25)],\n",
    "            #\"learning_rate\": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]#,\n",
    "            # \"min_child_weight\": [0,0.1,0.2], #over_fifty,\n",
    "            #\"gamma\": [0.5, 1, 1.5, 2, 2.5, 3, 3.5]#under_fifty#,\n",
    "            \"scale_pos_weight\": over_fifty,\n",
    "            #\"colsample_bylevel\": over_fifty#,\n",
    "            #\"colsample_bytree\": over_fifty,\n",
    "            #\"subsample\": over_fifty#,\n",
    "            #\"max_delta_step\": under_fifty,\n",
    "            #\"reg_lambda\": over_fifty#,\n",
    "            #\"reg_alpha\": under_fifty\n",
    "            #\"reg_lambda_bias\": under_fifty\n",
    "            }\n",
    "\n",
    "fit_params = {\n",
    "            \"early_stopping_rounds\": 50, \n",
    "            \"eval_metric\": \"mae\", \n",
    "            \"eval_set\": eval_set, \n",
    "            \"verbose\": False\n",
    "            }\n",
    "\n",
    "grid_search = GridSearchCV(model, paramGrid, scoring=\"r2\", fit_params=fit_params, verbose=2, cv=kfold)\n",
    "\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# Output model settings\n",
    "fit_time = time.time()\n",
    "print('Fit elapsed time: %d' % (fit_time - start))\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "params = grid_result.cv_results_['params']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "\n",
    "# Split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.7, test_size=0.3)\n",
    "\n",
    "print('Training for', target_column)\n",
    "\n",
    "# Fit model with training set\n",
    "start = time.time()\n",
    "model = xgb.XGBRegressor(base_score=0.35, colsample_bylevel=0.8, colsample_bytree=0.8, \n",
    "                         gamma=0, learning_rate=0.075, max_delta_step=0, max_depth=70, \n",
    "                         min_child_weight=0, missing=None, n_estimators=9500, nthread=-1, \n",
    "                         reg_alpha=0.4, reg_lambda=0.3, scale_pos_weight=0, subsample=0.8)\n",
    "model.fit(X_train, y_train)\n",
    "# Output model settings\n",
    "fit_time = time.time()\n",
    "print(model)\n",
    "print('Fit elapsed time: %d' % (fit_time - start))\n",
    "\n",
    "\n",
    "# make predictions for test data\n",
    "predictions = model.predict(X_test)\n",
    "predition_time = time.time()\n",
    "print('Prediction elapsed time: %d' % (predition_time - fit_time))\n",
    "\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print('Mean absolute error:', mae)\n",
    "\n",
    "# Evaluate distribution of errors - get error amount for each prediction\n",
    "y_errors = np.absolute(np.subtract(y_test, predictions))\n",
    "\n",
    "# Plot the distribution of errors\n",
    "pyplot.figure(figsize=(20, 16))\n",
    "plot_title = 'XGBoost ' + target_column + ' prediction errors'\n",
    "pyplot.plot(y_test, y_errors)\n",
    "pyplot.ylabel('Error')\n",
    "pyplot.xlabel('Actual return')\n",
    "pyplot.title(plot_title)\n",
    "pyplot.show(plot_title)\n",
    "\n",
    "# ---------- 8 Week Returns ---------------------------------------------\n",
    "    # --- All data ---\n",
    "    # XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "    #       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "    #       min_child_weight=1, missing=None, n_estimators=100, nthread=1,\n",
    "    #       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "    #       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "    # Mean absolute error:  27.209411857320072\n",
    "\n",
    "    # --- Removed outliers: n_estimators=100 ---\n",
    "    # XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "    #       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "    #       min_child_weight=1, missing=None, n_estimators=100, nthread=1,\n",
    "    #       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "    #       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "    # Mean absolute error:  23.8139769746\n",
    "\n",
    "    # --- Removed outliers: n_estimators=200 ---\n",
    "    # XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "    #       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "    #       min_child_weight=1, missing=None, n_estimators=200, nthread=1,\n",
    "    #       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "    #       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "    # Mean absolute error:  21.9375376132\n",
    "\n",
    "    # --- Removed outliers: n_estimators=500 ---\n",
    "    # XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "    #       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "    #       min_child_weight=1, missing=None, n_estimators=500, nthread=-1,\n",
    "    #       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "    #       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "    # Mean absolute error:  21.9761006957\n",
    "    \n",
    "    \n",
    "# ---------- 8 Week Risk Adjusted Returns -------------------------------------\n",
    "    # --- All data ---\n",
    "    # XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "    #   learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "    #   min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "    #   objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "    #   scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "    # Fit elapsed time: 193\n",
    "    # Prediction elapsed time: 3\n",
    "    # Mean absolute error: 456.680567416\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of errors\n",
    "pyplot.figure(figsize=(20, 16))\n",
    "\n",
    "print( min(y_test))\n",
    "print(max(y_test))\n",
    "\n",
    "\n",
    "plot_title = 'XGBoost ' + target_column + ' prediction errors'\n",
    "pyplot.plot(y_test, y_errors)\n",
    "pyplot.ylabel('Error')\n",
    "pyplot.xlabel('Actual return')\n",
    "pyplot.xlim([ min(y_test),max(y_test)])\n",
    "pyplot.title(plot_title)\n",
    "pyplot.show(plot_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost for one symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "\n",
    "# Split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.7, test_size=0.3)\n",
    "\n",
    "print('Training for', target_column)\n",
    "\n",
    "# Fit model with training set\n",
    "model = xgb.XGBRegressor(nthread=-1, colsample_bylevel=0.8, colsample_bytree=0.8,\n",
    "                         learning_rate=0.075, max_depth=10,n_estimators=9500, \n",
    "                         subsample=0.8)\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "# Output model settings\n",
    "print(model)\n",
    "print('Fit elapsed time: %d' % (elapsed))\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "# make predictions for test data\n",
    "predictions = model.predict(X_test)\n",
    "elapsed = time.time() - start\n",
    "print('Prediction elapsed time: %d' % (elapsed))\n",
    "\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print('Mean absolute error:', mae)\n",
    "\n",
    "# Evaluate distribution of errors - get error amount for each prediction\n",
    "y_errors = np.absolute(np.subtract(y_test, predictions))\n",
    "\n",
    "# Plot the distribution of errors\n",
    "pyplot.figure(figsize=(20, 16))\n",
    "plot_title = 'XGBoost ' + target_column + ' prediction errors'\n",
    "pyplot.plot(y_test, y_errors)\n",
    "pyplot.ylabel('Error')\n",
    "pyplot.xlabel('Actual return')\n",
    "pyplot.title(plot_title)\n",
    "pyplot.show(plot_title)\n",
    "\n",
    "# ---------- 8 Week Returns - CBA  ---------------------------------------------\n",
    "    # Training for Future8WeekReturn\n",
    "    # XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "    #        learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "    #        min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "    #        objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "    #        scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "    # Fit elapsed time: 0\n",
    "    # Prediction elapsed time: 0\n",
    "    # Mean absolute error: 2.85405055196\n",
    "\n",
    "#     Training for Future8WeekReturn\n",
    "#     XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "#            learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "#            min_child_weight=1, missing=None, n_estimators=500, nthread=-1,\n",
    "#            objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "#            scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "#     Fit elapsed time: 1\n",
    "#     Prediction elapsed time: 0\n",
    "#     Mean absolute error: 1.87473924615\n",
    "\n",
    "#     Training for Future8WeekReturn\n",
    "#     XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "#            learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "#            min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n",
    "#            objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "#            scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "#     Fit elapsed time: 2\n",
    "#     Prediction elapsed time: 0\n",
    "#     Mean absolute error: 1.82999759228\n",
    "\n",
    "#     Training for Future8WeekReturn\n",
    "#     XGBRegressor(base_score=0.5, colsample_bylevel=0.8, colsample_bytree=0.8,\n",
    "#            gamma=0, learning_rate=0.075, max_delta_step=0, max_depth=10,\n",
    "#            min_child_weight=1, missing=None, n_estimators=9500, nthread=-1,\n",
    "#            objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "#            scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
    "#     Fit elapsed time: 14\n",
    "#     Prediction elapsed time: 0\n",
    "#     Mean absolute error: 1.55688219974\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimise single symbol model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "\n",
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Work through parameter optimization\")\n",
    "\n",
    "    # Split into train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.7, test_size=0.3)\n",
    "\n",
    "    \n",
    "    model = xgb.XGBRegressor(nthread=-1)\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "\n",
    "    print(\"Set non-optimised baseline\")\n",
    "    round_err = []\n",
    "    for r in range(0, 5):\n",
    "        err = []\n",
    "        for train_index, test_index in kfold.split(X_data):\n",
    "            model.fit(X_data[train_index],y_data[train_index])\n",
    "            predictions = model.predict(X_data[test_index])\n",
    "            actuals = y_data[test_index]\n",
    "            err.append(mean_absolute_error(actuals, predictions))\n",
    "\n",
    "        print(np.mean(err))\n",
    "        round_err.append(np.mean(err))\n",
    "\n",
    "    baseline_error = np.mean(round_err)\n",
    "\n",
    "    print(\"Average baseline error: %f\" % baseline_error)\n",
    "    print('-----')\n",
    "\n",
    "    n_estimators=[7000, 7500, 8000, 8500, 9000, 9500, 10000]\n",
    "        \n",
    "    param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    n_estimators_r = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        n_estimators_r.append(grid_result.best_params_['n_estimators'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    n_estimators = find_nearest(n_estimators_r, np.mean(n_estimators_r))\n",
    "    \n",
    "    model.n_estimators = n_estimators\n",
    "    \n",
    "    print(\"Averaged best n_estimators: %f \" % n_estimators)\n",
    "    print('-----')  \n",
    "        \n",
    "    learning_rate = [0.025, 0.05, 0.075, 0.1, 0.2, 0.3]\n",
    "    param_grid = dict(learning_rate=learning_rate)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    learning_rates = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        learning_rates.append(grid_result.best_params_['learning_rate'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    learning_rate = find_nearest(learning_rates, np.mean(learning_rates))\n",
    "    \n",
    "    model.learning_rate = learning_rate\n",
    "    \n",
    "    print(\"Averaged best learning rate: %f \" % learning_rate)\n",
    "    print('-----')     \n",
    "\n",
    "    max_depth = [2, 4, 6, 8, 10, 12, 14]\n",
    "    param_grid = dict(max_depth=max_depth)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    max_depths = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        max_depths.append(grid_result.best_params_['max_depth'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    max_depth = find_nearest(max_depths, np.mean(max_depths))\n",
    "    \n",
    "    model.max_depth = max_depth\n",
    "    \n",
    "    print(\"Averaged best max depth: %f \" % max_depth)\n",
    "    print('-----')\n",
    "    samples = [0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1.0] #[i/100.0 for i in range(60,101, 5)]\n",
    "    param_grid = dict(subsample=samples)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    subsamples = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        subsamples.append(grid_result.best_params_['subsample'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    subsample = find_nearest(subsamples, np.mean(subsamples))\n",
    "    \n",
    "    model.subsample = subsample\n",
    "    \n",
    "    print(\"Averaged best subsample: %f \" % subsample)\n",
    "    print('-----')\n",
    "\n",
    "    param_grid = dict(colsample_bytree=samples)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    colsample_bytrees = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        colsample_bytrees.append(grid_result.best_params_['colsample_bytree'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    colsample_bytree = find_nearest(colsample_bytrees, np.mean(colsample_bytrees))\n",
    "    \n",
    "    model.colsample_bytree = colsample_bytree\n",
    "    \n",
    "    print(\"Averaged best colsample_bytree: %f \" % colsample_bytree)\n",
    "    print('-----')\n",
    "\n",
    "    param_grid = dict(colsample_bylevel=samples)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    colsample_bylevels = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        colsample_bylevels.append(grid_result.best_params_['colsample_bylevel'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    colsample_bylevel = find_nearest(colsample_bylevels, np.mean(colsample_bylevels))\n",
    "    \n",
    "    model.colsample_bylevel = colsample_bylevel\n",
    "    \n",
    "    print(\"Averaged best colsample_bylevel: %f \" % colsample_bylevel)\n",
    "    print('-----')\n",
    "\n",
    "    # Retest with new parameters\n",
    "    round_err = []\n",
    "    for r in range(0, 5):\n",
    "        err = []\n",
    "        for train_index, test_index in kfold.split(X_data):\n",
    "            xgb_model = xgb.XGBRegressor(nthread=-1, colsample_bytree = colsample_bytree, \n",
    "                                         learning_rate = learning_rate, max_depth = max_depth, \n",
    "                                         n_estimators = n_estimators, subsample = subsample,\n",
    "                                         colsample_bylevel = colsample_bylevel)\n",
    "            xgb_model.fit(X_data[train_index],y_data[train_index])\n",
    "            predictions = model.predict(X_data[test_index])\n",
    "            actuals = y_data[test_index]\n",
    "            err.append(mean_absolute_error(actuals, predictions))\n",
    "               \n",
    "        print(np.mean(err))\n",
    "        round_err.append(np.mean(err))\n",
    "\n",
    "    tuned_error = np.mean(round_err)\n",
    "\n",
    "    print(\"Average tuned error: %s\" % tuned_error)\n",
    "    improvement = baseline_error - tuned_error\n",
    "    print('-----')\n",
    "    print('Optimisation improvement result: %s, %s%%' % (improvement, improvement / baseline_error * 100))\n",
    "    print('-----')\n",
    "    print(xgb_model)\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    weights = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    \n",
    "#     model.eval_metric = 'mae'\n",
    "    \n",
    "#     gamma = [0]\n",
    "#     param_grid = dict(gamma=gamma)\n",
    "\n",
    "#     grid_search = GridSearchCV(model, param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "#     gammas = []\n",
    "\n",
    "#     for r in range(0, 5):\n",
    "#         grid_result = grid_search.fit(X_data, y_data)\n",
    "#         # summarize results\n",
    "#         print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#         gammas.append(grid_result.best_params_['gamma'])\n",
    "#         means = grid_result.cv_results_['mean_test_score']\n",
    "#         stds = grid_result.cv_results_['std_test_score']\n",
    "#         params = grid_result.cv_results_['params']\n",
    "\n",
    "#     gamma = find_nearest(gammas, np.mean(gammas))\n",
    "    \n",
    "#     model.gamma = gamma\n",
    "    \n",
    "#     print(\"Averaged best gamma: %f \" % gamma)\n",
    "#     print('-----')    \n",
    "    \n",
    "#     min_child_weight = [0]\n",
    "#     param_grid = dict(min_child_weight=min_child_weight)\n",
    "\n",
    "#     grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "#     min_child_weights = []\n",
    "\n",
    "#     for r in range(0, 5):\n",
    "#         grid_result = grid_search.fit(X_data, y_data)\n",
    "#         # summarize results\n",
    "#         print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#         min_child_weights.append(grid_result.best_params_['min_child_weight'])\n",
    "#         means = grid_result.cv_results_['mean_test_score']\n",
    "#         stds = grid_result.cv_results_['std_test_score']\n",
    "#         params = grid_result.cv_results_['params']\n",
    "\n",
    "#     min_child_weight = find_nearest(min_child_weights, np.mean(min_child_weights))\n",
    "    \n",
    "#     model.min_child_weight = min_child_weight\n",
    "    \n",
    "#     print(\"Averaged best min_child_weight: %f \" % min_child_weight)\n",
    "#     print('-----')\n",
    "\n",
    "    gamma = 0\n",
    "    min_child_weight = 0\n",
    "\n",
    "    reg_lambda = [0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "    param_grid = dict(reg_lambda=reg_lambda)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    reg_lambdas = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        reg_lambdas.append(grid_result.best_params_['reg_lambda'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    reg_lambda = find_nearest(reg_lambdas, np.mean(reg_lambdas))\n",
    "    \n",
    "    model.reg_lambda = reg_lambda\n",
    "    \n",
    "    print(\"Averaged best reg_lambda: %f \" % reg_lambda)\n",
    "    print('-----')\n",
    "\n",
    "    scale_pos_weight = [0, 1, 2, 3, 4, 5]\n",
    "    param_grid = dict(scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    scale_pos_weights = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        scale_pos_weights.append(grid_result.best_params_['scale_pos_weight'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    scale_pos_weight = find_nearest(scale_pos_weights, np.mean(scale_pos_weights))\n",
    "    \n",
    "    model.scale_pos_weight = scale_pos_weight\n",
    "    \n",
    "    print(\"Averaged best scale_pos_weight: %f \" % scale_pos_weight)\n",
    "    print('-----')\n",
    "    \n",
    "\n",
    "    reg_alpha = [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "    param_grid = dict(reg_alpha=reg_alpha)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    reg_alphas = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        reg_alphas.append(grid_result.best_params_['reg_alpha'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    reg_alpha = find_nearest(reg_alphas, np.mean(reg_alphas))\n",
    "    \n",
    "    model.reg_alpha = reg_alpha\n",
    "    \n",
    "    print(\"Averaged best reg_alpha: %f \" % reg_alpha)\n",
    "    print('-----')\n",
    "        \n",
    "    base_score = [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "    param_grid = dict(base_score=base_score)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    base_scores = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        base_scores.append(grid_result.best_params_['base_score'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    base_score = find_nearest(base_scores, np.mean(base_scores))\n",
    "    \n",
    "    model.base_score = base_score\n",
    "    \n",
    "    print(\"Averaged best base_score: %f \" % base_score)\n",
    "    print('-----')\n",
    "\n",
    "    \n",
    "    # Retest with new parameters\n",
    "    round_err = []\n",
    "    for r in range(0, 5):\n",
    "        err = []\n",
    "        for train_index, test_index in kfold.split(X_data):\n",
    "            xgb_model = xgb.XGBRegressor(nthread=-1, colsample_bytree = colsample_bytree, gamma=gamma, \n",
    "                                         learning_rate = learning_rate, max_depth = max_depth, \n",
    "                                         n_estimators = n_estimators, subsample = subsample,\n",
    "                                         colsample_bylevel = colsample_bylevel, base_score = base_score,\n",
    "                                         reg_alpha = reg_alpha, scale_pos_weight = scale_pos_weight,\n",
    "                                         reg_lambda = reg_lambda, min_child_weight = min_child_weight)\n",
    "            xgb_model.fit(X_data[train_index],y_data[train_index])\n",
    "            predictions = model.predict(X_data[test_index])\n",
    "            actuals = y_data[test_index]\n",
    "            err.append(mean_absolute_error(actuals, predictions))\n",
    "               \n",
    "        print(np.mean(err))\n",
    "        round_err.append(np.mean(err))\n",
    "\n",
    "    tuned_error = np.mean(round_err)\n",
    "\n",
    "    print(\"Average tuned error: %s\" % tuned_error)\n",
    "    improvement = baseline_error - tuned_error\n",
    "    print('-----')\n",
    "    print('Optimisation improvement result: %s, %s%%' % (improvement, improvement / baseline_error * 100))\n",
    "    print('-----')\n",
    "    print(xgb_model)\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    model.max_depth = 70\n",
    "    n_estimators=[7000, 7500, 8000, 8500, 9000, 9500, 10000]\n",
    "        \n",
    "    param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    n_estimators_r = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        n_estimators_r.append(grid_result.best_params_['n_estimators'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    n_estimators = find_nearest(n_estimators_r, np.mean(n_estimators_r))\n",
    "    \n",
    "    model.n_estimators = n_estimators\n",
    "    \n",
    "    print(\"Averaged best n_estimators: %f \" % n_estimators)\n",
    "    print('-----')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare model to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Test with base parameters\n",
    "print('-----')\n",
    "print('Base model')\n",
    "\n",
    "base_errs = []\n",
    "base_r2s = []\n",
    "for r in range(0, 5):\n",
    "    err = []\n",
    "    r2 = []\n",
    "    for train_index, test_index in kfold.split(X_data):\n",
    "        start = time.time()\n",
    "        base_model = xgb.XGBRegressor(nthread=-1)\n",
    "        base_model.fit(X_data[train_index],y_data[train_index])\n",
    "        fit_time = time.time()\n",
    "        predictions = base_model.predict(X_data[test_index])\n",
    "        prediction_time = time.time()\n",
    "        actuals = y_data[test_index]\n",
    "        err.append(mean_absolute_error(actuals, predictions))\n",
    "        r2.append(r2_score(actuals, predictions))\n",
    "               \n",
    "    print(np.mean(err))\n",
    "    base_errs.append(np.mean(err))\n",
    "    print(np.mean(r2))\n",
    "    base_r2s.append(np.mean(r2))\n",
    "    print('Fit elapsed time: %d, Prediction elapsed time: %d' % (fit_time - start, prediction_time - fit_time))\n",
    "\n",
    "base_error = np.mean(base_errs)\n",
    "base_r2 = np.mean(base_r2s)\n",
    "\n",
    "print('-----')\n",
    "print(base_model)\n",
    "print(\"Average base error: %s\" % base_error)\n",
    "print(\"Average base r2: %s\" % base_r2)\n",
    "\n",
    "\n",
    "# Retest with new parameters\n",
    "print('-----')\n",
    "print('Optimised model')\n",
    "\n",
    "opt_err = []\n",
    "opt_r2s = []\n",
    "for r in range(0, 5):\n",
    "    err = []\n",
    "    r2 = []\n",
    "    for train_index, test_index in kfold.split(X_data):\n",
    "        start = time.time()\n",
    "        tuned_model = xgb.XGBRegressor(n_estimators=10000, nthread=-1,  learning_rate=0.05, max_depth=50)\n",
    "        eval_set = [(X_data[test_index], y_data[test_index])]\n",
    "        tuned_model.fit(X_data[train_index],y_data[train_index], early_stopping_rounds=50, eval_metric=\"mae\", \n",
    "                        eval_set=eval_set, verbose=False)\n",
    "        fit_time = time.time()\n",
    "        predictions = tuned_model.predict(X_data[test_index])\n",
    "        prediction_time = time.time()\n",
    "        actuals = y_data[test_index]\n",
    "        err.append(mean_absolute_error(actuals, predictions))\n",
    "        r2.append(r2_score(actuals, predictions))\n",
    "               \n",
    "    print(np.mean(err))\n",
    "    opt_err.append(np.mean(err))\n",
    "    print(np.mean(r2))\n",
    "    opt_r2s.append(np.mean(r2))\n",
    "    print('Fit elapsed time: %d, Prediction elapsed time: %d' % (fit_time - start, prediction_time - fit_time))\n",
    "\n",
    "\n",
    "tuned_error = np.mean(opt_err)\n",
    "tuned_r2 = np.mean(opt_r2s)\n",
    "\n",
    "\n",
    "print('-----')\n",
    "print(tuned_model)\n",
    "print(\"Average tuned error: %s\" % tuned_error)\n",
    "improvement = base_error - tuned_error\n",
    "print('Optimisation improvement result: %s, %s%%' % (improvement, improvement / base_error * 100))\n",
    "print('-----')\n",
    "\n",
    "print(\"Average tuned r2: %s\" % tuned_r2)\n",
    "improvement = tuned_r2 - base_r2\n",
    "print('Optimisation improvement result: %s, %s%%' % (improvement, improvement / base_r2 * 100))\n",
    "print('-----')\n",
    "\n",
    "\n",
    "#     --- CBA --\n",
    "#     Base model\n",
    "#     2.76593178309\n",
    "#     Fit elapsed time: 0, Prediction elapsed time: 0\n",
    "#     2.80202959964\n",
    "#     Fit elapsed time: 0, Prediction elapsed time: 0\n",
    "#     2.74822700498\n",
    "#     Fit elapsed time: 0, Prediction elapsed time: 0\n",
    "#     2.80035623995\n",
    "#     Fit elapsed time: 0, Prediction elapsed time: 0\n",
    "#     2.78568218851\n",
    "#     Fit elapsed time: 0, Prediction elapsed time: 0\n",
    "#     -----\n",
    "#     XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "#            learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "#            min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "#            objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "#            scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "#     Average base error: 2.78044536324\n",
    "#     -----\n",
    "#     Optimised model\n",
    "#     1.42491403015\n",
    "#     Fit elapsed time: 42, Prediction elapsed time: 0\n",
    "#     1.4597646821\n",
    "#     Fit elapsed time: 43, Prediction elapsed time: 0\n",
    "#     1.46155690531\n",
    "#     Fit elapsed time: 43, Prediction elapsed time: 0\n",
    "#     1.45526380132\n",
    "#     Fit elapsed time: 44, Prediction elapsed time: 0\n",
    "#     1.48145221254\n",
    "#     Fit elapsed time: 42, Prediction elapsed time: 0\n",
    "#     -----\n",
    "#     XGBRegressor(base_score=0.35, colsample_bylevel=0.8, colsample_bytree=0.8,\n",
    "#            gamma=0, learning_rate=0.075, max_delta_step=0, max_depth=70,\n",
    "#            min_child_weight=0, missing=None, n_estimators=9500, nthread=-1,\n",
    "#            objective='reg:linear', reg_alpha=0.4, reg_lambda=0.3,\n",
    "#            scale_pos_weight=0, seed=0, silent=True, subsample=0.8)\n",
    "#     Average tuned error: 1.45659032628\n",
    "#     -----\n",
    "#     Optimisation improvement result: 1.32385503695, 47.6130570468%\n",
    "#     -----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check correlations \n",
    "filtered_data[data_columns].corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skrebate import ReliefF\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.7, test_size=0.3)\n",
    "\n",
    "\n",
    "fs = ReliefF()\n",
    "fs.fit(X_train, y_train)\n",
    "\n",
    "for feature_name, feature_score in zip(filtered_data.columns, fs.feature_importances_):\n",
    "    print(feature_name, '\\t', feature_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
