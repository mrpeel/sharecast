{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prep columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neilkloot/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/neilkloot/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>quoteDate</th>\n",
       "      <th>lastTradePriceOnly</th>\n",
       "      <th>adjustedPrice</th>\n",
       "      <th>volume</th>\n",
       "      <th>daysHigh</th>\n",
       "      <th>daysLow</th>\n",
       "      <th>previousClose</th>\n",
       "      <th>change</th>\n",
       "      <th>changeInPercent</th>\n",
       "      <th>52WeekHigh</th>\n",
       "      <th>52WeekLow</th>\n",
       "      <th>changeFrom52WeekHigh</th>\n",
       "      <th>changeFrom52WeekLow</th>\n",
       "      <th>percebtChangeFrom52WeekHigh</th>\n",
       "      <th>percentChangeFrom52WeekLow</th>\n",
       "      <th>Price200DayAverage</th>\n",
       "      <th>Price52WeekPercChange</th>\n",
       "      <th>1WeekVolatility</th>\n",
       "      <th>2WeekVolatility</th>\n",
       "      <th>4WeekVolatility</th>\n",
       "      <th>8WeekVolatility</th>\n",
       "      <th>12WeekVolatility</th>\n",
       "      <th>26WeekVolatility</th>\n",
       "      <th>52WeekVolatility</th>\n",
       "      <th>4WeekBollingerBandLower</th>\n",
       "      <th>4WeekBollingerBandUpper</th>\n",
       "      <th>4WeekBollingerPrediction</th>\n",
       "      <th>4WeekBollingerType</th>\n",
       "      <th>12WeekBollingerBandLower</th>\n",
       "      <th>12WeekBollingerBandUpper</th>\n",
       "      <th>12WeekBollingerPrediction</th>\n",
       "      <th>12WeekBollingerType</th>\n",
       "      <th>allordpreviousclose</th>\n",
       "      <th>allordchange</th>\n",
       "      <th>allorddayshigh</th>\n",
       "      <th>allorddayslow</th>\n",
       "      <th>allordpercebtChangeFrom52WeekHigh</th>\n",
       "      <th>allordpercentChangeFrom52WeekLow</th>\n",
       "      <th>asxpreviousclose</th>\n",
       "      <th>asxchange</th>\n",
       "      <th>asxdayshigh</th>\n",
       "      <th>asxdayslow</th>\n",
       "      <th>asxpercebtChangeFrom52WeekHigh</th>\n",
       "      <th>asxpercentChangeFrom52WeekLow</th>\n",
       "      <th>exDividendDate</th>\n",
       "      <th>exDividendPayout</th>\n",
       "      <th>640106_A3597525W</th>\n",
       "      <th>AINTCOV</th>\n",
       "      <th>AverageVolume</th>\n",
       "      <th>Beta</th>\n",
       "      <th>BookValuePerShareYear</th>\n",
       "      <th>CashPerShareYear</th>\n",
       "      <th>DPSRecentYear</th>\n",
       "      <th>EBITDMargin</th>\n",
       "      <th>EPS</th>\n",
       "      <th>EPSGrowthRate10Years</th>\n",
       "      <th>EPSGrowthRate5Years</th>\n",
       "      <th>FIRMMCRT</th>\n",
       "      <th>FXRUSD</th>\n",
       "      <th>Float</th>\n",
       "      <th>GRCPAIAD</th>\n",
       "      <th>GRCPAISAD</th>\n",
       "      <th>GRCPBCAD</th>\n",
       "      <th>GRCPBCSAD</th>\n",
       "      <th>GRCPBMAD</th>\n",
       "      <th>GRCPNRAD</th>\n",
       "      <th>GRCPRCAD</th>\n",
       "      <th>H01_GGDPCVGDP</th>\n",
       "      <th>H01_GGDPCVGDPFY</th>\n",
       "      <th>H05_GLFSEPTPOP</th>\n",
       "      <th>IAD</th>\n",
       "      <th>LTDebtToEquityQuarter</th>\n",
       "      <th>LTDebtToEquityYear</th>\n",
       "      <th>MarketCap</th>\n",
       "      <th>NetIncomeGrowthRate5Years</th>\n",
       "      <th>NetProfitMarginPercent</th>\n",
       "      <th>OperatingMargin</th>\n",
       "      <th>PE</th>\n",
       "      <th>PriceToBook</th>\n",
       "      <th>QuoteLast</th>\n",
       "      <th>ReturnOnAssets5Years</th>\n",
       "      <th>ReturnOnAssetsTTM</th>\n",
       "      <th>ReturnOnAssetsYear</th>\n",
       "      <th>ReturnOnEquity5Years</th>\n",
       "      <th>ReturnOnEquityTTM</th>\n",
       "      <th>ReturnOnEquityYear</th>\n",
       "      <th>RevenueGrowthRate10Years</th>\n",
       "      <th>RevenueGrowthRate5Years</th>\n",
       "      <th>TotalDebtToAssetsQuarter</th>\n",
       "      <th>TotalDebtToAssetsYear</th>\n",
       "      <th>TotalDebtToEquityQuarter</th>\n",
       "      <th>TotalDebtToEquityYear</th>\n",
       "      <th>bookValue</th>\n",
       "      <th>earningsPerShare</th>\n",
       "      <th>ebitda</th>\n",
       "      <th>epsEstimateCurrentYear</th>\n",
       "      <th>marketCapitalization</th>\n",
       "      <th>peRatio</th>\n",
       "      <th>pegRatio</th>\n",
       "      <th>pricePerBook</th>\n",
       "      <th>pricePerEpsEstimateCurrentYear</th>\n",
       "      <th>pricePerEpsEstimateNextYear</th>\n",
       "      <th>pricePerSales</th>\n",
       "      <th>Future1WeekDividend</th>\n",
       "      <th>Future1WeekPrice</th>\n",
       "      <th>Future1WeekReturn</th>\n",
       "      <th>Future1WeekRiskAdjustedReturn</th>\n",
       "      <th>Future2WeekDividend</th>\n",
       "      <th>Future2WeekPrice</th>\n",
       "      <th>Future2WeekReturn</th>\n",
       "      <th>Future2WeekRiskAdjustedReturn</th>\n",
       "      <th>Future4WeekDividend</th>\n",
       "      <th>Future4WeekPrice</th>\n",
       "      <th>Future4WeekReturn</th>\n",
       "      <th>Future4WeekRiskAdjustedReturn</th>\n",
       "      <th>Future8WeekDividend</th>\n",
       "      <th>Future8WeekPrice</th>\n",
       "      <th>Future8WeekReturn</th>\n",
       "      <th>Future8WeekRiskAdjustedReturn</th>\n",
       "      <th>Future12WeekDividend</th>\n",
       "      <th>Future12WeekPrice</th>\n",
       "      <th>Future12WeekReturn</th>\n",
       "      <th>Future12WeekRiskAdjustedReturn</th>\n",
       "      <th>Future26WeekDividend</th>\n",
       "      <th>Future26WeekPrice</th>\n",
       "      <th>Future26WeekReturn</th>\n",
       "      <th>Future26WeekRiskAdjustedReturn</th>\n",
       "      <th>Future52WeekDividend</th>\n",
       "      <th>Future52WeekPrice</th>\n",
       "      <th>Future52WeekReturn</th>\n",
       "      <th>Future52WeekRiskAdjustedReturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCA</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.560</td>\n",
       "      <td>1876700</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.765</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.267974</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>5221.000000</td>\n",
       "      <td>41.299805</td>\n",
       "      <td>5324.399902</td>\n",
       "      <td>5221.000000</td>\n",
       "      <td>-0.082183</td>\n",
       "      <td>0.083960</td>\n",
       "      <td>5142.399902</td>\n",
       "      <td>39.100097</td>\n",
       "      <td>5247.600098</td>\n",
       "      <td>5142.399902</td>\n",
       "      <td>-0.098884</td>\n",
       "      <td>0.079135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.2</td>\n",
       "      <td>3828.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>63500000.0</td>\n",
       "      <td>87.307409</td>\n",
       "      <td>89.957900</td>\n",
       "      <td>87.425456</td>\n",
       "      <td>92.706255</td>\n",
       "      <td>87.037799</td>\n",
       "      <td>85.756318</td>\n",
       "      <td>96.070719</td>\n",
       "      <td>412937.0</td>\n",
       "      <td>1.227102</td>\n",
       "      <td>61.092677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4147.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-1.785714</td>\n",
       "      <td>-7.688946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.65</td>\n",
       "      <td>16.071429</td>\n",
       "      <td>2.693578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.64</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>2.260607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.61</td>\n",
       "      <td>8.928571</td>\n",
       "      <td>1.801456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-3.571429</td>\n",
       "      <td>-19.327464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCA</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.590</td>\n",
       "      <td>985000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.145631</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>5310.399902</td>\n",
       "      <td>89.399902</td>\n",
       "      <td>5356.500000</td>\n",
       "      <td>5310.399902</td>\n",
       "      <td>-0.066467</td>\n",
       "      <td>0.102520</td>\n",
       "      <td>5233.399902</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>5278.899902</td>\n",
       "      <td>5233.399902</td>\n",
       "      <td>-0.082938</td>\n",
       "      <td>0.098231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.2</td>\n",
       "      <td>3828.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.7460</td>\n",
       "      <td>63500000.0</td>\n",
       "      <td>87.307409</td>\n",
       "      <td>89.957900</td>\n",
       "      <td>87.425456</td>\n",
       "      <td>92.706255</td>\n",
       "      <td>87.037799</td>\n",
       "      <td>85.756318</td>\n",
       "      <td>96.070719</td>\n",
       "      <td>412937.0</td>\n",
       "      <td>1.227102</td>\n",
       "      <td>61.092677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4147.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-8.474576</td>\n",
       "      <td>-33.621753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>10.169492</td>\n",
       "      <td>1.644524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>13.559322</td>\n",
       "      <td>2.167481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.694915</td>\n",
       "      <td>0.343165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>-11.864407</td>\n",
       "      <td>-65.487513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-5.084746</td>\n",
       "      <td>-25.146688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCA</td>\n",
       "      <td>2016-07-04</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.590</td>\n",
       "      <td>389500</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.014142</td>\n",
       "      <td>0.551716</td>\n",
       "      <td>0.608284</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>0.551716</td>\n",
       "      <td>0.608284</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>5327.100098</td>\n",
       "      <td>16.700196</td>\n",
       "      <td>5365.200195</td>\n",
       "      <td>5303.100098</td>\n",
       "      <td>-0.063532</td>\n",
       "      <td>0.105988</td>\n",
       "      <td>5246.600098</td>\n",
       "      <td>13.200196</td>\n",
       "      <td>5281.799805</td>\n",
       "      <td>5218.500000</td>\n",
       "      <td>-0.080625</td>\n",
       "      <td>0.101001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.2</td>\n",
       "      <td>3828.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>63500000.0</td>\n",
       "      <td>90.544594</td>\n",
       "      <td>91.341998</td>\n",
       "      <td>90.991309</td>\n",
       "      <td>92.573106</td>\n",
       "      <td>89.675330</td>\n",
       "      <td>88.864985</td>\n",
       "      <td>100.033999</td>\n",
       "      <td>417044.0</td>\n",
       "      <td>1.124840</td>\n",
       "      <td>61.122687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4147.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.864407</td>\n",
       "      <td>1.980153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>23.728814</td>\n",
       "      <td>3.265570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>15.254237</td>\n",
       "      <td>2.464773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-3.389831</td>\n",
       "      <td>-16.909912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-5.084746</td>\n",
       "      <td>-28.202774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-5.084746</td>\n",
       "      <td>-25.164750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCA</td>\n",
       "      <td>2016-07-05</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.475</td>\n",
       "      <td>288500</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.590</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>-0.194915</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-0.115</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.194915</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.459576</td>\n",
       "      <td>0.647924</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>0.459576</td>\n",
       "      <td>0.647924</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>5365.200195</td>\n",
       "      <td>38.100097</td>\n",
       "      <td>5365.899902</td>\n",
       "      <td>5306.899902</td>\n",
       "      <td>-0.056834</td>\n",
       "      <td>0.113898</td>\n",
       "      <td>5281.799805</td>\n",
       "      <td>35.199707</td>\n",
       "      <td>5282.299805</td>\n",
       "      <td>5221.100098</td>\n",
       "      <td>-0.074456</td>\n",
       "      <td>0.108388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.2</td>\n",
       "      <td>3828.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.7517</td>\n",
       "      <td>63500000.0</td>\n",
       "      <td>90.544594</td>\n",
       "      <td>91.341998</td>\n",
       "      <td>90.991309</td>\n",
       "      <td>92.573106</td>\n",
       "      <td>89.675330</td>\n",
       "      <td>88.864985</td>\n",
       "      <td>100.033999</td>\n",
       "      <td>417044.0</td>\n",
       "      <td>1.124840</td>\n",
       "      <td>61.122687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4147.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>38.947368</td>\n",
       "      <td>7.392109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>47.368421</td>\n",
       "      <td>7.965580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>43.157895</td>\n",
       "      <td>8.978208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>26.315789</td>\n",
       "      <td>6.024019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>22.105263</td>\n",
       "      <td>4.174630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>26.315789</td>\n",
       "      <td>5.414882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCA</td>\n",
       "      <td>2016-07-06</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.575</td>\n",
       "      <td>578900</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.105769</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.475</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.025424</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.042965</td>\n",
       "      <td>0.472070</td>\n",
       "      <td>0.643930</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>0.472070</td>\n",
       "      <td>0.643930</td>\n",
       "      <td>Steady</td>\n",
       "      <td>Within</td>\n",
       "      <td>5312.799805</td>\n",
       "      <td>-52.400390</td>\n",
       "      <td>5312.799805</td>\n",
       "      <td>5237.799805</td>\n",
       "      <td>-0.066046</td>\n",
       "      <td>0.103019</td>\n",
       "      <td>5228.000000</td>\n",
       "      <td>-53.799805</td>\n",
       "      <td>5228.000000</td>\n",
       "      <td>5148.700195</td>\n",
       "      <td>-0.083884</td>\n",
       "      <td>0.097098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.2</td>\n",
       "      <td>3828.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-30.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>63500000.0</td>\n",
       "      <td>90.544594</td>\n",
       "      <td>91.341998</td>\n",
       "      <td>90.991309</td>\n",
       "      <td>92.573106</td>\n",
       "      <td>89.675330</td>\n",
       "      <td>88.864985</td>\n",
       "      <td>100.033999</td>\n",
       "      <td>417044.0</td>\n",
       "      <td>1.124840</td>\n",
       "      <td>61.122687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4147.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-67.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>14.782609</td>\n",
       "      <td>2.619778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.487370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>0.940744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>4.347826</td>\n",
       "      <td>1.010167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-6.086957</td>\n",
       "      <td>-32.554628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>7.826087</td>\n",
       "      <td>1.607076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol   quoteDate  lastTradePriceOnly  adjustedPrice   volume  daysHigh  \\\n",
       "0    CCA  2016-06-30               0.560          0.560  1876700     0.770   \n",
       "1    CCA  2016-07-01               0.590          0.590   985000     0.625   \n",
       "2    CCA  2016-07-04               0.590          0.590   389500     0.595   \n",
       "3    CCA  2016-07-05               0.475          0.475   288500     0.590   \n",
       "4    CCA  2016-07-06               0.575          0.575   578900     0.580   \n",
       "\n",
       "   daysLow  previousClose  change  changeInPercent  52WeekHigh  52WeekLow  \\\n",
       "0    0.535          0.765  -0.205        -0.267974        0.56      0.560   \n",
       "1    0.500          0.515   0.075         0.145631        0.59      0.560   \n",
       "2    0.555          0.565   0.025         0.044248        0.59      0.560   \n",
       "3    0.475          0.590  -0.115        -0.194915        0.59      0.475   \n",
       "4    0.520          0.520   0.055         0.105769        0.59      0.475   \n",
       "\n",
       "   changeFrom52WeekHigh  changeFrom52WeekLow  percebtChangeFrom52WeekHigh  \\\n",
       "0                   NaN                  NaN                          NaN   \n",
       "1                 0.000                 0.03                     0.000000   \n",
       "2                 0.000                 0.03                     0.000000   \n",
       "3                -0.115                 0.00                    -0.194915   \n",
       "4                -0.015                 0.10                    -0.025424   \n",
       "\n",
       "   percentChangeFrom52WeekLow  Price200DayAverage  Price52WeekPercChange  \\\n",
       "0                         NaN                 NaN                    NaN   \n",
       "1                    0.053571                 NaN                    NaN   \n",
       "2                    0.053571                 NaN                    NaN   \n",
       "3                    0.000000                 NaN                    NaN   \n",
       "4                    0.210526                 NaN                    NaN   \n",
       "\n",
       "   1WeekVolatility  2WeekVolatility  4WeekVolatility  8WeekVolatility  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1         0.015000         0.015000         0.015000         0.015000   \n",
       "2         0.014142         0.014142         0.014142         0.014142   \n",
       "3         0.047087         0.047087         0.047087         0.047087   \n",
       "4         0.042965         0.042965         0.042965         0.042965   \n",
       "\n",
       "   12WeekVolatility  26WeekVolatility  52WeekVolatility  \\\n",
       "0               NaN               NaN               NaN   \n",
       "1          0.015000          0.015000          0.015000   \n",
       "2          0.014142          0.014142          0.014142   \n",
       "3          0.047087          0.047087          0.047087   \n",
       "4          0.042965          0.042965          0.042965   \n",
       "\n",
       "   4WeekBollingerBandLower  4WeekBollingerBandUpper 4WeekBollingerPrediction  \\\n",
       "0                 0.560000                 0.560000                   Steady   \n",
       "1                 0.545000                 0.605000                   Steady   \n",
       "2                 0.551716                 0.608284                   Steady   \n",
       "3                 0.459576                 0.647924                   Steady   \n",
       "4                 0.472070                 0.643930                   Steady   \n",
       "\n",
       "  4WeekBollingerType  12WeekBollingerBandLower  12WeekBollingerBandUpper  \\\n",
       "0             Within                  0.560000                  0.560000   \n",
       "1             Within                  0.545000                  0.605000   \n",
       "2             Within                  0.551716                  0.608284   \n",
       "3             Within                  0.459576                  0.647924   \n",
       "4             Within                  0.472070                  0.643930   \n",
       "\n",
       "  12WeekBollingerPrediction 12WeekBollingerType  allordpreviousclose  \\\n",
       "0                    Steady              Within          5221.000000   \n",
       "1                    Steady              Within          5310.399902   \n",
       "2                    Steady              Within          5327.100098   \n",
       "3                    Steady              Within          5365.200195   \n",
       "4                    Steady              Within          5312.799805   \n",
       "\n",
       "   allordchange  allorddayshigh  allorddayslow  \\\n",
       "0     41.299805     5324.399902    5221.000000   \n",
       "1     89.399902     5356.500000    5310.399902   \n",
       "2     16.700196     5365.200195    5303.100098   \n",
       "3     38.100097     5365.899902    5306.899902   \n",
       "4    -52.400390     5312.799805    5237.799805   \n",
       "\n",
       "   allordpercebtChangeFrom52WeekHigh  allordpercentChangeFrom52WeekLow  \\\n",
       "0                          -0.082183                          0.083960   \n",
       "1                          -0.066467                          0.102520   \n",
       "2                          -0.063532                          0.105988   \n",
       "3                          -0.056834                          0.113898   \n",
       "4                          -0.066046                          0.103019   \n",
       "\n",
       "   asxpreviousclose  asxchange  asxdayshigh   asxdayslow  \\\n",
       "0       5142.399902  39.100097  5247.600098  5142.399902   \n",
       "1       5233.399902  91.000000  5278.899902  5233.399902   \n",
       "2       5246.600098  13.200196  5281.799805  5218.500000   \n",
       "3       5281.799805  35.199707  5282.299805  5221.100098   \n",
       "4       5228.000000 -53.799805  5228.000000  5148.700195   \n",
       "\n",
       "   asxpercebtChangeFrom52WeekHigh  asxpercentChangeFrom52WeekLow  \\\n",
       "0                       -0.098884                       0.079135   \n",
       "1                       -0.082938                       0.098231   \n",
       "2                       -0.080625                       0.101001   \n",
       "3                       -0.074456                       0.108388   \n",
       "4                       -0.083884                       0.097098   \n",
       "\n",
       "  exDividendDate  exDividendPayout  640106_A3597525W  AINTCOV  AverageVolume  \\\n",
       "0            NaN               NaN             108.2   3828.0            NaN   \n",
       "1            NaN               NaN             108.2   3828.0            NaN   \n",
       "2            NaN               NaN             108.2   3828.0            NaN   \n",
       "3            NaN               NaN             108.2   3828.0            NaN   \n",
       "4            NaN               NaN             108.2   3828.0            NaN   \n",
       "\n",
       "   Beta  BookValuePerShareYear  CashPerShareYear  DPSRecentYear  EBITDMargin  \\\n",
       "0   NaN                   0.24            -0.213            NaN          NaN   \n",
       "1   NaN                   0.24            -0.213            0.0          NaN   \n",
       "2   NaN                   0.24            -0.213            0.0          NaN   \n",
       "3   NaN                   0.24            -0.213            0.0          NaN   \n",
       "4   NaN                   0.24            -0.213            0.0          NaN   \n",
       "\n",
       "    EPS  EPSGrowthRate10Years  EPSGrowthRate5Years  FIRMMCRT  FXRUSD  \\\n",
       "0 -30.8                   NaN                  NaN      1.77  0.7426   \n",
       "1 -30.8                   NaN                  NaN      1.77  0.7460   \n",
       "2 -30.8                   NaN                  NaN      1.77  0.7506   \n",
       "3 -30.8                   NaN                  NaN      1.77  0.7517   \n",
       "4 -30.8                   NaN                  NaN      1.77  0.7436   \n",
       "\n",
       "        Float   GRCPAIAD  GRCPAISAD   GRCPBCAD  GRCPBCSAD   GRCPBMAD  \\\n",
       "0  63500000.0  87.307409  89.957900  87.425456  92.706255  87.037799   \n",
       "1  63500000.0  87.307409  89.957900  87.425456  92.706255  87.037799   \n",
       "2  63500000.0  90.544594  91.341998  90.991309  92.573106  89.675330   \n",
       "3  63500000.0  90.544594  91.341998  90.991309  92.573106  89.675330   \n",
       "4  63500000.0  90.544594  91.341998  90.991309  92.573106  89.675330   \n",
       "\n",
       "    GRCPNRAD    GRCPRCAD  H01_GGDPCVGDP  H01_GGDPCVGDPFY  H05_GLFSEPTPOP  IAD  \\\n",
       "0  85.756318   96.070719       412937.0         1.227102       61.092677  NaN   \n",
       "1  85.756318   96.070719       412937.0         1.227102       61.092677  NaN   \n",
       "2  88.864985  100.033999       417044.0         1.124840       61.122687  NaN   \n",
       "3  88.864985  100.033999       417044.0         1.124840       61.122687  NaN   \n",
       "4  88.864985  100.033999       417044.0         1.124840       61.122687  NaN   \n",
       "\n",
       "   LTDebtToEquityQuarter  LTDebtToEquityYear   MarketCap  \\\n",
       "0                    NaN                 NaN  36000000.0   \n",
       "1                    NaN                 NaN  36000000.0   \n",
       "2                    NaN                 NaN  36000000.0   \n",
       "3                    NaN                 NaN  36000000.0   \n",
       "4                    NaN                 NaN  36000000.0   \n",
       "\n",
       "   NetIncomeGrowthRate5Years  NetProfitMarginPercent  OperatingMargin   PE  \\\n",
       "0                        NaN                     NaN          -4147.2  NaN   \n",
       "1                        NaN                     NaN          -4147.2  0.0   \n",
       "2                        NaN                     NaN          -4147.2  0.0   \n",
       "3                        NaN                     NaN          -4147.2  0.0   \n",
       "4                        NaN                     NaN          -4147.2  0.0   \n",
       "\n",
       "   PriceToBook  QuoteLast  ReturnOnAssets5Years  ReturnOnAssetsTTM  \\\n",
       "0          NaN        NaN                   NaN                NaN   \n",
       "1          NaN        NaN                   NaN                NaN   \n",
       "2          NaN        NaN                   NaN                NaN   \n",
       "3          NaN        NaN                   NaN                NaN   \n",
       "4          NaN        NaN                   NaN                NaN   \n",
       "\n",
       "   ReturnOnAssetsYear  ReturnOnEquity5Years  ReturnOnEquityTTM  \\\n",
       "0                 NaN                   NaN                NaN   \n",
       "1                 NaN                   NaN                NaN   \n",
       "2                 NaN                   NaN                NaN   \n",
       "3                 NaN                   NaN                NaN   \n",
       "4                 NaN                   NaN                NaN   \n",
       "\n",
       "   ReturnOnEquityYear  RevenueGrowthRate10Years  RevenueGrowthRate5Years  \\\n",
       "0               -67.4                       NaN                      NaN   \n",
       "1               -67.4                       NaN                      NaN   \n",
       "2               -67.4                       NaN                      NaN   \n",
       "3               -67.4                       NaN                      NaN   \n",
       "4               -67.4                       NaN                      NaN   \n",
       "\n",
       "   TotalDebtToAssetsQuarter  TotalDebtToAssetsYear  TotalDebtToEquityQuarter  \\\n",
       "0                       NaN                    NaN                       NaN   \n",
       "1                       NaN                    NaN                       NaN   \n",
       "2                       NaN                    NaN                       NaN   \n",
       "3                       NaN                    NaN                       NaN   \n",
       "4                       NaN                    NaN                       NaN   \n",
       "\n",
       "   TotalDebtToEquityYear  bookValue  earningsPerShare  ebitda  \\\n",
       "0                    NaN        NaN               NaN     NaN   \n",
       "1                    0.0        NaN               NaN     NaN   \n",
       "2                    0.0        NaN               NaN     NaN   \n",
       "3                    0.0        NaN               NaN     NaN   \n",
       "4                    0.0        NaN               NaN     NaN   \n",
       "\n",
       "   epsEstimateCurrentYear  marketCapitalization  peRatio  pegRatio  \\\n",
       "0                     NaN                   NaN      NaN       NaN   \n",
       "1                     NaN                   NaN      NaN       NaN   \n",
       "2                     NaN                   NaN      NaN       NaN   \n",
       "3                     NaN                   NaN      NaN       NaN   \n",
       "4                     NaN                   NaN      NaN       NaN   \n",
       "\n",
       "   pricePerBook  pricePerEpsEstimateCurrentYear  pricePerEpsEstimateNextYear  \\\n",
       "0           NaN                             NaN                          NaN   \n",
       "1           NaN                             NaN                          NaN   \n",
       "2           NaN                             NaN                          NaN   \n",
       "3           NaN                             NaN                          NaN   \n",
       "4           NaN                             NaN                          NaN   \n",
       "\n",
       "   pricePerSales  Future1WeekDividend  Future1WeekPrice  Future1WeekReturn  \\\n",
       "0            NaN                  NaN              0.55          -1.785714   \n",
       "1            NaN                  0.0              0.54          -8.474576   \n",
       "2            NaN                  0.0              0.66          11.864407   \n",
       "3            NaN                  0.0              0.66          38.947368   \n",
       "4            NaN                  0.0              0.66          14.782609   \n",
       "\n",
       "   Future1WeekRiskAdjustedReturn  Future2WeekDividend  Future2WeekPrice  \\\n",
       "0                      -7.688946                  NaN              0.65   \n",
       "1                     -33.621753                  0.0              0.65   \n",
       "2                       1.980153                  0.0              0.73   \n",
       "3                       7.392109                  0.0              0.70   \n",
       "4                       2.619778                  0.0              0.69   \n",
       "\n",
       "   Future2WeekReturn  Future2WeekRiskAdjustedReturn  Future4WeekDividend  \\\n",
       "0          16.071429                       2.693578                  NaN   \n",
       "1          10.169492                       1.644524                  0.0   \n",
       "2          23.728814                       3.265570                  0.0   \n",
       "3          47.368421                       7.965580                  0.0   \n",
       "4          20.000000                       3.487370                  0.0   \n",
       "\n",
       "   Future4WeekPrice  Future4WeekReturn  Future4WeekRiskAdjustedReturn  \\\n",
       "0              0.64          14.285714                       2.260607   \n",
       "1              0.67          13.559322                       2.167481   \n",
       "2              0.68          15.254237                       2.464773   \n",
       "3              0.68          43.157895                       8.978208   \n",
       "4              0.60           4.347826                       0.940744   \n",
       "\n",
       "   Future8WeekDividend  Future8WeekPrice  Future8WeekReturn  \\\n",
       "0                  NaN              0.61           8.928571   \n",
       "1                  0.0              0.60           1.694915   \n",
       "2                  0.0              0.57          -3.389831   \n",
       "3                  0.0              0.60          26.315789   \n",
       "4                  0.0              0.60           4.347826   \n",
       "\n",
       "   Future8WeekRiskAdjustedReturn  Future12WeekDividend  Future12WeekPrice  \\\n",
       "0                       1.801456                   NaN               0.54   \n",
       "1                       0.343165                   0.0               0.52   \n",
       "2                     -16.909912                   0.0               0.56   \n",
       "3                       6.024019                   0.0               0.58   \n",
       "4                       1.010167                   0.0               0.54   \n",
       "\n",
       "   Future12WeekReturn  Future12WeekRiskAdjustedReturn  Future26WeekDividend  \\\n",
       "0           -3.571429                      -19.327464                   NaN   \n",
       "1          -11.864407                      -65.487513                   0.0   \n",
       "2           -5.084746                      -28.202774                   0.0   \n",
       "3           22.105263                        4.174630                   0.0   \n",
       "4           -6.086957                      -32.554628                   0.0   \n",
       "\n",
       "   Future26WeekPrice  Future26WeekReturn  Future26WeekRiskAdjustedReturn  \\\n",
       "0               0.56                 NaN                             NaN   \n",
       "1               0.56           -5.084746                      -25.146688   \n",
       "2               0.56           -5.084746                      -25.164750   \n",
       "3               0.60           26.315789                        5.414882   \n",
       "4               0.62            7.826087                        1.607076   \n",
       "\n",
       "   Future52WeekDividend  Future52WeekPrice  Future52WeekReturn  \\\n",
       "0                   NaN                NaN                 NaN   \n",
       "1                   NaN                NaN                 NaN   \n",
       "2                   NaN                NaN                 NaN   \n",
       "3                   NaN                NaN                 NaN   \n",
       "4                   NaN                NaN                 NaN   \n",
       "\n",
       "   Future52WeekRiskAdjustedReturn  \n",
       "0                             NaN  \n",
       "1                             NaN  \n",
       "2                             NaN  \n",
       "3                             NaN  \n",
       "4                             NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy import stats\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "\n",
    "# Define columns\n",
    "data_columns = ['symbol', 'quoteDate', 'adjustedPrice', 'volume', 'previousClose', 'change', 'changeInPercent', \n",
    "                '52WeekHigh', '52WeekLow', 'changeFrom52WeekHigh', 'changeFrom52WeekLow', \n",
    "                'percebtChangeFrom52WeekHigh', 'percentChangeFrom52WeekLow', 'Price200DayAverage', \n",
    "                'Price52WeekPercChange', '1WeekVolatility', '2WeekVolatility', '4WeekVolatility', '8WeekVolatility', \n",
    "                '12WeekVolatility', '26WeekVolatility','52WeekVolatility','4WeekBollingerPrediction', '4WeekBollingerType',\n",
    "                '12WeekBollingerPrediction', '12WeekBollingerType', 'allordpreviousclose', 'allordchange', \n",
    "                'allorddayshigh', 'allorddayslow', 'allordpercebtChangeFrom52WeekHigh', \n",
    "                'allordpercentChangeFrom52WeekLow', 'asxpreviousclose', 'asxchange', 'asxdayshigh', \n",
    "                'asxdayslow', 'asxpercebtChangeFrom52WeekHigh', 'asxpercentChangeFrom52WeekLow', 'exDividendDate', \n",
    "                'exDividendPayout', '640106_A3597525W', 'AINTCOV', 'AverageVolume', 'BookValuePerShareYear', \n",
    "                'CashPerShareYear', 'DPSRecentYear', 'EBITDMargin', 'EPS', 'EPSGrowthRate10Years', \n",
    "                'EPSGrowthRate5Years', 'FIRMMCRT', 'FXRUSD', 'Float', 'GRCPAIAD', 'GRCPAISAD', 'GRCPBCAD', \n",
    "                'GRCPBCSAD', 'GRCPBMAD', 'GRCPNRAD', 'GRCPRCAD', 'H01_GGDPCVGDP', 'H01_GGDPCVGDPFY', 'H05_GLFSEPTPOP', \n",
    "                'IAD', 'LTDebtToEquityQuarter', 'LTDebtToEquityYear', 'MarketCap',\n",
    "                'NetIncomeGrowthRate5Years', 'NetProfitMarginPercent', 'OperatingMargin', 'PE',\n",
    "                'PriceToBook', 'ReturnOnAssets5Years', 'ReturnOnAssetsTTM', 'ReturnOnAssetsYear', \n",
    "                'ReturnOnEquity5Years', 'ReturnOnEquityTTM', 'ReturnOnEquityYear', 'RevenueGrowthRate10Years', \n",
    "                'RevenueGrowthRate5Years', 'TotalDebtToAssetsQuarter', 'TotalDebtToAssetsYear', \n",
    "                'TotalDebtToEquityQuarter', 'TotalDebtToEquityYear', 'bookValue', 'earningsPerShare', \n",
    "                'ebitda', 'epsEstimateCurrentYear', 'marketCapitalization', 'peRatio', 'pegRatio', 'pricePerBook', \n",
    "                'pricePerEpsEstimateCurrentYear', 'pricePerEpsEstimateNextYear', 'pricePerSales']\n",
    "\n",
    "selected_columns = ['symbol', 'adjustedPrice', 'volume', 'previousClose', 'change', \n",
    "                    '52WeekHigh', '52WeekLow', 'changeFrom52WeekHigh', 'changeFrom52WeekLow', \n",
    "                    'percebtChangeFrom52WeekHigh', 'percentChangeFrom52WeekLow', 'Price200DayAverage', \n",
    "                    'Price52WeekPercChange', '1WeekVolatility', '2WeekVolatility', '4WeekVolatility', '8WeekVolatility', \n",
    "                    '12WeekVolatility', '26WeekVolatility','52WeekVolatility','4WeekBollingerPrediction', '4WeekBollingerType',\n",
    "                    '12WeekBollingerPrediction', '12WeekBollingerType', 'allordchange', \n",
    "                    'allorddayshigh', 'allorddayslow', 'allordpercebtChangeFrom52WeekHigh', \n",
    "                    'allordpercentChangeFrom52WeekLow', 'asxchange', 'asxdayshigh', \n",
    "                    'asxdayslow', 'asxpercebtChangeFrom52WeekHigh', 'asxpercentChangeFrom52WeekLow', 'AverageVolume', \n",
    "                    'EBITDMargin', 'EPSGrowthRate10Years', 'EPSGrowthRate5Years', 'FIRMMCRT', 'FXRUSD', 'Float', \n",
    "                    'GRCPAIAD', 'GRCPBCAD', 'GRCPBMAD', 'GRCPNRAD', 'GRCPRCAD', 'H01_GGDPCVGDPFY', 'H05_GLFSEPTPOP', \n",
    "                    'IAD', 'LTDebtToEquityQuarter', 'LTDebtToEquityYear', 'MarketCap',\n",
    "                    'NetIncomeGrowthRate5Years', 'NetProfitMarginPercent', \n",
    "                    'PriceToBook', 'ReturnOnAssets5Years', 'ReturnOnAssetsTTM', 'ReturnOnAssetsYear', \n",
    "                    'ReturnOnEquity5Years', 'ReturnOnEquityTTM', 'RevenueGrowthRate10Years', \n",
    "                    'RevenueGrowthRate5Years', 'TotalDebtToAssetsQuarter', 'TotalDebtToAssetsYear', \n",
    "                    'TotalDebtToEquityQuarter', 'bookValue', 'earningsPerShare', \n",
    "                    'ebitda', 'epsEstimateCurrentYear', 'marketCapitalization', 'peRatio', 'pegRatio', 'pricePerBook', \n",
    "                    'pricePerEpsEstimateCurrentYear', 'pricePerEpsEstimateNextYear', 'pricePerSales']\n",
    "\n",
    "\n",
    "returns = {\n",
    "    '1': 'Future1WeekReturn',\n",
    "    '2': 'Future2WeekReturn',\n",
    "    '4': 'Future4WeekReturn',\n",
    "    '8': 'Future8WeekReturn',\n",
    "    '12': 'Future12WeekReturn',\n",
    "    '26': 'Future26WeekReturn',\n",
    "    '52': 'Future52WeekReturn',\n",
    "    '1ra': 'Future1WeekRiskAdjustedReturn',\n",
    "    '2ra': 'Future2WeekRiskAdjustedReturn',\n",
    "    '4ra': 'Future4WeekRiskAdjustedReturn',\n",
    "    '8ra': 'Future8WeekRiskAdjustedReturn',\n",
    "    '12ra': 'Future12WeekRiskAdjustedReturn',\n",
    "    '26ra': 'Future26WeekRiskAdjustedReturn',\n",
    "    '52ra': 'Future52WeekRiskAdjustedReturn'\n",
    "}\n",
    "\n",
    "# Load data\n",
    "raw_data = pd.read_csv('data/companyQuotes-20170417-001.csv')\n",
    "raw_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clip values less than -99 (represents losing all money, can't go below -100)\n",
    "for key in returns:\n",
    "    return_column = returns[key]\n",
    "    raw_data[return_column] = raw_data[return_column].clip(-99, 999, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot values for each potential target\n",
    "for key in returns:\n",
    "    print('-----')\n",
    "    return_column = returns[key]\n",
    "    print(return_column)\n",
    "    raw_data.hist(column=return_column,bins=[-50, -45, -40, -35, -30, -25, -20, -15, -10, -5, 0, \n",
    "                                            5, 10, 15, 20, 25, 30, 35, 40, 45, 50])\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "    print('Instances: ', raw_data[return_column].count())\n",
    "    print('Mean: ', raw_data[return_column].mean())\n",
    "    print('Min: ', raw_data[return_column].min())\n",
    "    print('25th percentile: ', raw_data[return_column].quantile(0.25))\n",
    "    print('Median: ', raw_data[return_column].median())\n",
    "    print('75th percentile: ', raw_data[return_column].quantile(0.75))\n",
    "    print('Max: ', raw_data[return_column].max())\n",
    "    print('Std deviation: ', raw_data[return_column].std())\n",
    "    print('Variance: ', raw_data[return_column].var())\n",
    "    print('Skew: ', raw_data[return_column].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check outliers\n",
    "outliers = raw_data.loc[(raw_data[target_column] > 100) | (raw_data[target_column] < -50)]\n",
    "print(len(outliers))\n",
    "\n",
    "exclude_symbols = outliers['symbol'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove rows in the excluded symbols list\n",
    "filtered_data = raw_data[~raw_data['symbol'].isin(exclude_symbols)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply filter for specific symbolx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run filter for a few companies\n",
    "include_symbols = ['BHP', 'CBA', 'AOU', 'AYS', 'ATT', 'A01', 'BUD', 'AAP', 'AIV', 'AIB', '4DS']\n",
    "reduced_data = raw_data[raw_data['symbol'].isin(include_symbols)]\n",
    "print(len(reduced_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_data = reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Re-plot values for each potential target\n",
    "for key in returns:\n",
    "    print('-----')\n",
    "    return_column = returns[key]\n",
    "    print(return_column)\n",
    "    filtered_data.hist(column=return_column,bins=[-50, -45, -40, -35, -30, -25, -20, -15, -10, -5, 0,\n",
    "                                                  5, 10, 15, 20, 25, 30, 35, 40, 45, 50])\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "    print('Instances: ', filtered_data[return_column].count())\n",
    "    print('Mean: ', filtered_data[return_column].mean())\n",
    "    print('Min: ', filtered_data[return_column].min())\n",
    "    print('25th percentile: ', filtered_data[return_column].quantile(0.25))\n",
    "    print('Median: ', filtered_data[return_column].median())\n",
    "    print('75th percentile: ', filtered_data[return_column].quantile(0.75))\n",
    "    print('Max: ', filtered_data[return_column].max())\n",
    "    print('Std deviation: ', filtered_data[return_column].std())\n",
    "    print('Variance: ', filtered_data[return_column].var())\n",
    "    print('Skew: ', filtered_data[return_column].skew())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_data = raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up learning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set target column\n",
    "target_column = returns['8']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove rows missing the target column\n",
    "filtered_data = filtered_data.dropna(subset=[target_column], how='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     8.928571\n",
      "1     1.694915\n",
      "2    -3.389831\n",
      "3    26.315789\n",
      "4     4.347826\n",
      "Name: Future8WeekReturn, dtype: float64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a6f150f5507c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mshift_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_shift_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshift_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-a6f150f5507c>\u001b[0m in \u001b[0;36mget_shift_value\u001b[0;34m(data_frame)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmin_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin_val\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mshift_val\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmin_val\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "# Use natural log to reduce spread of nums (only works for positive numbers)\n",
    "import math\n",
    "\n",
    "shift_val = 0\n",
    "\n",
    "def get_shift_value(data_frame):\n",
    "    # if the minimum value is < 1, shift all the values to make them >= 1\n",
    "    min_val = min(data_frame.values)\n",
    "    if min_val < 1:\n",
    "        return (min_val * -1) + 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "print(filtered_data[target_column].head(5))\n",
    "    \n",
    "shift_val = get_shift_value(filtered_data[target_column])\n",
    "print(shift_val)\n",
    "\n",
    "filtered_data[target_column] = filtered_data[target_column].add(shift_val)\n",
    "\n",
    "print(filtered_data[target_column].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbol                                object\n",
      "quoteDate                             object\n",
      "adjustedPrice                        float64\n",
      "volume                                 int64\n",
      "previousClose                        float64\n",
      "change                               float64\n",
      "changeInPercent                      float64\n",
      "52WeekHigh                           float64\n",
      "52WeekLow                            float64\n",
      "changeFrom52WeekHigh                 float64\n",
      "changeFrom52WeekLow                  float64\n",
      "percebtChangeFrom52WeekHigh          float64\n",
      "percentChangeFrom52WeekLow           float64\n",
      "Price200DayAverage                   float64\n",
      "Price52WeekPercChange                float64\n",
      "1WeekVolatility                      float64\n",
      "2WeekVolatility                      float64\n",
      "4WeekVolatility                      float64\n",
      "8WeekVolatility                      float64\n",
      "12WeekVolatility                     float64\n",
      "26WeekVolatility                     float64\n",
      "52WeekVolatility                     float64\n",
      "4WeekBollingerPrediction              object\n",
      "4WeekBollingerType                    object\n",
      "12WeekBollingerPrediction             object\n",
      "12WeekBollingerType                   object\n",
      "allordpreviousclose                  float64\n",
      "allordchange                         float64\n",
      "allorddayshigh                       float64\n",
      "allorddayslow                        float64\n",
      "allordpercebtChangeFrom52WeekHigh    float64\n",
      "allordpercentChangeFrom52WeekLow     float64\n",
      "asxpreviousclose                     float64\n",
      "asxchange                            float64\n",
      "asxdayshigh                          float64\n",
      "asxdayslow                           float64\n",
      "asxpercebtChangeFrom52WeekHigh       float64\n",
      "asxpercentChangeFrom52WeekLow        float64\n",
      "exDividendDate                        object\n",
      "exDividendPayout                     float64\n",
      "640106_A3597525W                     float64\n",
      "AINTCOV                              float64\n",
      "AverageVolume                        float64\n",
      "BookValuePerShareYear                float64\n",
      "CashPerShareYear                     float64\n",
      "DPSRecentYear                        float64\n",
      "EBITDMargin                          float64\n",
      "EPS                                  float64\n",
      "EPSGrowthRate10Years                 float64\n",
      "EPSGrowthRate5Years                  float64\n",
      "FIRMMCRT                             float64\n",
      "FXRUSD                               float64\n",
      "Float                                float64\n",
      "GRCPAIAD                             float64\n",
      "GRCPAISAD                            float64\n",
      "GRCPBCAD                             float64\n",
      "GRCPBCSAD                            float64\n",
      "GRCPBMAD                             float64\n",
      "GRCPNRAD                             float64\n",
      "GRCPRCAD                             float64\n",
      "H01_GGDPCVGDP                        float64\n",
      "H01_GGDPCVGDPFY                      float64\n",
      "H05_GLFSEPTPOP                       float64\n",
      "IAD                                  float64\n",
      "LTDebtToEquityQuarter                float64\n",
      "LTDebtToEquityYear                   float64\n",
      "MarketCap                            float64\n",
      "NetIncomeGrowthRate5Years            float64\n",
      "NetProfitMarginPercent               float64\n",
      "OperatingMargin                      float64\n",
      "PE                                   float64\n",
      "PriceToBook                          float64\n",
      "ReturnOnAssets5Years                 float64\n",
      "ReturnOnAssetsTTM                    float64\n",
      "ReturnOnAssetsYear                   float64\n",
      "ReturnOnEquity5Years                 float64\n",
      "ReturnOnEquityTTM                    float64\n",
      "ReturnOnEquityYear                   float64\n",
      "RevenueGrowthRate10Years             float64\n",
      "RevenueGrowthRate5Years              float64\n",
      "TotalDebtToAssetsQuarter             float64\n",
      "TotalDebtToAssetsYear                float64\n",
      "TotalDebtToEquityQuarter             float64\n",
      "TotalDebtToEquityYear                float64\n",
      "bookValue                            float64\n",
      "earningsPerShare                     float64\n",
      "ebitda                               float64\n",
      "epsEstimateCurrentYear               float64\n",
      "marketCapitalization                 float64\n",
      "peRatio                              float64\n",
      "pegRatio                             float64\n",
      "pricePerBook                         float64\n",
      "pricePerEpsEstimateCurrentYear       float64\n",
      "pricePerEpsEstimateNextYear          float64\n",
      "pricePerSales                        float64\n",
      "dtype: object\n",
      "Min: 0.0 , Max: 13.5369876762\n"
     ]
    }
   ],
   "source": [
    "# Create y_data\n",
    "y_data = filtered_data[target_column].values\n",
    "\n",
    "\n",
    "# Filter down data to the X columns being used\n",
    "filtered_data = filtered_data[data_columns]\n",
    "\n",
    "\n",
    "print(filtered_data.dtypes)\n",
    "\n",
    "print('Min:',min(y_data),', Max:', max(y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert non-numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  symbol  quoteDate  adjustedPrice   volume  previousClose  change  \\\n",
      "0    CCA     736145          0.560  1876700          0.765  -0.205   \n",
      "1    CCA     736146          0.590   985000          0.515   0.075   \n",
      "2    CCA     736149          0.590   389500          0.565   0.025   \n",
      "3    CCA     736150          0.475   288500          0.590  -0.115   \n",
      "4    CCA     736151          0.575   578900          0.520   0.055   \n",
      "\n",
      "   changeInPercent  52WeekHigh  52WeekLow  changeFrom52WeekHigh  \\\n",
      "0        -0.267974        0.56      0.560                   NaN   \n",
      "1         0.145631        0.59      0.560                 0.000   \n",
      "2         0.044248        0.59      0.560                 0.000   \n",
      "3        -0.194915        0.59      0.475                -0.115   \n",
      "4         0.105769        0.59      0.475                -0.015   \n",
      "\n",
      "   changeFrom52WeekLow  percebtChangeFrom52WeekHigh  \\\n",
      "0                  NaN                          NaN   \n",
      "1                 0.03                     0.000000   \n",
      "2                 0.03                     0.000000   \n",
      "3                 0.00                    -0.194915   \n",
      "4                 0.10                    -0.025424   \n",
      "\n",
      "   percentChangeFrom52WeekLow  Price200DayAverage  Price52WeekPercChange  \\\n",
      "0                         NaN                 NaN                    NaN   \n",
      "1                    0.053571                 NaN                    NaN   \n",
      "2                    0.053571                 NaN                    NaN   \n",
      "3                    0.000000                 NaN                    NaN   \n",
      "4                    0.210526                 NaN                    NaN   \n",
      "\n",
      "   1WeekVolatility  2WeekVolatility  4WeekVolatility  8WeekVolatility  \\\n",
      "0              NaN              NaN              NaN              NaN   \n",
      "1         0.015000         0.015000         0.015000         0.015000   \n",
      "2         0.014142         0.014142         0.014142         0.014142   \n",
      "3         0.047087         0.047087         0.047087         0.047087   \n",
      "4         0.042965         0.042965         0.042965         0.042965   \n",
      "\n",
      "   12WeekVolatility  26WeekVolatility  52WeekVolatility  \\\n",
      "0               NaN               NaN               NaN   \n",
      "1          0.015000          0.015000          0.015000   \n",
      "2          0.014142          0.014142          0.014142   \n",
      "3          0.047087          0.047087          0.047087   \n",
      "4          0.042965          0.042965          0.042965   \n",
      "\n",
      "  4WeekBollingerPrediction 4WeekBollingerType 12WeekBollingerPrediction  \\\n",
      "0                   Steady             Within                    Steady   \n",
      "1                   Steady             Within                    Steady   \n",
      "2                   Steady             Within                    Steady   \n",
      "3                   Steady             Within                    Steady   \n",
      "4                   Steady             Within                    Steady   \n",
      "\n",
      "  12WeekBollingerType  allordpreviousclose  allordchange  allorddayshigh  \\\n",
      "0              Within          5221.000000     41.299805     5324.399902   \n",
      "1              Within          5310.399902     89.399902     5356.500000   \n",
      "2              Within          5327.100098     16.700196     5365.200195   \n",
      "3              Within          5365.200195     38.100097     5365.899902   \n",
      "4              Within          5312.799805    -52.400390     5312.799805   \n",
      "\n",
      "   allorddayslow  allordpercebtChangeFrom52WeekHigh  \\\n",
      "0    5221.000000                          -0.082183   \n",
      "1    5310.399902                          -0.066467   \n",
      "2    5303.100098                          -0.063532   \n",
      "3    5306.899902                          -0.056834   \n",
      "4    5237.799805                          -0.066046   \n",
      "\n",
      "   allordpercentChangeFrom52WeekLow  asxpreviousclose  asxchange  asxdayshigh  \\\n",
      "0                          0.083960       5142.399902  39.100097  5247.600098   \n",
      "1                          0.102520       5233.399902  91.000000  5278.899902   \n",
      "2                          0.105988       5246.600098  13.200196  5281.799805   \n",
      "3                          0.113898       5281.799805  35.199707  5282.299805   \n",
      "4                          0.103019       5228.000000 -53.799805  5228.000000   \n",
      "\n",
      "    asxdayslow  asxpercebtChangeFrom52WeekHigh  asxpercentChangeFrom52WeekLow  \\\n",
      "0  5142.399902                       -0.098884                       0.079135   \n",
      "1  5233.399902                       -0.082938                       0.098231   \n",
      "2  5218.500000                       -0.080625                       0.101001   \n",
      "3  5221.100098                       -0.074456                       0.108388   \n",
      "4  5148.700195                       -0.083884                       0.097098   \n",
      "\n",
      "   exDividendDate  exDividendPayout  640106_A3597525W  AINTCOV  AverageVolume  \\\n",
      "0          -99999               NaN             108.2   3828.0            NaN   \n",
      "1          -99999               NaN             108.2   3828.0            NaN   \n",
      "2          -99999               NaN             108.2   3828.0            NaN   \n",
      "3          -99999               NaN             108.2   3828.0            NaN   \n",
      "4          -99999               NaN             108.2   3828.0            NaN   \n",
      "\n",
      "   BookValuePerShareYear  CashPerShareYear  DPSRecentYear  EBITDMargin   EPS  \\\n",
      "0                   0.24            -0.213            NaN          NaN -30.8   \n",
      "1                   0.24            -0.213            0.0          NaN -30.8   \n",
      "2                   0.24            -0.213            0.0          NaN -30.8   \n",
      "3                   0.24            -0.213            0.0          NaN -30.8   \n",
      "4                   0.24            -0.213            0.0          NaN -30.8   \n",
      "\n",
      "   EPSGrowthRate10Years  EPSGrowthRate5Years  FIRMMCRT  FXRUSD       Float  \\\n",
      "0                   NaN                  NaN      1.77  0.7426  63500000.0   \n",
      "1                   NaN                  NaN      1.77  0.7460  63500000.0   \n",
      "2                   NaN                  NaN      1.77  0.7506  63500000.0   \n",
      "3                   NaN                  NaN      1.77  0.7517  63500000.0   \n",
      "4                   NaN                  NaN      1.77  0.7436  63500000.0   \n",
      "\n",
      "    GRCPAIAD  GRCPAISAD   GRCPBCAD  GRCPBCSAD   GRCPBMAD   GRCPNRAD  \\\n",
      "0  87.307409  89.957900  87.425456  92.706255  87.037799  85.756318   \n",
      "1  87.307409  89.957900  87.425456  92.706255  87.037799  85.756318   \n",
      "2  90.544594  91.341998  90.991309  92.573106  89.675330  88.864985   \n",
      "3  90.544594  91.341998  90.991309  92.573106  89.675330  88.864985   \n",
      "4  90.544594  91.341998  90.991309  92.573106  89.675330  88.864985   \n",
      "\n",
      "     GRCPRCAD  H01_GGDPCVGDP  H01_GGDPCVGDPFY  H05_GLFSEPTPOP  IAD  \\\n",
      "0   96.070719       412937.0         1.227102       61.092677  NaN   \n",
      "1   96.070719       412937.0         1.227102       61.092677  NaN   \n",
      "2  100.033999       417044.0         1.124840       61.122687  NaN   \n",
      "3  100.033999       417044.0         1.124840       61.122687  NaN   \n",
      "4  100.033999       417044.0         1.124840       61.122687  NaN   \n",
      "\n",
      "   LTDebtToEquityQuarter  LTDebtToEquityYear   MarketCap  \\\n",
      "0                    NaN                 NaN  36000000.0   \n",
      "1                    NaN                 NaN  36000000.0   \n",
      "2                    NaN                 NaN  36000000.0   \n",
      "3                    NaN                 NaN  36000000.0   \n",
      "4                    NaN                 NaN  36000000.0   \n",
      "\n",
      "   NetIncomeGrowthRate5Years  NetProfitMarginPercent  OperatingMargin   PE  \\\n",
      "0                        NaN                     NaN          -4147.2  NaN   \n",
      "1                        NaN                     NaN          -4147.2  0.0   \n",
      "2                        NaN                     NaN          -4147.2  0.0   \n",
      "3                        NaN                     NaN          -4147.2  0.0   \n",
      "4                        NaN                     NaN          -4147.2  0.0   \n",
      "\n",
      "   PriceToBook  ReturnOnAssets5Years  ReturnOnAssetsTTM  ReturnOnAssetsYear  \\\n",
      "0          NaN                   NaN                NaN                 NaN   \n",
      "1          NaN                   NaN                NaN                 NaN   \n",
      "2          NaN                   NaN                NaN                 NaN   \n",
      "3          NaN                   NaN                NaN                 NaN   \n",
      "4          NaN                   NaN                NaN                 NaN   \n",
      "\n",
      "   ReturnOnEquity5Years  ReturnOnEquityTTM  ReturnOnEquityYear  \\\n",
      "0                   NaN                NaN               -67.4   \n",
      "1                   NaN                NaN               -67.4   \n",
      "2                   NaN                NaN               -67.4   \n",
      "3                   NaN                NaN               -67.4   \n",
      "4                   NaN                NaN               -67.4   \n",
      "\n",
      "   RevenueGrowthRate10Years  RevenueGrowthRate5Years  \\\n",
      "0                       NaN                      NaN   \n",
      "1                       NaN                      NaN   \n",
      "2                       NaN                      NaN   \n",
      "3                       NaN                      NaN   \n",
      "4                       NaN                      NaN   \n",
      "\n",
      "   TotalDebtToAssetsQuarter  TotalDebtToAssetsYear  TotalDebtToEquityQuarter  \\\n",
      "0                       NaN                    NaN                       NaN   \n",
      "1                       NaN                    NaN                       NaN   \n",
      "2                       NaN                    NaN                       NaN   \n",
      "3                       NaN                    NaN                       NaN   \n",
      "4                       NaN                    NaN                       NaN   \n",
      "\n",
      "   TotalDebtToEquityYear  bookValue  earningsPerShare  ebitda  \\\n",
      "0                    NaN        NaN               NaN     NaN   \n",
      "1                    0.0        NaN               NaN     NaN   \n",
      "2                    0.0        NaN               NaN     NaN   \n",
      "3                    0.0        NaN               NaN     NaN   \n",
      "4                    0.0        NaN               NaN     NaN   \n",
      "\n",
      "   epsEstimateCurrentYear  marketCapitalization  peRatio  pegRatio  \\\n",
      "0                     NaN                   NaN      NaN       NaN   \n",
      "1                     NaN                   NaN      NaN       NaN   \n",
      "2                     NaN                   NaN      NaN       NaN   \n",
      "3                     NaN                   NaN      NaN       NaN   \n",
      "4                     NaN                   NaN      NaN       NaN   \n",
      "\n",
      "   pricePerBook  pricePerEpsEstimateCurrentYear  pricePerEpsEstimateNextYear  \\\n",
      "0           NaN                             NaN                          NaN   \n",
      "1           NaN                             NaN                          NaN   \n",
      "2           NaN                             NaN                          NaN   \n",
      "3           NaN                             NaN                          NaN   \n",
      "4           NaN                             NaN                          NaN   \n",
      "\n",
      "   pricePerSales  \n",
      "0            NaN  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            NaN  \n",
      "4            NaN  \n",
      "quoteDate                            False\n",
      "adjustedPrice                        False\n",
      "volume                               False\n",
      "previousClose                        False\n",
      "change                               False\n",
      "changeInPercent                      False\n",
      "52WeekHigh                           False\n",
      "52WeekLow                            False\n",
      "changeFrom52WeekHigh                 False\n",
      "changeFrom52WeekLow                  False\n",
      "percebtChangeFrom52WeekHigh          False\n",
      "percentChangeFrom52WeekLow           False\n",
      "Price200DayAverage                   False\n",
      "Price52WeekPercChange                False\n",
      "1WeekVolatility                      False\n",
      "2WeekVolatility                      False\n",
      "4WeekVolatility                      False\n",
      "8WeekVolatility                      False\n",
      "12WeekVolatility                     False\n",
      "26WeekVolatility                     False\n",
      "52WeekVolatility                     False\n",
      "allordpreviousclose                  False\n",
      "allordchange                         False\n",
      "allorddayshigh                       False\n",
      "allorddayslow                        False\n",
      "allordpercebtChangeFrom52WeekHigh    False\n",
      "allordpercentChangeFrom52WeekLow     False\n",
      "asxpreviousclose                     False\n",
      "asxchange                            False\n",
      "asxdayshigh                          False\n",
      "asxdayslow                           False\n",
      "asxpercebtChangeFrom52WeekHigh       False\n",
      "asxpercentChangeFrom52WeekLow        False\n",
      "exDividendDate                       False\n",
      "exDividendPayout                     False\n",
      "640106_A3597525W                     False\n",
      "AINTCOV                              False\n",
      "AverageVolume                        False\n",
      "BookValuePerShareYear                False\n",
      "CashPerShareYear                     False\n",
      "DPSRecentYear                        False\n",
      "EBITDMargin                          False\n",
      "EPS                                  False\n",
      "EPSGrowthRate10Years                 False\n",
      "EPSGrowthRate5Years                  False\n",
      "FIRMMCRT                             False\n",
      "FXRUSD                               False\n",
      "Float                                False\n",
      "GRCPAIAD                             False\n",
      "GRCPAISAD                            False\n",
      "GRCPBCAD                             False\n",
      "GRCPBCSAD                            False\n",
      "GRCPBMAD                             False\n",
      "GRCPNRAD                             False\n",
      "GRCPRCAD                             False\n",
      "H01_GGDPCVGDP                        False\n",
      "H01_GGDPCVGDPFY                      False\n",
      "H05_GLFSEPTPOP                       False\n",
      "IAD                                  False\n",
      "LTDebtToEquityQuarter                False\n",
      "LTDebtToEquityYear                   False\n",
      "MarketCap                            False\n",
      "NetIncomeGrowthRate5Years            False\n",
      "NetProfitMarginPercent               False\n",
      "OperatingMargin                      False\n",
      "PE                                   False\n",
      "PriceToBook                          False\n",
      "ReturnOnAssets5Years                 False\n",
      "ReturnOnAssetsTTM                    False\n",
      "ReturnOnAssetsYear                   False\n",
      "ReturnOnEquity5Years                 False\n",
      "ReturnOnEquityTTM                    False\n",
      "ReturnOnEquityYear                   False\n",
      "RevenueGrowthRate10Years             False\n",
      "RevenueGrowthRate5Years              False\n",
      "TotalDebtToAssetsQuarter             False\n",
      "TotalDebtToAssetsYear                False\n",
      "TotalDebtToEquityQuarter             False\n",
      "TotalDebtToEquityYear                False\n",
      "bookValue                            False\n",
      "earningsPerShare                     False\n",
      "ebitda                               False\n",
      "epsEstimateCurrentYear               False\n",
      "marketCapitalization                 False\n",
      "peRatio                              False\n",
      "pegRatio                             False\n",
      "pricePerBook                         False\n",
      "pricePerEpsEstimateCurrentYear       False\n",
      "pricePerEpsEstimateNextYear          False\n",
      "pricePerSales                        False\n",
      "symbol_1AD                           False\n",
      "symbol_1AG                           False\n",
      "symbol_1AL                           False\n",
      "symbol_1PG                           False\n",
      "symbol_1ST                           False\n",
      "symbol_3DP                           False\n",
      "symbol_3PL                           False\n",
      "symbol_4CE                           False\n",
      "symbol_4DS                           False\n",
      "symbol_88E                           False\n",
      "                                     ...  \n",
      "symbol_CNC                           False\n",
      "symbol_CND                           False\n",
      "symbol_CNH                           False\n",
      "symbol_CNI                           False\n",
      "symbol_CNJ                           False\n",
      "symbol_CNL                           False\n",
      "symbol_CNP                           False\n",
      "symbol_CNQ                           False\n",
      "symbol_CNR                           False\n",
      "symbol_CNU                           False\n",
      "symbol_CNW                           False\n",
      "symbol_CNX                           False\n",
      "symbol_COE                           False\n",
      "symbol_COH                           False\n",
      "symbol_COI                           False\n",
      "symbol_COJ                           False\n",
      "symbol_COM                           False\n",
      "symbol_COO                           False\n",
      "symbol_COY                           False\n",
      "symbol_CPA                           False\n",
      "symbol_CPH                           False\n",
      "symbol_CPK                           False\n",
      "symbol_CPL                           False\n",
      "symbol_CPN                           False\n",
      "symbol_CPS                           False\n",
      "symbol_CPU                           False\n",
      "symbol_CQC                           False\n",
      "symbol_CQR                           False\n",
      "symbol_CR8                           False\n",
      "symbol_CRB                           False\n",
      "symbol_CRC                           False\n",
      "symbol_CRL                           False\n",
      "symbol_CRM                           False\n",
      "symbol_CSD                           False\n",
      "symbol_CSE                           False\n",
      "symbol_CSL                           False\n",
      "symbol_CSR                           False\n",
      "symbol_CSS                           False\n",
      "symbol_CSU                           False\n",
      "symbol_CSV                           False\n",
      "symbol_CTD                           False\n",
      "symbol_CTE                           False\n",
      "symbol_CTM                           False\n",
      "symbol_CTN                           False\n",
      "symbol_CTO                           False\n",
      "symbol_CTP                           False\n",
      "symbol_CTR                           False\n",
      "symbol_CTX                           False\n",
      "symbol_CUA                           False\n",
      "symbol_CUE                           False\n",
      "symbol_CUL                           False\n",
      "symbol_CUP                           False\n",
      "symbol_CUV                           False\n",
      "symbol_CUX                           False\n",
      "symbol_CV1                           False\n",
      "symbol_CVC                           False\n",
      "symbol_CVN                           False\n",
      "symbol_CVO                           False\n",
      "symbol_CVR                           False\n",
      "symbol_CVS                           False\n",
      "symbol_CVT                           False\n",
      "symbol_CVV                           False\n",
      "symbol_CVW                           False\n",
      "symbol_CVY                           False\n",
      "symbol_CWC                           False\n",
      "symbol_CWH                           False\n",
      "symbol_CWK                           False\n",
      "symbol_CWN                           False\n",
      "symbol_CWP                           False\n",
      "symbol_CWY                           False\n",
      "symbol_CXD                           False\n",
      "symbol_CXM                           False\n",
      "symbol_CXO                           False\n",
      "symbol_CXU                           False\n",
      "symbol_CXX                           False\n",
      "symbol_CXZ                           False\n",
      "symbol_CYA                           False\n",
      "symbol_CYB                           False\n",
      "symbol_CYC                           False\n",
      "symbol_CYG                           False\n",
      "symbol_CYL                           False\n",
      "symbol_CYO                           False\n",
      "symbol_CYP                           False\n",
      "symbol_CYU                           False\n",
      "symbol_CYY                           False\n",
      "symbol_CZA                           False\n",
      "symbol_CZI                           False\n",
      "symbol_CZL                           False\n",
      "4WeekBollingerPrediction_Falling     False\n",
      "4WeekBollingerPrediction_Rising      False\n",
      "4WeekBollingerPrediction_Steady      False\n",
      "4WeekBollingerType_Above             False\n",
      "4WeekBollingerType_Below             False\n",
      "4WeekBollingerType_Within            False\n",
      "12WeekBollingerPrediction_Falling    False\n",
      "12WeekBollingerPrediction_Rising     False\n",
      "12WeekBollingerPrediction_Steady     False\n",
      "12WeekBollingerType_Above            False\n",
      "12WeekBollingerType_Below            False\n",
      "12WeekBollingerType_Within           False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def is_date(string):\n",
    "    try: \n",
    "        parse(string)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def convert_date_to_ordinal(date_val):\n",
    "    if(pd.isnull(date_val)):\n",
    "        return -99999\n",
    "    \n",
    "    elif(type(date_val) is str):\n",
    "        if(is_date(date_val)):\n",
    "            return parse(date_val).toordinal()\n",
    "        else:\n",
    "            return -99999\n",
    "\n",
    "    elif(type(date_val) is int or type(date_val) is float):\n",
    "        return date_val\n",
    "    \n",
    "\n",
    "# Fix date values - convert to ordinals\n",
    "filtered_data['quoteDate'] = filtered_data['quoteDate'].apply(lambda x: convert_date_to_ordinal(x))\n",
    "\n",
    "# print(filtered_data['exDividendDate'].apply(lambda x: convert_date_to_ordinal(x)))\n",
    "filtered_data['exDividendDate'] = filtered_data['exDividendDate'].apply(lambda x: convert_date_to_ordinal(x))\n",
    "\n",
    "print(filtered_data.head(5))\n",
    "\n",
    "# Convert categorical variables to boolean fields\n",
    "#  4WeekBollingerPrediction              \n",
    "#  4WeekBollingerType                    \n",
    "#  12WeekBollingerPrediction             \n",
    "#  12WeekBollingerType                   \n",
    "\n",
    "filtered_data = pd.get_dummies(data=filtered_data, columns=['symbol', '4WeekBollingerPrediction', '4WeekBollingerType', \n",
    "                                                            '12WeekBollingerPrediction', '12WeekBollingerType'])\n",
    "\n",
    "\n",
    "# Fill nan values with placeholder and check for null values\n",
    "filtered_data = filtered_data.fillna(-99999)\n",
    "print(pd.isnull(filtered_data).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quoteDate                              int64\n",
      "adjustedPrice                        float64\n",
      "volume                                 int64\n",
      "previousClose                        float64\n",
      "change                               float64\n",
      "changeInPercent                      float64\n",
      "52WeekHigh                           float64\n",
      "52WeekLow                            float64\n",
      "changeFrom52WeekHigh                 float64\n",
      "changeFrom52WeekLow                  float64\n",
      "percebtChangeFrom52WeekHigh          float64\n",
      "percentChangeFrom52WeekLow           float64\n",
      "Price200DayAverage                   float64\n",
      "Price52WeekPercChange                float64\n",
      "1WeekVolatility                      float64\n",
      "2WeekVolatility                      float64\n",
      "4WeekVolatility                      float64\n",
      "8WeekVolatility                      float64\n",
      "12WeekVolatility                     float64\n",
      "26WeekVolatility                     float64\n",
      "52WeekVolatility                     float64\n",
      "allordpreviousclose                  float64\n",
      "allordchange                         float64\n",
      "allorddayshigh                       float64\n",
      "allorddayslow                        float64\n",
      "allordpercebtChangeFrom52WeekHigh    float64\n",
      "allordpercentChangeFrom52WeekLow     float64\n",
      "asxpreviousclose                     float64\n",
      "asxchange                            float64\n",
      "asxdayshigh                          float64\n",
      "asxdayslow                           float64\n",
      "asxpercebtChangeFrom52WeekHigh       float64\n",
      "asxpercentChangeFrom52WeekLow        float64\n",
      "exDividendDate                         int64\n",
      "exDividendPayout                     float64\n",
      "640106_A3597525W                     float64\n",
      "AINTCOV                              float64\n",
      "AverageVolume                        float64\n",
      "BookValuePerShareYear                float64\n",
      "CashPerShareYear                     float64\n",
      "DPSRecentYear                        float64\n",
      "EBITDMargin                          float64\n",
      "EPS                                  float64\n",
      "EPSGrowthRate10Years                 float64\n",
      "EPSGrowthRate5Years                  float64\n",
      "FIRMMCRT                             float64\n",
      "FXRUSD                               float64\n",
      "Float                                float64\n",
      "GRCPAIAD                             float64\n",
      "GRCPAISAD                            float64\n",
      "GRCPBCAD                             float64\n",
      "GRCPBCSAD                            float64\n",
      "GRCPBMAD                             float64\n",
      "GRCPNRAD                             float64\n",
      "GRCPRCAD                             float64\n",
      "H01_GGDPCVGDP                        float64\n",
      "H01_GGDPCVGDPFY                      float64\n",
      "H05_GLFSEPTPOP                       float64\n",
      "IAD                                  float64\n",
      "LTDebtToEquityQuarter                float64\n",
      "LTDebtToEquityYear                   float64\n",
      "MarketCap                            float64\n",
      "NetIncomeGrowthRate5Years            float64\n",
      "NetProfitMarginPercent               float64\n",
      "OperatingMargin                      float64\n",
      "PE                                   float64\n",
      "PriceToBook                          float64\n",
      "ReturnOnAssets5Years                 float64\n",
      "ReturnOnAssetsTTM                    float64\n",
      "ReturnOnAssetsYear                   float64\n",
      "ReturnOnEquity5Years                 float64\n",
      "ReturnOnEquityTTM                    float64\n",
      "ReturnOnEquityYear                   float64\n",
      "RevenueGrowthRate10Years             float64\n",
      "RevenueGrowthRate5Years              float64\n",
      "TotalDebtToAssetsQuarter             float64\n",
      "TotalDebtToAssetsYear                float64\n",
      "TotalDebtToEquityQuarter             float64\n",
      "TotalDebtToEquityYear                float64\n",
      "bookValue                            float64\n",
      "earningsPerShare                     float64\n",
      "ebitda                               float64\n",
      "epsEstimateCurrentYear               float64\n",
      "marketCapitalization                 float64\n",
      "peRatio                              float64\n",
      "pegRatio                             float64\n",
      "pricePerBook                         float64\n",
      "pricePerEpsEstimateCurrentYear       float64\n",
      "pricePerEpsEstimateNextYear          float64\n",
      "pricePerSales                        float64\n",
      "symbol_1AD                             uint8\n",
      "symbol_1AG                             uint8\n",
      "symbol_1AL                             uint8\n",
      "symbol_1PG                             uint8\n",
      "symbol_1ST                             uint8\n",
      "symbol_3DP                             uint8\n",
      "symbol_3PL                             uint8\n",
      "symbol_4CE                             uint8\n",
      "symbol_4DS                             uint8\n",
      "symbol_88E                             uint8\n",
      "                                      ...   \n",
      "symbol_CNC                             uint8\n",
      "symbol_CND                             uint8\n",
      "symbol_CNH                             uint8\n",
      "symbol_CNI                             uint8\n",
      "symbol_CNJ                             uint8\n",
      "symbol_CNL                             uint8\n",
      "symbol_CNP                             uint8\n",
      "symbol_CNQ                             uint8\n",
      "symbol_CNR                             uint8\n",
      "symbol_CNU                             uint8\n",
      "symbol_CNW                             uint8\n",
      "symbol_CNX                             uint8\n",
      "symbol_COE                             uint8\n",
      "symbol_COH                             uint8\n",
      "symbol_COI                             uint8\n",
      "symbol_COJ                             uint8\n",
      "symbol_COM                             uint8\n",
      "symbol_COO                             uint8\n",
      "symbol_COY                             uint8\n",
      "symbol_CPA                             uint8\n",
      "symbol_CPH                             uint8\n",
      "symbol_CPK                             uint8\n",
      "symbol_CPL                             uint8\n",
      "symbol_CPN                             uint8\n",
      "symbol_CPS                             uint8\n",
      "symbol_CPU                             uint8\n",
      "symbol_CQC                             uint8\n",
      "symbol_CQR                             uint8\n",
      "symbol_CR8                             uint8\n",
      "symbol_CRB                             uint8\n",
      "symbol_CRC                             uint8\n",
      "symbol_CRL                             uint8\n",
      "symbol_CRM                             uint8\n",
      "symbol_CSD                             uint8\n",
      "symbol_CSE                             uint8\n",
      "symbol_CSL                             uint8\n",
      "symbol_CSR                             uint8\n",
      "symbol_CSS                             uint8\n",
      "symbol_CSU                             uint8\n",
      "symbol_CSV                             uint8\n",
      "symbol_CTD                             uint8\n",
      "symbol_CTE                             uint8\n",
      "symbol_CTM                             uint8\n",
      "symbol_CTN                             uint8\n",
      "symbol_CTO                             uint8\n",
      "symbol_CTP                             uint8\n",
      "symbol_CTR                             uint8\n",
      "symbol_CTX                             uint8\n",
      "symbol_CUA                             uint8\n",
      "symbol_CUE                             uint8\n",
      "symbol_CUL                             uint8\n",
      "symbol_CUP                             uint8\n",
      "symbol_CUV                             uint8\n",
      "symbol_CUX                             uint8\n",
      "symbol_CV1                             uint8\n",
      "symbol_CVC                             uint8\n",
      "symbol_CVN                             uint8\n",
      "symbol_CVO                             uint8\n",
      "symbol_CVR                             uint8\n",
      "symbol_CVS                             uint8\n",
      "symbol_CVT                             uint8\n",
      "symbol_CVV                             uint8\n",
      "symbol_CVW                             uint8\n",
      "symbol_CVY                             uint8\n",
      "symbol_CWC                             uint8\n",
      "symbol_CWH                             uint8\n",
      "symbol_CWK                             uint8\n",
      "symbol_CWN                             uint8\n",
      "symbol_CWP                             uint8\n",
      "symbol_CWY                             uint8\n",
      "symbol_CXD                             uint8\n",
      "symbol_CXM                             uint8\n",
      "symbol_CXO                             uint8\n",
      "symbol_CXU                             uint8\n",
      "symbol_CXX                             uint8\n",
      "symbol_CXZ                             uint8\n",
      "symbol_CYA                             uint8\n",
      "symbol_CYB                             uint8\n",
      "symbol_CYC                             uint8\n",
      "symbol_CYG                             uint8\n",
      "symbol_CYL                             uint8\n",
      "symbol_CYO                             uint8\n",
      "symbol_CYP                             uint8\n",
      "symbol_CYU                             uint8\n",
      "symbol_CYY                             uint8\n",
      "symbol_CZA                             uint8\n",
      "symbol_CZI                             uint8\n",
      "symbol_CZL                             uint8\n",
      "4WeekBollingerPrediction_Falling       uint8\n",
      "4WeekBollingerPrediction_Rising        uint8\n",
      "4WeekBollingerPrediction_Steady        uint8\n",
      "4WeekBollingerType_Above               uint8\n",
      "4WeekBollingerType_Below               uint8\n",
      "4WeekBollingerType_Within              uint8\n",
      "12WeekBollingerPrediction_Falling      uint8\n",
      "12WeekBollingerPrediction_Rising       uint8\n",
      "12WeekBollingerPrediction_Steady       uint8\n",
      "12WeekBollingerType_Above              uint8\n",
      "12WeekBollingerType_Below              uint8\n",
      "12WeekBollingerType_Within             uint8\n",
      "dtype: object\n",
      "(756392, 744)\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(filtered_data.dtypes)\n",
    "\n",
    "# Copy over X_data columns\n",
    "X_data = filtered_data.values\n",
    "\n",
    "\n",
    "# Check how many fields in X_data\n",
    "print(X_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run xgboost with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for Future8WeekReturn\n",
      "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
      "       gamma=1.5, learning_rate=0.05, max_delta_step=0, max_depth=50,\n",
      "       min_child_weight=0, missing=None, n_estimators=10000, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
      "[0]\tvalidation_0-mae:3.88846\n",
      "Will train until validation_0-mae hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-mae:3.69408\n",
      "[2]\tvalidation_0-mae:3.50942\n",
      "[3]\tvalidation_0-mae:3.334\n",
      "[4]\tvalidation_0-mae:3.16737\n",
      "[5]\tvalidation_0-mae:3.00905\n",
      "[6]\tvalidation_0-mae:2.85867\n",
      "[7]\tvalidation_0-mae:2.7158\n",
      "[8]\tvalidation_0-mae:2.58007\n",
      "[9]\tvalidation_0-mae:2.45114\n",
      "[10]\tvalidation_0-mae:2.32868\n",
      "[11]\tvalidation_0-mae:2.21233\n",
      "[12]\tvalidation_0-mae:2.10182\n",
      "[13]\tvalidation_0-mae:1.99684\n",
      "[14]\tvalidation_0-mae:1.89711\n",
      "[15]\tvalidation_0-mae:1.8024\n",
      "[16]\tvalidation_0-mae:1.71245\n",
      "[17]\tvalidation_0-mae:1.62696\n",
      "[18]\tvalidation_0-mae:1.54578\n",
      "[19]\tvalidation_0-mae:1.46865\n",
      "[20]\tvalidation_0-mae:1.39543\n",
      "[21]\tvalidation_0-mae:1.32587\n",
      "[22]\tvalidation_0-mae:1.25979\n",
      "[23]\tvalidation_0-mae:1.19701\n",
      "[24]\tvalidation_0-mae:1.13739\n",
      "[25]\tvalidation_0-mae:1.08076\n",
      "[26]\tvalidation_0-mae:1.02695\n",
      "[27]\tvalidation_0-mae:0.975834\n",
      "[28]\tvalidation_0-mae:0.927296\n",
      "[29]\tvalidation_0-mae:0.881199\n",
      "[30]\tvalidation_0-mae:0.837409\n",
      "[31]\tvalidation_0-mae:0.795831\n",
      "[32]\tvalidation_0-mae:0.756332\n",
      "[33]\tvalidation_0-mae:0.718846\n",
      "[34]\tvalidation_0-mae:0.683264\n",
      "[35]\tvalidation_0-mae:0.649507\n",
      "[36]\tvalidation_0-mae:0.617456\n",
      "[37]\tvalidation_0-mae:0.587063\n",
      "[38]\tvalidation_0-mae:0.55826\n",
      "[39]\tvalidation_0-mae:0.530976\n",
      "[40]\tvalidation_0-mae:0.505133\n",
      "[41]\tvalidation_0-mae:0.480674\n",
      "[42]\tvalidation_0-mae:0.457512\n",
      "[43]\tvalidation_0-mae:0.435636\n",
      "[44]\tvalidation_0-mae:0.414952\n",
      "[45]\tvalidation_0-mae:0.395474\n",
      "[46]\tvalidation_0-mae:0.377091\n",
      "[47]\tvalidation_0-mae:0.35981\n",
      "[48]\tvalidation_0-mae:0.343568\n",
      "[49]\tvalidation_0-mae:0.328285\n",
      "[50]\tvalidation_0-mae:0.313845\n",
      "[51]\tvalidation_0-mae:0.300386\n",
      "[52]\tvalidation_0-mae:0.287603\n",
      "[53]\tvalidation_0-mae:0.275793\n",
      "[54]\tvalidation_0-mae:0.264638\n",
      "[55]\tvalidation_0-mae:0.25414\n",
      "[56]\tvalidation_0-mae:0.244457\n",
      "[57]\tvalidation_0-mae:0.235378\n",
      "[58]\tvalidation_0-mae:0.226958\n",
      "[59]\tvalidation_0-mae:0.21914\n",
      "[60]\tvalidation_0-mae:0.211716\n",
      "[61]\tvalidation_0-mae:0.204865\n",
      "[62]\tvalidation_0-mae:0.198655\n",
      "[63]\tvalidation_0-mae:0.192753\n",
      "[64]\tvalidation_0-mae:0.187426\n",
      "[65]\tvalidation_0-mae:0.182275\n",
      "[66]\tvalidation_0-mae:0.177673\n",
      "[67]\tvalidation_0-mae:0.173494\n",
      "[68]\tvalidation_0-mae:0.169446\n",
      "[69]\tvalidation_0-mae:0.165723\n",
      "[70]\tvalidation_0-mae:0.162451\n",
      "[71]\tvalidation_0-mae:0.159241\n",
      "[72]\tvalidation_0-mae:0.156397\n",
      "[73]\tvalidation_0-mae:0.153641\n",
      "[74]\tvalidation_0-mae:0.151187\n",
      "[75]\tvalidation_0-mae:0.149052\n",
      "[76]\tvalidation_0-mae:0.146915\n",
      "[77]\tvalidation_0-mae:0.145114\n",
      "[78]\tvalidation_0-mae:0.143098\n",
      "[79]\tvalidation_0-mae:0.141576\n",
      "[80]\tvalidation_0-mae:0.140184\n",
      "[81]\tvalidation_0-mae:0.138804\n",
      "[82]\tvalidation_0-mae:0.137635\n",
      "[83]\tvalidation_0-mae:0.136323\n",
      "[84]\tvalidation_0-mae:0.135362\n",
      "[85]\tvalidation_0-mae:0.134441\n",
      "[86]\tvalidation_0-mae:0.133447\n",
      "[87]\tvalidation_0-mae:0.132635\n",
      "[88]\tvalidation_0-mae:0.132004\n",
      "[89]\tvalidation_0-mae:0.131257\n",
      "[90]\tvalidation_0-mae:0.130463\n",
      "[91]\tvalidation_0-mae:0.129678\n",
      "[92]\tvalidation_0-mae:0.129107\n",
      "[93]\tvalidation_0-mae:0.128666\n",
      "[94]\tvalidation_0-mae:0.128103\n",
      "[95]\tvalidation_0-mae:0.127539\n",
      "[96]\tvalidation_0-mae:0.126938\n",
      "[97]\tvalidation_0-mae:0.126614\n",
      "[98]\tvalidation_0-mae:0.126129\n",
      "[99]\tvalidation_0-mae:0.125911\n",
      "[100]\tvalidation_0-mae:0.12555\n",
      "[101]\tvalidation_0-mae:0.125152\n",
      "[102]\tvalidation_0-mae:0.124976\n",
      "[103]\tvalidation_0-mae:0.12481\n",
      "[104]\tvalidation_0-mae:0.124548\n",
      "[105]\tvalidation_0-mae:0.124355\n",
      "[106]\tvalidation_0-mae:0.124078\n",
      "[107]\tvalidation_0-mae:0.123888\n",
      "[108]\tvalidation_0-mae:0.123748\n",
      "[109]\tvalidation_0-mae:0.123648\n",
      "[110]\tvalidation_0-mae:0.123306\n",
      "[111]\tvalidation_0-mae:0.123045\n",
      "[112]\tvalidation_0-mae:0.122842\n",
      "[113]\tvalidation_0-mae:0.122597\n",
      "[114]\tvalidation_0-mae:0.122354\n",
      "[115]\tvalidation_0-mae:0.122302\n",
      "[116]\tvalidation_0-mae:0.122184\n",
      "[117]\tvalidation_0-mae:0.121979\n",
      "[118]\tvalidation_0-mae:0.121902\n",
      "[119]\tvalidation_0-mae:0.121721\n",
      "[120]\tvalidation_0-mae:0.121633\n",
      "[121]\tvalidation_0-mae:0.12151\n",
      "[122]\tvalidation_0-mae:0.121298\n",
      "[123]\tvalidation_0-mae:0.121211\n",
      "[124]\tvalidation_0-mae:0.121041\n",
      "[125]\tvalidation_0-mae:0.120851\n",
      "[126]\tvalidation_0-mae:0.120674\n",
      "[127]\tvalidation_0-mae:0.120494\n",
      "[128]\tvalidation_0-mae:0.120357\n",
      "[129]\tvalidation_0-mae:0.120329\n",
      "[130]\tvalidation_0-mae:0.120309\n",
      "[131]\tvalidation_0-mae:0.12016\n",
      "[132]\tvalidation_0-mae:0.120143\n",
      "[133]\tvalidation_0-mae:0.120052\n",
      "[134]\tvalidation_0-mae:0.120013\n",
      "[135]\tvalidation_0-mae:0.119867\n",
      "[136]\tvalidation_0-mae:0.119856\n",
      "[137]\tvalidation_0-mae:0.119757\n",
      "[138]\tvalidation_0-mae:0.119683\n",
      "[139]\tvalidation_0-mae:0.119515\n",
      "[140]\tvalidation_0-mae:0.119322\n",
      "[141]\tvalidation_0-mae:0.1192\n",
      "[142]\tvalidation_0-mae:0.119187\n",
      "[143]\tvalidation_0-mae:0.119152\n",
      "[144]\tvalidation_0-mae:0.118988\n",
      "[145]\tvalidation_0-mae:0.118836\n",
      "[146]\tvalidation_0-mae:0.118778\n",
      "[147]\tvalidation_0-mae:0.118676\n",
      "[148]\tvalidation_0-mae:0.118652\n",
      "[149]\tvalidation_0-mae:0.118577\n",
      "[150]\tvalidation_0-mae:0.118429\n",
      "[151]\tvalidation_0-mae:0.118326\n",
      "[152]\tvalidation_0-mae:0.118286\n",
      "[153]\tvalidation_0-mae:0.118165\n",
      "[154]\tvalidation_0-mae:0.118157\n",
      "[155]\tvalidation_0-mae:0.118134\n",
      "[156]\tvalidation_0-mae:0.118062\n",
      "[157]\tvalidation_0-mae:0.118042\n",
      "[158]\tvalidation_0-mae:0.118024\n",
      "[159]\tvalidation_0-mae:0.117934\n",
      "[160]\tvalidation_0-mae:0.117853\n",
      "[161]\tvalidation_0-mae:0.117819\n",
      "[162]\tvalidation_0-mae:0.11768\n",
      "[163]\tvalidation_0-mae:0.11766\n",
      "[164]\tvalidation_0-mae:0.117607\n",
      "[165]\tvalidation_0-mae:0.117521\n",
      "[166]\tvalidation_0-mae:0.117473\n",
      "[167]\tvalidation_0-mae:0.117432\n",
      "[168]\tvalidation_0-mae:0.117312\n",
      "[169]\tvalidation_0-mae:0.117171\n",
      "[170]\tvalidation_0-mae:0.117136\n",
      "[171]\tvalidation_0-mae:0.117074\n",
      "[172]\tvalidation_0-mae:0.117046\n",
      "[173]\tvalidation_0-mae:0.116997\n",
      "[174]\tvalidation_0-mae:0.11691\n",
      "[175]\tvalidation_0-mae:0.116902\n",
      "[176]\tvalidation_0-mae:0.116851\n",
      "[177]\tvalidation_0-mae:0.116817\n",
      "[178]\tvalidation_0-mae:0.116791\n",
      "[179]\tvalidation_0-mae:0.116789\n",
      "[180]\tvalidation_0-mae:0.116735\n",
      "[181]\tvalidation_0-mae:0.11671\n",
      "[182]\tvalidation_0-mae:0.116698\n",
      "[183]\tvalidation_0-mae:0.116539\n",
      "[184]\tvalidation_0-mae:0.116462\n",
      "[185]\tvalidation_0-mae:0.116402\n",
      "[186]\tvalidation_0-mae:0.116364\n",
      "[187]\tvalidation_0-mae:0.116316\n",
      "[188]\tvalidation_0-mae:0.116236\n",
      "[189]\tvalidation_0-mae:0.116164\n",
      "[190]\tvalidation_0-mae:0.1161\n",
      "[191]\tvalidation_0-mae:0.116008\n",
      "[192]\tvalidation_0-mae:0.115985\n",
      "[193]\tvalidation_0-mae:0.115969\n",
      "[194]\tvalidation_0-mae:0.115873\n",
      "[195]\tvalidation_0-mae:0.115843\n",
      "[196]\tvalidation_0-mae:0.115803\n",
      "[197]\tvalidation_0-mae:0.115803\n",
      "[198]\tvalidation_0-mae:0.115803\n",
      "[199]\tvalidation_0-mae:0.115804\n",
      "[200]\tvalidation_0-mae:0.115804\n",
      "[201]\tvalidation_0-mae:0.115804\n",
      "[202]\tvalidation_0-mae:0.115804\n",
      "[203]\tvalidation_0-mae:0.115804\n",
      "[204]\tvalidation_0-mae:0.115804\n",
      "[205]\tvalidation_0-mae:0.115804\n",
      "[206]\tvalidation_0-mae:0.115804\n",
      "[207]\tvalidation_0-mae:0.115804\n",
      "[208]\tvalidation_0-mae:0.115805\n",
      "[209]\tvalidation_0-mae:0.115805\n",
      "[210]\tvalidation_0-mae:0.115805\n",
      "[211]\tvalidation_0-mae:0.115805\n",
      "[212]\tvalidation_0-mae:0.115805\n",
      "[213]\tvalidation_0-mae:0.115805\n",
      "[214]\tvalidation_0-mae:0.115805\n",
      "[215]\tvalidation_0-mae:0.115805\n",
      "[216]\tvalidation_0-mae:0.115805\n",
      "[217]\tvalidation_0-mae:0.115805\n",
      "[218]\tvalidation_0-mae:0.115805\n",
      "[219]\tvalidation_0-mae:0.115805\n",
      "[220]\tvalidation_0-mae:0.115805\n",
      "[221]\tvalidation_0-mae:0.115805\n",
      "[222]\tvalidation_0-mae:0.115805\n",
      "[223]\tvalidation_0-mae:0.115805\n",
      "[224]\tvalidation_0-mae:0.115805\n",
      "[225]\tvalidation_0-mae:0.115806\n",
      "[226]\tvalidation_0-mae:0.115806\n",
      "[227]\tvalidation_0-mae:0.115806\n",
      "[228]\tvalidation_0-mae:0.115806\n",
      "[229]\tvalidation_0-mae:0.115806\n",
      "[230]\tvalidation_0-mae:0.115806\n",
      "[231]\tvalidation_0-mae:0.115806\n",
      "[232]\tvalidation_0-mae:0.115806\n",
      "[233]\tvalidation_0-mae:0.115806\n",
      "[234]\tvalidation_0-mae:0.115806\n",
      "[235]\tvalidation_0-mae:0.115806\n",
      "[236]\tvalidation_0-mae:0.115806\n",
      "[237]\tvalidation_0-mae:0.115806\n",
      "[238]\tvalidation_0-mae:0.115806\n",
      "[239]\tvalidation_0-mae:0.115806\n",
      "[240]\tvalidation_0-mae:0.115806\n",
      "[241]\tvalidation_0-mae:0.115806\n",
      "[242]\tvalidation_0-mae:0.115806\n",
      "[243]\tvalidation_0-mae:0.115806\n",
      "[244]\tvalidation_0-mae:0.115806\n",
      "[245]\tvalidation_0-mae:0.115806\n",
      "[246]\tvalidation_0-mae:0.115806\n",
      "Stopping. Best iteration:\n",
      "[196]\tvalidation_0-mae:0.115803\n",
      "\n",
      "Elapsed time: 4788\n",
      "Fold mean absolute error: 0.115806049482\n",
      "Fold r2: 0.681075784805\n",
      "[0]\tvalidation_0-mae:3.88917\n",
      "Will train until validation_0-mae hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-mae:3.69477\n",
      "[2]\tvalidation_0-mae:3.5101\n",
      "[3]\tvalidation_0-mae:3.33466\n",
      "[4]\tvalidation_0-mae:3.16798\n",
      "[5]\tvalidation_0-mae:3.00968\n",
      "[6]\tvalidation_0-mae:2.85927\n",
      "[7]\tvalidation_0-mae:2.7164\n",
      "[8]\tvalidation_0-mae:2.58069\n",
      "[9]\tvalidation_0-mae:2.45176\n",
      "[10]\tvalidation_0-mae:2.32927\n",
      "[11]\tvalidation_0-mae:2.21293\n",
      "[12]\tvalidation_0-mae:2.10243\n",
      "[13]\tvalidation_0-mae:1.99746\n",
      "[14]\tvalidation_0-mae:1.89775\n",
      "[15]\tvalidation_0-mae:1.80302\n",
      "[16]\tvalidation_0-mae:1.71305\n",
      "[17]\tvalidation_0-mae:1.62756\n",
      "[18]\tvalidation_0-mae:1.54637\n",
      "[19]\tvalidation_0-mae:1.46925\n",
      "[20]\tvalidation_0-mae:1.39599\n",
      "[21]\tvalidation_0-mae:1.3264\n",
      "[22]\tvalidation_0-mae:1.26031\n",
      "[23]\tvalidation_0-mae:1.19751\n",
      "[24]\tvalidation_0-mae:1.13787\n",
      "[25]\tvalidation_0-mae:1.08119\n",
      "[26]\tvalidation_0-mae:1.02739\n",
      "[27]\tvalidation_0-mae:0.976295\n",
      "[28]\tvalidation_0-mae:0.927748\n",
      "[29]\tvalidation_0-mae:0.8816\n",
      "[30]\tvalidation_0-mae:0.837805\n",
      "[31]\tvalidation_0-mae:0.796219\n",
      "[32]\tvalidation_0-mae:0.756737\n",
      "[33]\tvalidation_0-mae:0.719245\n",
      "[34]\tvalidation_0-mae:0.683638\n",
      "[35]\tvalidation_0-mae:0.649873\n",
      "[36]\tvalidation_0-mae:0.617818\n",
      "[37]\tvalidation_0-mae:0.587441\n",
      "[38]\tvalidation_0-mae:0.558636\n",
      "[39]\tvalidation_0-mae:0.531338\n",
      "[40]\tvalidation_0-mae:0.505479\n",
      "[41]\tvalidation_0-mae:0.480999\n",
      "[42]\tvalidation_0-mae:0.457832\n",
      "[43]\tvalidation_0-mae:0.435923\n",
      "[44]\tvalidation_0-mae:0.41523\n",
      "[45]\tvalidation_0-mae:0.395682\n",
      "[46]\tvalidation_0-mae:0.37725\n",
      "[47]\tvalidation_0-mae:0.359887\n",
      "[48]\tvalidation_0-mae:0.343525\n",
      "[49]\tvalidation_0-mae:0.328186\n",
      "[50]\tvalidation_0-mae:0.313692\n",
      "[51]\tvalidation_0-mae:0.300156\n",
      "[52]\tvalidation_0-mae:0.287488\n",
      "[53]\tvalidation_0-mae:0.275561\n",
      "[54]\tvalidation_0-mae:0.264437\n",
      "[55]\tvalidation_0-mae:0.254107\n",
      "[56]\tvalidation_0-mae:0.244417\n",
      "[57]\tvalidation_0-mae:0.235374\n",
      "[58]\tvalidation_0-mae:0.226952\n",
      "[59]\tvalidation_0-mae:0.219164\n",
      "[60]\tvalidation_0-mae:0.211789\n",
      "[61]\tvalidation_0-mae:0.204939\n",
      "[62]\tvalidation_0-mae:0.198739\n",
      "[63]\tvalidation_0-mae:0.19286\n",
      "[64]\tvalidation_0-mae:0.187435\n",
      "[65]\tvalidation_0-mae:0.182325\n",
      "[66]\tvalidation_0-mae:0.177814\n",
      "[67]\tvalidation_0-mae:0.173396\n",
      "[68]\tvalidation_0-mae:0.169293\n",
      "[69]\tvalidation_0-mae:0.16566\n",
      "[70]\tvalidation_0-mae:0.162249\n",
      "[71]\tvalidation_0-mae:0.159057\n",
      "[72]\tvalidation_0-mae:0.15612\n",
      "[73]\tvalidation_0-mae:0.153522\n",
      "[74]\tvalidation_0-mae:0.151095\n",
      "[75]\tvalidation_0-mae:0.148927\n",
      "[76]\tvalidation_0-mae:0.146671\n",
      "[77]\tvalidation_0-mae:0.14481\n",
      "[78]\tvalidation_0-mae:0.143098\n",
      "[79]\tvalidation_0-mae:0.141526\n",
      "[80]\tvalidation_0-mae:0.139838\n",
      "[81]\tvalidation_0-mae:0.138481\n",
      "[82]\tvalidation_0-mae:0.13714\n",
      "[83]\tvalidation_0-mae:0.13607\n",
      "[84]\tvalidation_0-mae:0.135119\n",
      "[85]\tvalidation_0-mae:0.133844\n",
      "[86]\tvalidation_0-mae:0.132882\n",
      "[87]\tvalidation_0-mae:0.131989\n",
      "[88]\tvalidation_0-mae:0.131367\n",
      "[89]\tvalidation_0-mae:0.130647\n",
      "[90]\tvalidation_0-mae:0.129687\n",
      "[91]\tvalidation_0-mae:0.12907\n",
      "[92]\tvalidation_0-mae:0.128609\n",
      "[93]\tvalidation_0-mae:0.128189\n",
      "[94]\tvalidation_0-mae:0.127826\n",
      "[95]\tvalidation_0-mae:0.127212\n",
      "[96]\tvalidation_0-mae:0.126769\n",
      "[97]\tvalidation_0-mae:0.126492\n",
      "[98]\tvalidation_0-mae:0.125953\n",
      "[99]\tvalidation_0-mae:0.125474\n",
      "[100]\tvalidation_0-mae:0.125224\n",
      "[101]\tvalidation_0-mae:0.124837\n",
      "[102]\tvalidation_0-mae:0.124563\n",
      "[103]\tvalidation_0-mae:0.124143\n",
      "[104]\tvalidation_0-mae:0.123998\n",
      "[105]\tvalidation_0-mae:0.123703\n",
      "[106]\tvalidation_0-mae:0.123431\n",
      "[107]\tvalidation_0-mae:0.123306\n",
      "[108]\tvalidation_0-mae:0.123164\n",
      "[109]\tvalidation_0-mae:0.122943\n",
      "[110]\tvalidation_0-mae:0.122648\n",
      "[111]\tvalidation_0-mae:0.122552\n",
      "[112]\tvalidation_0-mae:0.122435\n",
      "[113]\tvalidation_0-mae:0.122279\n",
      "[114]\tvalidation_0-mae:0.122116\n",
      "[115]\tvalidation_0-mae:0.121959\n",
      "[116]\tvalidation_0-mae:0.1219\n",
      "[117]\tvalidation_0-mae:0.121779\n",
      "[118]\tvalidation_0-mae:0.121688\n",
      "[119]\tvalidation_0-mae:0.12146\n",
      "[120]\tvalidation_0-mae:0.12129\n",
      "[121]\tvalidation_0-mae:0.121268\n",
      "[122]\tvalidation_0-mae:0.121102\n",
      "[123]\tvalidation_0-mae:0.120972\n",
      "[124]\tvalidation_0-mae:0.120785\n",
      "[125]\tvalidation_0-mae:0.120696\n",
      "[126]\tvalidation_0-mae:0.120677\n",
      "[127]\tvalidation_0-mae:0.12051\n",
      "[128]\tvalidation_0-mae:0.120395\n",
      "[129]\tvalidation_0-mae:0.12019\n",
      "[130]\tvalidation_0-mae:0.120181\n",
      "[131]\tvalidation_0-mae:0.120054\n",
      "[132]\tvalidation_0-mae:0.119996\n",
      "[133]\tvalidation_0-mae:0.119898\n",
      "[134]\tvalidation_0-mae:0.119837\n",
      "[135]\tvalidation_0-mae:0.119765\n",
      "[136]\tvalidation_0-mae:0.119759\n",
      "[137]\tvalidation_0-mae:0.119642\n",
      "[138]\tvalidation_0-mae:0.119539\n",
      "[139]\tvalidation_0-mae:0.119453\n",
      "[140]\tvalidation_0-mae:0.119398\n",
      "[141]\tvalidation_0-mae:0.119239\n",
      "[142]\tvalidation_0-mae:0.119164\n",
      "[143]\tvalidation_0-mae:0.119158\n",
      "[144]\tvalidation_0-mae:0.11914\n",
      "[145]\tvalidation_0-mae:0.119028\n",
      "[146]\tvalidation_0-mae:0.118896\n",
      "[147]\tvalidation_0-mae:0.118871\n",
      "[148]\tvalidation_0-mae:0.118769\n",
      "[149]\tvalidation_0-mae:0.118634\n",
      "[150]\tvalidation_0-mae:0.118577\n",
      "[151]\tvalidation_0-mae:0.118502\n",
      "[152]\tvalidation_0-mae:0.118421\n",
      "[153]\tvalidation_0-mae:0.118332\n",
      "[154]\tvalidation_0-mae:0.11825\n",
      "[155]\tvalidation_0-mae:0.118164\n",
      "[156]\tvalidation_0-mae:0.118058\n",
      "[157]\tvalidation_0-mae:0.118028\n",
      "[158]\tvalidation_0-mae:0.117949\n",
      "[159]\tvalidation_0-mae:0.117855\n",
      "[160]\tvalidation_0-mae:0.117831\n",
      "[161]\tvalidation_0-mae:0.117783\n",
      "[162]\tvalidation_0-mae:0.11773\n",
      "[163]\tvalidation_0-mae:0.117644\n",
      "[164]\tvalidation_0-mae:0.117598\n",
      "[165]\tvalidation_0-mae:0.117405\n",
      "[166]\tvalidation_0-mae:0.117397\n",
      "[167]\tvalidation_0-mae:0.117329\n",
      "[168]\tvalidation_0-mae:0.117297\n",
      "[169]\tvalidation_0-mae:0.117236\n",
      "[170]\tvalidation_0-mae:0.117093\n",
      "[171]\tvalidation_0-mae:0.117009\n",
      "[172]\tvalidation_0-mae:0.11695\n",
      "[173]\tvalidation_0-mae:0.116896\n",
      "[174]\tvalidation_0-mae:0.116871\n",
      "[175]\tvalidation_0-mae:0.116841\n",
      "[176]\tvalidation_0-mae:0.11676\n",
      "[177]\tvalidation_0-mae:0.116741\n",
      "[178]\tvalidation_0-mae:0.116705\n",
      "[179]\tvalidation_0-mae:0.11663\n",
      "[180]\tvalidation_0-mae:0.116578\n",
      "[181]\tvalidation_0-mae:0.116525\n",
      "[182]\tvalidation_0-mae:0.116482\n",
      "[183]\tvalidation_0-mae:0.116451\n",
      "[184]\tvalidation_0-mae:0.116438\n",
      "[185]\tvalidation_0-mae:0.116419\n",
      "[186]\tvalidation_0-mae:0.116391\n",
      "[187]\tvalidation_0-mae:0.116347\n",
      "[188]\tvalidation_0-mae:0.116316\n",
      "[189]\tvalidation_0-mae:0.116287\n",
      "[190]\tvalidation_0-mae:0.116198\n",
      "[191]\tvalidation_0-mae:0.116114\n",
      "[192]\tvalidation_0-mae:0.116032\n",
      "[193]\tvalidation_0-mae:0.115973\n",
      "[194]\tvalidation_0-mae:0.115967\n",
      "[195]\tvalidation_0-mae:0.115925\n",
      "[196]\tvalidation_0-mae:0.115892\n",
      "[197]\tvalidation_0-mae:0.115871\n",
      "[198]\tvalidation_0-mae:0.115832\n",
      "[199]\tvalidation_0-mae:0.11574\n",
      "[200]\tvalidation_0-mae:0.115713\n",
      "[201]\tvalidation_0-mae:0.115661\n",
      "[202]\tvalidation_0-mae:0.115642\n",
      "[203]\tvalidation_0-mae:0.11563\n",
      "[204]\tvalidation_0-mae:0.115525\n",
      "[205]\tvalidation_0-mae:0.11549\n",
      "[206]\tvalidation_0-mae:0.115473\n",
      "[207]\tvalidation_0-mae:0.115417\n",
      "[208]\tvalidation_0-mae:0.115418\n",
      "[209]\tvalidation_0-mae:0.115418\n",
      "[210]\tvalidation_0-mae:0.115418\n",
      "[211]\tvalidation_0-mae:0.115418\n",
      "[212]\tvalidation_0-mae:0.115418\n",
      "[213]\tvalidation_0-mae:0.115418\n",
      "[214]\tvalidation_0-mae:0.115418\n",
      "[215]\tvalidation_0-mae:0.115418\n",
      "[216]\tvalidation_0-mae:0.115418\n",
      "[217]\tvalidation_0-mae:0.115418\n",
      "[218]\tvalidation_0-mae:0.115418\n",
      "[219]\tvalidation_0-mae:0.115418\n",
      "[220]\tvalidation_0-mae:0.115418\n",
      "[221]\tvalidation_0-mae:0.115418\n",
      "[222]\tvalidation_0-mae:0.115418\n",
      "[223]\tvalidation_0-mae:0.115418\n",
      "[224]\tvalidation_0-mae:0.115418\n",
      "[225]\tvalidation_0-mae:0.115418\n",
      "[226]\tvalidation_0-mae:0.115418\n",
      "[227]\tvalidation_0-mae:0.115418\n",
      "[228]\tvalidation_0-mae:0.115418\n",
      "[229]\tvalidation_0-mae:0.115418\n",
      "[230]\tvalidation_0-mae:0.115419\n",
      "[231]\tvalidation_0-mae:0.115419\n",
      "[232]\tvalidation_0-mae:0.115419\n",
      "[233]\tvalidation_0-mae:0.115419\n",
      "[234]\tvalidation_0-mae:0.115419\n",
      "[235]\tvalidation_0-mae:0.115419\n",
      "[236]\tvalidation_0-mae:0.115419\n",
      "[237]\tvalidation_0-mae:0.115419\n",
      "[238]\tvalidation_0-mae:0.115419\n",
      "[239]\tvalidation_0-mae:0.115419\n",
      "[240]\tvalidation_0-mae:0.115419\n",
      "[241]\tvalidation_0-mae:0.115419\n",
      "[242]\tvalidation_0-mae:0.115419\n",
      "[243]\tvalidation_0-mae:0.115419\n",
      "[244]\tvalidation_0-mae:0.115419\n",
      "[245]\tvalidation_0-mae:0.115419\n",
      "[246]\tvalidation_0-mae:0.115419\n",
      "[247]\tvalidation_0-mae:0.115419\n",
      "[248]\tvalidation_0-mae:0.115419\n",
      "[249]\tvalidation_0-mae:0.115419\n",
      "[250]\tvalidation_0-mae:0.115419\n",
      "[251]\tvalidation_0-mae:0.115419\n",
      "[252]\tvalidation_0-mae:0.115419\n",
      "[253]\tvalidation_0-mae:0.115419\n",
      "[254]\tvalidation_0-mae:0.115419\n",
      "[255]\tvalidation_0-mae:0.115419\n",
      "[256]\tvalidation_0-mae:0.115419\n",
      "[257]\tvalidation_0-mae:0.115419\n",
      "Stopping. Best iteration:\n",
      "[207]\tvalidation_0-mae:0.115417\n",
      "\n",
      "Elapsed time: 9510\n",
      "Fold mean absolute error: 0.115418931245\n",
      "Fold r2: 0.676191167572\n",
      "-----\n",
      "Average (2 folds) mean absolute error: 0.115612490364\n",
      "Average (2 folds) r2: 0.678633476188\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "\n",
    "# Split into train and test data\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.7, test_size=0.3)\n",
    "\n",
    "print('Training for', target_column)\n",
    "\n",
    "# Fit model with training set\n",
    "start = time.time()\n",
    "model = xgb.XGBRegressor(nthread=-1, n_estimators=10000, learning_rate=0.05, max_depth=50, min_child_weight=0,\n",
    "                        gamma=1.5)\n",
    "\n",
    "print(model)\n",
    "\n",
    "kfold = KFold(n_splits=2, shuffle=True)\n",
    "\n",
    "errs = []\n",
    "r2s = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X_data):\n",
    "    actuals = y_data[test_index]\n",
    "    eval_set = [(X_data[test_index], actuals)]\n",
    "    model.fit(X_data[train_index],y_data[train_index], early_stopping_rounds=50, eval_metric=\"mae\", \n",
    "              eval_set=eval_set, verbose=True)\n",
    "    predictions = model.predict(X_data[test_index])\n",
    "\n",
    "    # Output model settings\n",
    "    fit_time = time.time()\n",
    "    print('Elapsed time: %d' % (fit_time - start))\n",
    "    err = mean_absolute_error(actuals, predictions)\n",
    "    errs.append(err)\n",
    "    r2 = r2_score(actuals, predictions)\n",
    "    r2s.append(r2)\n",
    "    print(\"Fold mean absolute error: %s\" % err)\n",
    "    print(\"Fold r2: %s\" % r2)\n",
    "    \n",
    "\n",
    "print('-----')\n",
    "print(\"Average (2 folds) mean absolute error: %s\" % np.mean(errs))\n",
    "print(\"Average (2 folds) r2: %s\" % np.mean(r2s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVGridSearch with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "\n",
    "# Split into train and test data\n",
    "print('Splitting data')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.75, test_size=0.25)\n",
    "\n",
    "kfold = KFold(n_splits=4, shuffle=True)\n",
    "\n",
    "print('Training for', target_column)\n",
    "\n",
    "# Fit model with training set\n",
    "start = time.time()\n",
    "model = xgb.XGBRegressor(nthread=-1, n_estimators=10000, learning_rate=0.05, max_depth=50, min_child_weight=0,\n",
    "                        gamma=1.5)\n",
    "eval_set = [(X_test, y_test)]\n",
    "over_fifty = [i/100.0 for i in range(0, 101, 5)]\n",
    "under_fifty = [i/100.0 for i in range(0, 36, 5)]\n",
    "\n",
    "paramGrid = {\n",
    "            #\"max_depth\": [i for i in range(25, 151, 25)],\n",
    "            #\"learning_rate\": [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]#,\n",
    "            # \"min_child_weight\": [0,0.1,0.2], #over_fifty,\n",
    "            #\"gamma\": [0.5, 1, 1.5, 2, 2.5, 3, 3.5]#under_fifty#,\n",
    "            \"scale_pos_weight\": over_fifty,\n",
    "            #\"colsample_bylevel\": over_fifty#,\n",
    "            #\"colsample_bytree\": over_fifty,\n",
    "            #\"subsample\": over_fifty#,\n",
    "            #\"max_delta_step\": under_fifty,\n",
    "            #\"reg_lambda\": over_fifty#,\n",
    "            #\"reg_alpha\": under_fifty\n",
    "            #\"reg_lambda_bias\": under_fifty\n",
    "            }\n",
    "\n",
    "fit_params = {\n",
    "            \"early_stopping_rounds\": 50, \n",
    "            \"eval_metric\": \"mae\", \n",
    "            \"eval_set\": eval_set, \n",
    "            \"verbose\": False\n",
    "            }\n",
    "\n",
    "grid_search = GridSearchCV(model, paramGrid, scoring=\"r2\", fit_params=fit_params, verbose=2, cv=kfold)\n",
    "\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "# Output model settings\n",
    "fit_time = time.time()\n",
    "print('Fit elapsed time: %d' % (fit_time - start))\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "params = grid_result.cv_results_['params']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "\n",
    "# Split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.7, test_size=0.3)\n",
    "\n",
    "print('Training for', target_column)\n",
    "\n",
    "# Fit model with training set\n",
    "start = time.time()\n",
    "model = xgb.XGBRegressor(base_score=0.35, colsample_bylevel=0.8, colsample_bytree=0.8, \n",
    "                         gamma=0, learning_rate=0.075, max_delta_step=0, max_depth=70, \n",
    "                         min_child_weight=0, missing=None, n_estimators=9500, nthread=-1, \n",
    "                         reg_alpha=0.4, reg_lambda=0.3, scale_pos_weight=0, subsample=0.8)\n",
    "model.fit(X_train, y_train)\n",
    "# Output model settings\n",
    "fit_time = time.time()\n",
    "print(model)\n",
    "print('Fit elapsed time: %d' % (fit_time - start))\n",
    "\n",
    "\n",
    "# make predictions for test data\n",
    "predictions = model.predict(X_test)\n",
    "predition_time = time.time()\n",
    "print('Prediction elapsed time: %d' % (predition_time - fit_time))\n",
    "\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print('Mean absolute error:', mae)\n",
    "\n",
    "# Evaluate distribution of errors - get error amount for each prediction\n",
    "y_errors = np.absolute(np.subtract(y_test, predictions))\n",
    "\n",
    "# Plot the distribution of errors\n",
    "pyplot.figure(figsize=(20, 16))\n",
    "plot_title = 'XGBoost ' + target_column + ' prediction errors'\n",
    "pyplot.plot(y_test, y_errors)\n",
    "pyplot.ylabel('Error')\n",
    "pyplot.xlabel('Actual return')\n",
    "pyplot.title(plot_title)\n",
    "pyplot.show(plot_title)\n",
    "\n",
    "# ---------- 8 Week Returns ---------------------------------------------\n",
    "    # --- All data ---\n",
    "    # XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "    #       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "    #       min_child_weight=1, missing=None, n_estimators=100, nthread=1,\n",
    "    #       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "    #       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "    # Mean absolute error:  27.209411857320072\n",
    "\n",
    "    # --- Removed outliers: n_estimators=100 ---\n",
    "    # XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "    #       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "    #       min_child_weight=1, missing=None, n_estimators=100, nthread=1,\n",
    "    #       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "    #       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "    # Mean absolute error:  23.8139769746\n",
    "\n",
    "    # --- Removed outliers: n_estimators=200 ---\n",
    "    # XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "    #       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "    #       min_child_weight=1, missing=None, n_estimators=200, nthread=1,\n",
    "    #       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "    #       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "    # Mean absolute error:  21.9375376132\n",
    "\n",
    "    # --- Removed outliers: n_estimators=500 ---\n",
    "    # XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "    #       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "    #       min_child_weight=1, missing=None, n_estimators=500, nthread=-1,\n",
    "    #       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "    #       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "    # Mean absolute error:  21.9761006957\n",
    "    \n",
    "    \n",
    "# ---------- 8 Week Risk Adjusted Returns -------------------------------------\n",
    "    # --- All data ---\n",
    "    # XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "    #   learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "    #   min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "    #   objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "    #   scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "    # Fit elapsed time: 193\n",
    "    # Prediction elapsed time: 3\n",
    "    # Mean absolute error: 456.680567416\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of errors\n",
    "pyplot.figure(figsize=(20, 16))\n",
    "\n",
    "print( min(y_test))\n",
    "print(max(y_test))\n",
    "\n",
    "\n",
    "plot_title = 'XGBoost ' + target_column + ' prediction errors'\n",
    "pyplot.plot(y_test, y_errors)\n",
    "pyplot.ylabel('Error')\n",
    "pyplot.xlabel('Actual return')\n",
    "pyplot.xlim([ min(y_test),max(y_test)])\n",
    "pyplot.title(plot_title)\n",
    "pyplot.show(plot_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost for one symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "\n",
    "# Split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.7, test_size=0.3)\n",
    "\n",
    "print('Training for', target_column)\n",
    "\n",
    "# Fit model with training set\n",
    "model = xgb.XGBRegressor(nthread=-1, colsample_bylevel=0.8, colsample_bytree=0.8,\n",
    "                         learning_rate=0.075, max_depth=10,n_estimators=9500, \n",
    "                         subsample=0.8)\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "# Output model settings\n",
    "print(model)\n",
    "print('Fit elapsed time: %d' % (elapsed))\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "# make predictions for test data\n",
    "predictions = model.predict(X_test)\n",
    "elapsed = time.time() - start\n",
    "print('Prediction elapsed time: %d' % (elapsed))\n",
    "\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print('Mean absolute error:', mae)\n",
    "\n",
    "# Evaluate distribution of errors - get error amount for each prediction\n",
    "y_errors = np.absolute(np.subtract(y_test, predictions))\n",
    "\n",
    "# Plot the distribution of errors\n",
    "pyplot.figure(figsize=(20, 16))\n",
    "plot_title = 'XGBoost ' + target_column + ' prediction errors'\n",
    "pyplot.plot(y_test, y_errors)\n",
    "pyplot.ylabel('Error')\n",
    "pyplot.xlabel('Actual return')\n",
    "pyplot.title(plot_title)\n",
    "pyplot.show(plot_title)\n",
    "\n",
    "# ---------- 8 Week Returns - CBA  ---------------------------------------------\n",
    "    # Training for Future8WeekReturn\n",
    "    # XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "    #        learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "    #        min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "    #        objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "    #        scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "    # Fit elapsed time: 0\n",
    "    # Prediction elapsed time: 0\n",
    "    # Mean absolute error: 2.85405055196\n",
    "\n",
    "#     Training for Future8WeekReturn\n",
    "#     XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "#            learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "#            min_child_weight=1, missing=None, n_estimators=500, nthread=-1,\n",
    "#            objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "#            scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "#     Fit elapsed time: 1\n",
    "#     Prediction elapsed time: 0\n",
    "#     Mean absolute error: 1.87473924615\n",
    "\n",
    "#     Training for Future8WeekReturn\n",
    "#     XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "#            learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "#            min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n",
    "#            objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "#            scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "#     Fit elapsed time: 2\n",
    "#     Prediction elapsed time: 0\n",
    "#     Mean absolute error: 1.82999759228\n",
    "\n",
    "#     Training for Future8WeekReturn\n",
    "#     XGBRegressor(base_score=0.5, colsample_bylevel=0.8, colsample_bytree=0.8,\n",
    "#            gamma=0, learning_rate=0.075, max_delta_step=0, max_depth=10,\n",
    "#            min_child_weight=1, missing=None, n_estimators=9500, nthread=-1,\n",
    "#            objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "#            scale_pos_weight=1, seed=0, silent=True, subsample=0.8)\n",
    "#     Fit elapsed time: 14\n",
    "#     Prediction elapsed time: 0\n",
    "#     Mean absolute error: 1.55688219974\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimise single symbol model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "\n",
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Work through parameter optimization\")\n",
    "\n",
    "    # Split into train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.7, test_size=0.3)\n",
    "\n",
    "    \n",
    "    model = xgb.XGBRegressor(nthread=-1)\n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "\n",
    "    print(\"Set non-optimised baseline\")\n",
    "    round_err = []\n",
    "    for r in range(0, 5):\n",
    "        err = []\n",
    "        for train_index, test_index in kfold.split(X_data):\n",
    "            model.fit(X_data[train_index],y_data[train_index])\n",
    "            predictions = model.predict(X_data[test_index])\n",
    "            actuals = y_data[test_index]\n",
    "            err.append(mean_absolute_error(actuals, predictions))\n",
    "\n",
    "        print(np.mean(err))\n",
    "        round_err.append(np.mean(err))\n",
    "\n",
    "    baseline_error = np.mean(round_err)\n",
    "\n",
    "    print(\"Average baseline error: %f\" % baseline_error)\n",
    "    print('-----')\n",
    "\n",
    "    n_estimators=[7000, 7500, 8000, 8500, 9000, 9500, 10000]\n",
    "        \n",
    "    param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    n_estimators_r = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        n_estimators_r.append(grid_result.best_params_['n_estimators'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    n_estimators = find_nearest(n_estimators_r, np.mean(n_estimators_r))\n",
    "    \n",
    "    model.n_estimators = n_estimators\n",
    "    \n",
    "    print(\"Averaged best n_estimators: %f \" % n_estimators)\n",
    "    print('-----')  \n",
    "        \n",
    "    learning_rate = [0.025, 0.05, 0.075, 0.1, 0.2, 0.3]\n",
    "    param_grid = dict(learning_rate=learning_rate)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    learning_rates = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        learning_rates.append(grid_result.best_params_['learning_rate'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    learning_rate = find_nearest(learning_rates, np.mean(learning_rates))\n",
    "    \n",
    "    model.learning_rate = learning_rate\n",
    "    \n",
    "    print(\"Averaged best learning rate: %f \" % learning_rate)\n",
    "    print('-----')     \n",
    "\n",
    "    max_depth = [2, 4, 6, 8, 10, 12, 14]\n",
    "    param_grid = dict(max_depth=max_depth)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    max_depths = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        max_depths.append(grid_result.best_params_['max_depth'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    max_depth = find_nearest(max_depths, np.mean(max_depths))\n",
    "    \n",
    "    model.max_depth = max_depth\n",
    "    \n",
    "    print(\"Averaged best max depth: %f \" % max_depth)\n",
    "    print('-----')\n",
    "    samples = [0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1.0] #[i/100.0 for i in range(60,101, 5)]\n",
    "    param_grid = dict(subsample=samples)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    subsamples = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        subsamples.append(grid_result.best_params_['subsample'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    subsample = find_nearest(subsamples, np.mean(subsamples))\n",
    "    \n",
    "    model.subsample = subsample\n",
    "    \n",
    "    print(\"Averaged best subsample: %f \" % subsample)\n",
    "    print('-----')\n",
    "\n",
    "    param_grid = dict(colsample_bytree=samples)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    colsample_bytrees = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        colsample_bytrees.append(grid_result.best_params_['colsample_bytree'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    colsample_bytree = find_nearest(colsample_bytrees, np.mean(colsample_bytrees))\n",
    "    \n",
    "    model.colsample_bytree = colsample_bytree\n",
    "    \n",
    "    print(\"Averaged best colsample_bytree: %f \" % colsample_bytree)\n",
    "    print('-----')\n",
    "\n",
    "    param_grid = dict(colsample_bylevel=samples)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    colsample_bylevels = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        colsample_bylevels.append(grid_result.best_params_['colsample_bylevel'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    colsample_bylevel = find_nearest(colsample_bylevels, np.mean(colsample_bylevels))\n",
    "    \n",
    "    model.colsample_bylevel = colsample_bylevel\n",
    "    \n",
    "    print(\"Averaged best colsample_bylevel: %f \" % colsample_bylevel)\n",
    "    print('-----')\n",
    "\n",
    "    # Retest with new parameters\n",
    "    round_err = []\n",
    "    for r in range(0, 5):\n",
    "        err = []\n",
    "        for train_index, test_index in kfold.split(X_data):\n",
    "            xgb_model = xgb.XGBRegressor(nthread=-1, colsample_bytree = colsample_bytree, \n",
    "                                         learning_rate = learning_rate, max_depth = max_depth, \n",
    "                                         n_estimators = n_estimators, subsample = subsample,\n",
    "                                         colsample_bylevel = colsample_bylevel)\n",
    "            xgb_model.fit(X_data[train_index],y_data[train_index])\n",
    "            predictions = model.predict(X_data[test_index])\n",
    "            actuals = y_data[test_index]\n",
    "            err.append(mean_absolute_error(actuals, predictions))\n",
    "               \n",
    "        print(np.mean(err))\n",
    "        round_err.append(np.mean(err))\n",
    "\n",
    "    tuned_error = np.mean(round_err)\n",
    "\n",
    "    print(\"Average tuned error: %s\" % tuned_error)\n",
    "    improvement = baseline_error - tuned_error\n",
    "    print('-----')\n",
    "    print('Optimisation improvement result: %s, %s%%' % (improvement, improvement / baseline_error * 100))\n",
    "    print('-----')\n",
    "    print(xgb_model)\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    weights = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    \n",
    "#     model.eval_metric = 'mae'\n",
    "    \n",
    "#     gamma = [0]\n",
    "#     param_grid = dict(gamma=gamma)\n",
    "\n",
    "#     grid_search = GridSearchCV(model, param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "#     gammas = []\n",
    "\n",
    "#     for r in range(0, 5):\n",
    "#         grid_result = grid_search.fit(X_data, y_data)\n",
    "#         # summarize results\n",
    "#         print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#         gammas.append(grid_result.best_params_['gamma'])\n",
    "#         means = grid_result.cv_results_['mean_test_score']\n",
    "#         stds = grid_result.cv_results_['std_test_score']\n",
    "#         params = grid_result.cv_results_['params']\n",
    "\n",
    "#     gamma = find_nearest(gammas, np.mean(gammas))\n",
    "    \n",
    "#     model.gamma = gamma\n",
    "    \n",
    "#     print(\"Averaged best gamma: %f \" % gamma)\n",
    "#     print('-----')    \n",
    "    \n",
    "#     min_child_weight = [0]\n",
    "#     param_grid = dict(min_child_weight=min_child_weight)\n",
    "\n",
    "#     grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "#     min_child_weights = []\n",
    "\n",
    "#     for r in range(0, 5):\n",
    "#         grid_result = grid_search.fit(X_data, y_data)\n",
    "#         # summarize results\n",
    "#         print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#         min_child_weights.append(grid_result.best_params_['min_child_weight'])\n",
    "#         means = grid_result.cv_results_['mean_test_score']\n",
    "#         stds = grid_result.cv_results_['std_test_score']\n",
    "#         params = grid_result.cv_results_['params']\n",
    "\n",
    "#     min_child_weight = find_nearest(min_child_weights, np.mean(min_child_weights))\n",
    "    \n",
    "#     model.min_child_weight = min_child_weight\n",
    "    \n",
    "#     print(\"Averaged best min_child_weight: %f \" % min_child_weight)\n",
    "#     print('-----')\n",
    "\n",
    "    gamma = 0\n",
    "    min_child_weight = 0\n",
    "\n",
    "    reg_lambda = [0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "    param_grid = dict(reg_lambda=reg_lambda)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    reg_lambdas = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        reg_lambdas.append(grid_result.best_params_['reg_lambda'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    reg_lambda = find_nearest(reg_lambdas, np.mean(reg_lambdas))\n",
    "    \n",
    "    model.reg_lambda = reg_lambda\n",
    "    \n",
    "    print(\"Averaged best reg_lambda: %f \" % reg_lambda)\n",
    "    print('-----')\n",
    "\n",
    "    scale_pos_weight = [0, 1, 2, 3, 4, 5]\n",
    "    param_grid = dict(scale_pos_weight=scale_pos_weight)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    scale_pos_weights = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        scale_pos_weights.append(grid_result.best_params_['scale_pos_weight'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    scale_pos_weight = find_nearest(scale_pos_weights, np.mean(scale_pos_weights))\n",
    "    \n",
    "    model.scale_pos_weight = scale_pos_weight\n",
    "    \n",
    "    print(\"Averaged best scale_pos_weight: %f \" % scale_pos_weight)\n",
    "    print('-----')\n",
    "    \n",
    "\n",
    "    reg_alpha = [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "    param_grid = dict(reg_alpha=reg_alpha)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    reg_alphas = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        reg_alphas.append(grid_result.best_params_['reg_alpha'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    reg_alpha = find_nearest(reg_alphas, np.mean(reg_alphas))\n",
    "    \n",
    "    model.reg_alpha = reg_alpha\n",
    "    \n",
    "    print(\"Averaged best reg_alpha: %f \" % reg_alpha)\n",
    "    print('-----')\n",
    "        \n",
    "    base_score = [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "    param_grid = dict(base_score=base_score)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    base_scores = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        base_scores.append(grid_result.best_params_['base_score'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    base_score = find_nearest(base_scores, np.mean(base_scores))\n",
    "    \n",
    "    model.base_score = base_score\n",
    "    \n",
    "    print(\"Averaged best base_score: %f \" % base_score)\n",
    "    print('-----')\n",
    "\n",
    "    \n",
    "    # Retest with new parameters\n",
    "    round_err = []\n",
    "    for r in range(0, 5):\n",
    "        err = []\n",
    "        for train_index, test_index in kfold.split(X_data):\n",
    "            xgb_model = xgb.XGBRegressor(nthread=-1, colsample_bytree = colsample_bytree, gamma=gamma, \n",
    "                                         learning_rate = learning_rate, max_depth = max_depth, \n",
    "                                         n_estimators = n_estimators, subsample = subsample,\n",
    "                                         colsample_bylevel = colsample_bylevel, base_score = base_score,\n",
    "                                         reg_alpha = reg_alpha, scale_pos_weight = scale_pos_weight,\n",
    "                                         reg_lambda = reg_lambda, min_child_weight = min_child_weight)\n",
    "            xgb_model.fit(X_data[train_index],y_data[train_index])\n",
    "            predictions = model.predict(X_data[test_index])\n",
    "            actuals = y_data[test_index]\n",
    "            err.append(mean_absolute_error(actuals, predictions))\n",
    "               \n",
    "        print(np.mean(err))\n",
    "        round_err.append(np.mean(err))\n",
    "\n",
    "    tuned_error = np.mean(round_err)\n",
    "\n",
    "    print(\"Average tuned error: %s\" % tuned_error)\n",
    "    improvement = baseline_error - tuned_error\n",
    "    print('-----')\n",
    "    print('Optimisation improvement result: %s, %s%%' % (improvement, improvement / baseline_error * 100))\n",
    "    print('-----')\n",
    "    print(xgb_model)\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    model.max_depth = 70\n",
    "    n_estimators=[7000, 7500, 8000, 8500, 9000, 9500, 10000]\n",
    "        \n",
    "    param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "    grid_search = GridSearchCV(model,param_grid, scoring=\"neg_mean_absolute_error\", cv=kfold, verbose=1, n_jobs=-1)\n",
    "    n_estimators_r = []\n",
    "\n",
    "    for r in range(0, 5):\n",
    "        grid_result = grid_search.fit(X_data, y_data)\n",
    "        # summarize results\n",
    "        print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "        n_estimators_r.append(grid_result.best_params_['n_estimators'])\n",
    "        means = grid_result.cv_results_['mean_test_score']\n",
    "        stds = grid_result.cv_results_['std_test_score']\n",
    "        params = grid_result.cv_results_['params']\n",
    "\n",
    "    n_estimators = find_nearest(n_estimators_r, np.mean(n_estimators_r))\n",
    "    \n",
    "    model.n_estimators = n_estimators\n",
    "    \n",
    "    print(\"Averaged best n_estimators: %f \" % n_estimators)\n",
    "    print('-----')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare model to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Test with base parameters\n",
    "print('-----')\n",
    "print('Base model')\n",
    "\n",
    "base_errs = []\n",
    "base_r2s = []\n",
    "for r in range(0, 5):\n",
    "    err = []\n",
    "    r2 = []\n",
    "    for train_index, test_index in kfold.split(X_data):\n",
    "        start = time.time()\n",
    "        base_model = xgb.XGBRegressor(nthread=-1)\n",
    "        base_model.fit(X_data[train_index],y_data[train_index])\n",
    "        fit_time = time.time()\n",
    "        predictions = base_model.predict(X_data[test_index])\n",
    "        prediction_time = time.time()\n",
    "        actuals = y_data[test_index]\n",
    "        err.append(mean_absolute_error(actuals, predictions))\n",
    "        r2.append(r2_score(actuals, predictions))\n",
    "               \n",
    "    print(np.mean(err))\n",
    "    base_errs.append(np.mean(err))\n",
    "    print(np.mean(r2))\n",
    "    base_r2s.append(np.mean(r2))\n",
    "    print('Fit elapsed time: %d, Prediction elapsed time: %d' % (fit_time - start, prediction_time - fit_time))\n",
    "\n",
    "base_error = np.mean(base_errs)\n",
    "base_r2 = np.mean(base_r2s)\n",
    "\n",
    "print('-----')\n",
    "print(base_model)\n",
    "print(\"Average base error: %s\" % base_error)\n",
    "print(\"Average base r2: %s\" % base_r2)\n",
    "\n",
    "\n",
    "# Retest with new parameters\n",
    "print('-----')\n",
    "print('Optimised model')\n",
    "\n",
    "opt_err = []\n",
    "opt_r2s = []\n",
    "for r in range(0, 5):\n",
    "    err = []\n",
    "    r2 = []\n",
    "    for train_index, test_index in kfold.split(X_data):\n",
    "        start = time.time()\n",
    "        tuned_model = xgb.XGBRegressor(n_estimators=10000, nthread=-1,  learning_rate=0.05, max_depth=50)\n",
    "        eval_set = [(X_data[test_index], y_data[test_index])]\n",
    "        tuned_model.fit(X_data[train_index],y_data[train_index], early_stopping_rounds=50, eval_metric=\"mae\", \n",
    "                        eval_set=eval_set, verbose=False)\n",
    "        fit_time = time.time()\n",
    "        predictions = tuned_model.predict(X_data[test_index])\n",
    "        prediction_time = time.time()\n",
    "        actuals = y_data[test_index]\n",
    "        err.append(mean_absolute_error(actuals, predictions))\n",
    "        r2.append(r2_score(actuals, predictions))\n",
    "               \n",
    "    print(np.mean(err))\n",
    "    opt_err.append(np.mean(err))\n",
    "    print(np.mean(r2))\n",
    "    opt_r2s.append(np.mean(r2))\n",
    "    print('Fit elapsed time: %d, Prediction elapsed time: %d' % (fit_time - start, prediction_time - fit_time))\n",
    "\n",
    "\n",
    "tuned_error = np.mean(opt_err)\n",
    "tuned_r2 = np.mean(opt_r2s)\n",
    "\n",
    "\n",
    "print('-----')\n",
    "print(tuned_model)\n",
    "print(\"Average tuned error: %s\" % tuned_error)\n",
    "improvement = base_error - tuned_error\n",
    "print('Optimisation improvement result: %s, %s%%' % (improvement, improvement / base_error * 100))\n",
    "print('-----')\n",
    "\n",
    "print(\"Average tuned r2: %s\" % tuned_r2)\n",
    "improvement = tuned_r2 - base_r2\n",
    "print('Optimisation improvement result: %s, %s%%' % (improvement, improvement / base_r2 * 100))\n",
    "print('-----')\n",
    "\n",
    "\n",
    "#     --- CBA --\n",
    "#     Base model\n",
    "#     2.76593178309\n",
    "#     Fit elapsed time: 0, Prediction elapsed time: 0\n",
    "#     2.80202959964\n",
    "#     Fit elapsed time: 0, Prediction elapsed time: 0\n",
    "#     2.74822700498\n",
    "#     Fit elapsed time: 0, Prediction elapsed time: 0\n",
    "#     2.80035623995\n",
    "#     Fit elapsed time: 0, Prediction elapsed time: 0\n",
    "#     2.78568218851\n",
    "#     Fit elapsed time: 0, Prediction elapsed time: 0\n",
    "#     -----\n",
    "#     XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "#            learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "#            min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "#            objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "#            scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "#     Average base error: 2.78044536324\n",
    "#     -----\n",
    "#     Optimised model\n",
    "#     1.42491403015\n",
    "#     Fit elapsed time: 42, Prediction elapsed time: 0\n",
    "#     1.4597646821\n",
    "#     Fit elapsed time: 43, Prediction elapsed time: 0\n",
    "#     1.46155690531\n",
    "#     Fit elapsed time: 43, Prediction elapsed time: 0\n",
    "#     1.45526380132\n",
    "#     Fit elapsed time: 44, Prediction elapsed time: 0\n",
    "#     1.48145221254\n",
    "#     Fit elapsed time: 42, Prediction elapsed time: 0\n",
    "#     -----\n",
    "#     XGBRegressor(base_score=0.35, colsample_bylevel=0.8, colsample_bytree=0.8,\n",
    "#            gamma=0, learning_rate=0.075, max_delta_step=0, max_depth=70,\n",
    "#            min_child_weight=0, missing=None, n_estimators=9500, nthread=-1,\n",
    "#            objective='reg:linear', reg_alpha=0.4, reg_lambda=0.3,\n",
    "#            scale_pos_weight=0, seed=0, silent=True, subsample=0.8)\n",
    "#     Average tuned error: 1.45659032628\n",
    "#     -----\n",
    "#     Optimisation improvement result: 1.32385503695, 47.6130570468%\n",
    "#     -----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check correlations \n",
    "filtered_data[data_columns].corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skrebate import ReliefF\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.7, test_size=0.3)\n",
    "\n",
    "\n",
    "fs = ReliefF()\n",
    "fs.fit(X_train, y_train)\n",
    "\n",
    "for feature_name, feature_score in zip(filtered_data.columns, fs.feature_importances_):\n",
    "    print(feature_name, '\\t', feature_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
